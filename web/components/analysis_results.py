"""
åˆ†æç»“æœç®¡ç†ç»„ä»¶
æä¾›è‚¡ç¥¨åˆ†æå†å²ç»“æœçš„æŸ¥çœ‹å’Œç®¡ç†åŠŸèƒ½
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from typing import Dict, List, Any
import json
import os
from pathlib import Path
import hashlib
import logging

# MongoDBç›¸å…³å¯¼å…¥
try:
    from web.utils.mongodb_report_manager import MongoDBReportManager
    MONGODB_AVAILABLE = True
    print("âœ… MongoDBæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    MONGODB_AVAILABLE = False
    print(f"âŒ MongoDBæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

def safe_timestamp_to_datetime(timestamp_value):
    """å®‰å…¨åœ°å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºdatetimeå¯¹è±¡"""
    if isinstance(timestamp_value, datetime):
        # å¦‚æœå·²ç»æ˜¯datetimeå¯¹è±¡ï¼ˆæ¥è‡ªMongoDBï¼‰
        return timestamp_value
    elif isinstance(timestamp_value, (int, float)):
        # å¦‚æœæ˜¯æ—¶é—´æˆ³æ•°å­—ï¼ˆæ¥è‡ªæ–‡ä»¶ç³»ç»Ÿï¼‰
        try:
            return datetime.fromtimestamp(timestamp_value)
        except (ValueError, OSError):
            # æ—¶é—´æˆ³æ— æ•ˆï¼Œä½¿ç”¨å½“å‰æ—¶é—´
            return datetime.now()
    else:
        # å…¶ä»–æƒ…å†µï¼Œä½¿ç”¨å½“å‰æ—¶é—´
        return datetime.now()

def get_analysis_results_dir():
    """è·å–åˆ†æç»“æœç›®å½•"""
    results_dir = Path(__file__).parent.parent / "data" / "analysis_results"
    results_dir.mkdir(parents=True, exist_ok=True)
    return results_dir

def get_favorites_file():
    """è·å–æ”¶è—æ–‡ä»¶è·¯å¾„"""
    return get_analysis_results_dir() / "favorites.json"

def get_tags_file():
    """è·å–æ ‡ç­¾æ–‡ä»¶è·¯å¾„"""
    return get_analysis_results_dir() / "tags.json"

def load_favorites():
    """åŠ è½½æ”¶è—åˆ—è¡¨"""
    favorites_file = get_favorites_file()
    if favorites_file.exists():
        try:
            with open(favorites_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []
    return []

def save_favorites(favorites):
    """ä¿å­˜æ”¶è—åˆ—è¡¨"""
    favorites_file = get_favorites_file()
    try:
        with open(favorites_file, 'w', encoding='utf-8') as f:
            json.dump(favorites, f, ensure_ascii=False, indent=2)
        return True
    except:
        return False

def load_tags():
    """åŠ è½½æ ‡ç­¾æ•°æ®"""
    tags_file = get_tags_file()
    if tags_file.exists():
        try:
            with open(tags_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_tags(tags):
    """ä¿å­˜æ ‡ç­¾æ•°æ®"""
    tags_file = get_tags_file()
    try:
        with open(tags_file, 'w', encoding='utf-8') as f:
            json.dump(tags, f, ensure_ascii=False, indent=2)
        return True
    except:
        return False

def add_tag_to_analysis(analysis_id, tag):
    """ä¸ºåˆ†æç»“æœæ·»åŠ æ ‡ç­¾"""
    tags = load_tags()
    if analysis_id not in tags:
        tags[analysis_id] = []
    if tag not in tags[analysis_id]:
        tags[analysis_id].append(tag)
        save_tags(tags)

def remove_tag_from_analysis(analysis_id, tag):
    """ä»åˆ†æç»“æœç§»é™¤æ ‡ç­¾"""
    tags = load_tags()
    if analysis_id in tags and tag in tags[analysis_id]:
        tags[analysis_id].remove(tag)
        if not tags[analysis_id]:  # å¦‚æœæ²¡æœ‰æ ‡ç­¾äº†ï¼Œåˆ é™¤è¯¥æ¡ç›®
            del tags[analysis_id]
        save_tags(tags)

def get_analysis_tags(analysis_id):
    """è·å–åˆ†æç»“æœçš„æ ‡ç­¾"""
    tags = load_tags()
    return tags.get(analysis_id, [])

def load_analysis_results(start_date=None, end_date=None, stock_symbol=None, analyst_type=None,
                         limit=100, search_text=None, tags_filter=None, favorites_only=False):
    """åŠ è½½åˆ†æç»“æœ - ä¼˜å…ˆä»MongoDBåŠ è½½"""
    all_results = []
    favorites = load_favorites() if favorites_only else []
    tags_data = load_tags()
    mongodb_loaded = False

    # ä¼˜å…ˆä»MongoDBåŠ è½½æ•°æ®
    if MONGODB_AVAILABLE:
        try:
            print("ğŸ” [æ•°æ®åŠ è½½] ä»MongoDBåŠ è½½åˆ†æç»“æœ")
            mongodb_manager = MongoDBReportManager()
            mongodb_results = mongodb_manager.get_all_reports()
            print(f"ğŸ” [æ•°æ®åŠ è½½] MongoDBè¿”å› {len(mongodb_results)} ä¸ªç»“æœ")

            for mongo_result in mongodb_results:
                # è½¬æ¢MongoDBç»“æœæ ¼å¼
                result = {
                    'analysis_id': mongo_result.get('analysis_id', ''),
                    'timestamp': mongo_result.get('timestamp', 0),
                    'stock_symbol': mongo_result.get('stock_symbol', ''),
                    'analysts': mongo_result.get('analysts', []),
                    'research_depth': mongo_result.get('research_depth', 1),
                    'status': mongo_result.get('status', 'completed'),
                    'summary': mongo_result.get('summary', ''),
                    'performance': mongo_result.get('performance', {}),
                    'tags': tags_data.get(mongo_result.get('analysis_id', ''), []),
                    'is_favorite': mongo_result.get('analysis_id', '') in favorites,
                    'reports': mongo_result.get('reports', {}),
                    'source': 'mongodb'  # æ ‡è®°æ•°æ®æ¥æº
                }
                all_results.append(result)

            mongodb_loaded = True
            print(f"âœ… ä»MongoDBåŠ è½½äº† {len(mongodb_results)} ä¸ªåˆ†æç»“æœ")

        except Exception as e:
            print(f"âŒ MongoDBåŠ è½½å¤±è´¥: {e}")
            logger.error(f"MongoDBåŠ è½½å¤±è´¥: {e}")
            mongodb_loaded = False
    else:
        print("âš ï¸ MongoDBä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ–‡ä»¶ç³»ç»Ÿæ•°æ®")

    # åªæœ‰åœ¨MongoDBåŠ è½½å¤±è´¥æˆ–ä¸å¯ç”¨æ—¶æ‰ä»æ–‡ä»¶ç³»ç»ŸåŠ è½½
    if not mongodb_loaded:
        print("ğŸ”„ [å¤‡ç”¨æ•°æ®æº] ä»æ–‡ä»¶ç³»ç»ŸåŠ è½½åˆ†æç»“æœ")

        # é¦–å…ˆå°è¯•ä»Webç•Œé¢çš„ä¿å­˜ä½ç½®è¯»å–
        web_results_dir = get_analysis_results_dir()
        for result_file in web_results_dir.glob("*.json"):
            if result_file.name in ['favorites.json', 'tags.json']:
                continue

            try:
                with open(result_file, 'r', encoding='utf-8') as f:
                    result = json.load(f)

                    # æ·»åŠ æ ‡ç­¾ä¿¡æ¯
                    result['tags'] = tags_data.get(result.get('analysis_id', ''), [])
                    result['is_favorite'] = result.get('analysis_id', '') in favorites
                    result['source'] = 'file_system'  # æ ‡è®°æ•°æ®æ¥æº

                    all_results.append(result)
            except Exception as e:
                st.warning(f"è¯»å–åˆ†æç»“æœæ–‡ä»¶ {result_file.name} å¤±è´¥: {e}")

        # ç„¶åä»å®é™…çš„åˆ†æç»“æœä¿å­˜ä½ç½®è¯»å–
        project_results_dir = Path(__file__).parent.parent.parent / "data" / "analysis_results" / "detailed"

        if project_results_dir.exists():
            # éå†è‚¡ç¥¨ä»£ç ç›®å½•
            for stock_dir in project_results_dir.iterdir():
                if not stock_dir.is_dir():
                    continue

                stock_code = stock_dir.name

                # éå†æ—¥æœŸç›®å½•
                for date_dir in stock_dir.iterdir():
                    if not date_dir.is_dir():
                        continue

                    date_str = date_dir.name
                    reports_dir = date_dir / "reports"

                    if not reports_dir.exists():
                        continue

                    # è¯»å–æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
                    reports = {}
                    summary_content = ""

                    for report_file in reports_dir.glob("*.md"):
                        try:
                            with open(report_file, 'r', encoding='utf-8') as f:
                                content = f.read()
                                report_name = report_file.stem
                                reports[report_name] = content

                                # å¦‚æœæ˜¯æœ€ç»ˆå†³ç­–æŠ¥å‘Šï¼Œæå–æ‘˜è¦
                                if report_name == "final_trade_decision":
                                    # æå–å‰200ä¸ªå­—ç¬¦ä½œä¸ºæ‘˜è¦
                                    summary_content = content[:200].replace('#', '').replace('*', '').strip()
                                    if len(content) > 200:
                                        summary_content += "..."

                        except Exception as e:
                            continue

                    if reports:
                        # è§£ææ—¥æœŸ
                        try:
                            analysis_date = datetime.strptime(date_str, '%Y-%m-%d')
                            timestamp = analysis_date.timestamp()
                        except:
                            timestamp = datetime.now().timestamp()

                        # åˆ›å»ºåˆ†æç»“æœæ¡ç›®
                        analysis_id = f"{stock_code}_{date_str}_{int(timestamp)}"

                        # å°è¯•ä»å…ƒæ•°æ®æ–‡ä»¶ä¸­è¯»å–çœŸå®çš„ç ”ç©¶æ·±åº¦å’Œåˆ†æå¸ˆä¿¡æ¯
                        research_depth = 1
                        analysts = ['market', 'fundamentals', 'trader']  # é»˜è®¤å€¼

                        metadata_file = date_dir / "analysis_metadata.json"
                        if metadata_file.exists():
                            try:
                                with open(metadata_file, 'r', encoding='utf-8') as f:
                                    metadata = json.load(f)
                                    research_depth = metadata.get('research_depth', 1)
                                    analysts = metadata.get('analysts', analysts)
                            except Exception as e:
                                # å¦‚æœè¯»å–å…ƒæ•°æ®å¤±è´¥ï¼Œä½¿ç”¨æ¨æ–­é€»è¾‘
                                if len(reports) >= 5:
                                    research_depth = 3
                                elif len(reports) >= 3:
                                    research_depth = 2
                        else:
                            # å¦‚æœæ²¡æœ‰å…ƒæ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨æ¨æ–­é€»è¾‘
                            if len(reports) >= 5:
                                research_depth = 3
                            elif len(reports) >= 3:
                                research_depth = 2

                        result = {
                            'analysis_id': analysis_id,
                            'timestamp': timestamp,
                            'stock_symbol': stock_code,
                            'analysts': analysts,
                            'research_depth': research_depth,
                            'status': 'completed',
                            'summary': summary_content,
                            'performance': {},
                            'tags': tags_data.get(analysis_id, []),
                            'is_favorite': analysis_id in favorites,
                            'reports': reports,  # ä¿å­˜æ‰€æœ‰æŠ¥å‘Šå†…å®¹
                            'source': 'file_system'  # æ ‡è®°æ•°æ®æ¥æº
                        }

                        all_results.append(result)

        print(f"ğŸ”„ [å¤‡ç”¨æ•°æ®æº] ä»æ–‡ä»¶ç³»ç»ŸåŠ è½½äº† {len(all_results)} ä¸ªåˆ†æç»“æœ")
    
    # è¿‡æ»¤ç»“æœ
    filtered_results = []
    for result in all_results:
        # æ”¶è—è¿‡æ»¤
        if favorites_only and not result.get('is_favorite', False):
            continue
            
        # æ—¶é—´è¿‡æ»¤
        if start_date or end_date:
            result_time = safe_timestamp_to_datetime(result.get('timestamp', 0))
            if start_date and result_time.date() < start_date:
                continue
            if end_date and result_time.date() > end_date:
                continue
        
        # è‚¡ç¥¨ä»£ç è¿‡æ»¤
        if stock_symbol and stock_symbol.upper() not in result.get('stock_symbol', '').upper():
            continue
        
        # åˆ†æå¸ˆç±»å‹è¿‡æ»¤
        if analyst_type and analyst_type not in result.get('analysts', []):
            continue
            
        # æ–‡æœ¬æœç´¢è¿‡æ»¤
        if search_text:
            search_text = search_text.lower()
            searchable_text = f"{result.get('stock_symbol', '')} {result.get('summary', '')} {' '.join(result.get('analysts', []))}".lower()
            if search_text not in searchable_text:
                continue
                
        # æ ‡ç­¾è¿‡æ»¤
        if tags_filter:
            result_tags = result.get('tags', [])
            if not any(tag in result_tags for tag in tags_filter):
                continue
        
        filtered_results.append(result)
    
    # æŒ‰æ—¶é—´å€’åºæ’åˆ— - ä½¿ç”¨å®‰å…¨çš„æ—¶é—´æˆ³è½¬æ¢å‡½æ•°ç¡®ä¿ç±»å‹ä¸€è‡´
    filtered_results.sort(key=lambda x: safe_timestamp_to_datetime(x.get('timestamp', 0)), reverse=True)
    
    # é™åˆ¶æ•°é‡
    return filtered_results[:limit]

def render_analysis_results():
    """æ¸²æŸ“åˆ†æç»“æœç®¡ç†ç•Œé¢"""
    
    # æ£€æŸ¥æƒé™
    try:
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.dirname(__file__)))
        from utils.auth_manager import auth_manager
        
        if not auth_manager or not auth_manager.check_permission("analysis"):
            st.error("âŒ æ‚¨æ²¡æœ‰æƒé™è®¿é—®åˆ†æç»“æœ")
            st.info("ğŸ’¡ æç¤ºï¼šåˆ†æç»“æœåŠŸèƒ½éœ€è¦ 'analysis' æƒé™")
            return
    except Exception as e:
        st.error(f"âŒ æƒé™æ£€æŸ¥å¤±è´¥: {e}")
        return
    
    st.title("ğŸ“Š åˆ†æç»“æœå†å²è®°å½•")
    
    # ä¾§è¾¹æ è¿‡æ»¤é€‰é¡¹
    with st.sidebar:
        st.header("ğŸ” æœç´¢ä¸è¿‡æ»¤")
        
        # æ–‡æœ¬æœç´¢
        search_text = st.text_input("ğŸ” å…³é”®è¯æœç´¢", placeholder="æœç´¢è‚¡ç¥¨ä»£ç ã€æ‘˜è¦å†…å®¹...")
        
        # æ”¶è—è¿‡æ»¤
        favorites_only = st.checkbox("â­ ä»…æ˜¾ç¤ºæ”¶è—")
        
        # æ—¥æœŸèŒƒå›´é€‰æ‹©
        date_range = st.selectbox(
            "ğŸ“… æ—¶é—´èŒƒå›´",
            ["æœ€è¿‘1å¤©", "æœ€è¿‘3å¤©", "æœ€è¿‘7å¤©", "æœ€è¿‘30å¤©", "è‡ªå®šä¹‰"],
            index=2
        )
        
        if date_range == "è‡ªå®šä¹‰":
            start_date = st.date_input("å¼€å§‹æ—¥æœŸ", datetime.now() - timedelta(days=7))
            end_date = st.date_input("ç»“æŸæ—¥æœŸ", datetime.now())
        else:
            days_map = {"æœ€è¿‘1å¤©": 1, "æœ€è¿‘3å¤©": 3, "æœ€è¿‘7å¤©": 7, "æœ€è¿‘30å¤©": 30}
            days = days_map[date_range]
            end_date = datetime.now().date()
            start_date = (datetime.now() - timedelta(days=days)).date()
        
        # è‚¡ç¥¨ä»£ç è¿‡æ»¤
        stock_filter = st.text_input("ğŸ“ˆ è‚¡ç¥¨ä»£ç ", placeholder="å¦‚: 000001, AAPL")
        
        # åˆ†æå¸ˆç±»å‹è¿‡æ»¤
        analyst_filter = st.selectbox(
            "ğŸ‘¥ åˆ†æå¸ˆç±»å‹",
            ["å…¨éƒ¨", "market_analyst", "social_media_analyst", "news_analyst", "fundamental_analyst"],
            help="æ³¨æ„ï¼šç¤¾äº¤åª’ä½“åˆ†æå¸ˆä»…é€‚ç”¨äºç¾è‚¡å’Œæ¸¯è‚¡ï¼ŒAè‚¡åˆ†æä¸­ä¸åŒ…å«æ­¤ç±»å‹"
        )
        
        if analyst_filter == "å…¨éƒ¨":
            analyst_filter = None
            
        # æ ‡ç­¾è¿‡æ»¤
        all_tags = set()
        tags_data = load_tags()
        for tag_list in tags_data.values():
            all_tags.update(tag_list)
        
        if all_tags:
            selected_tags = st.multiselect("ğŸ·ï¸ æ ‡ç­¾è¿‡æ»¤", sorted(all_tags))
        else:
            selected_tags = []
    
    # åŠ è½½åˆ†æç»“æœ
    results = load_analysis_results(
        start_date=start_date,
        end_date=end_date,
        stock_symbol=stock_filter if stock_filter else None,
        analyst_type=analyst_filter,
        limit=200,
        search_text=search_text if search_text else None,
        tags_filter=selected_tags if selected_tags else None,
        favorites_only=favorites_only
    )
    
    if not results:
        st.warning("ğŸ“­ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„åˆ†æç»“æœ")
        return
    
    # æ˜¾ç¤ºç»Ÿè®¡æ¦‚è§ˆ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ“Š æ€»åˆ†ææ•°", len(results))
    
    with col2:
        unique_stocks = len(set(result.get('stock_symbol', 'unknown') for result in results))
        st.metric("ğŸ“ˆ åˆ†æè‚¡ç¥¨", unique_stocks)
    
    with col3:
        successful_analyses = sum(1 for result in results if result.get('status') == 'completed')
        success_rate = (successful_analyses / len(results) * 100) if results else 0
        st.metric("âœ… æˆåŠŸç‡", f"{success_rate:.1f}%")
    
    with col4:
        favorites_count = sum(1 for result in results if result.get('is_favorite', False))
        st.metric("â­ æ”¶è—æ•°", favorites_count)
    
    # ä¿ç•™éœ€è¦çš„åŠŸèƒ½æŒ‰é’®ï¼Œç§»é™¤ä¸éœ€è¦çš„åŠŸèƒ½
    tab1, tab2, tab3 = st.tabs([
        "ğŸ“‹ ç»“æœåˆ—è¡¨", "ğŸ“ˆ ç»Ÿè®¡å›¾è¡¨", "ğŸ“Š è¯¦ç»†åˆ†æ"
    ])
    
    with tab1:
        render_results_list(results)
    
    with tab2:
        render_results_charts(results)
    
    with tab3:
        render_detailed_analysis(results)

def render_results_list(results: List[Dict[str, Any]]):
    """æ¸²æŸ“åˆ†æç»“æœåˆ—è¡¨"""
    
    st.subheader("ğŸ“‹ åˆ†æç»“æœåˆ—è¡¨")
    
    # æ’åºé€‰é¡¹
    col1, col2 = st.columns([2, 1])
    with col1:
        sort_by = st.selectbox("æ’åºæ–¹å¼", ["æ—¶é—´å€’åº", "æ—¶é—´æ­£åº", "è‚¡ç¥¨ä»£ç ", "æˆåŠŸç‡"])
    with col2:
        view_mode = st.selectbox("æ˜¾ç¤ºæ¨¡å¼", ["å¡ç‰‡è§†å›¾", "è¡¨æ ¼è§†å›¾"])
    
    # æ’åºç»“æœ
    if sort_by == "æ—¶é—´æ­£åº":
        results.sort(key=lambda x: safe_timestamp_to_datetime(x.get('timestamp', 0)))
    elif sort_by == "è‚¡ç¥¨ä»£ç ":
        results.sort(key=lambda x: x.get('stock_symbol', ''))
    elif sort_by == "æˆåŠŸç‡":
        results.sort(key=lambda x: 1 if x.get('status') == 'completed' else 0, reverse=True)
    
    if view_mode == "è¡¨æ ¼è§†å›¾":
        render_results_table(results)
    else:
        render_results_cards(results)

def render_results_table(results: List[Dict[str, Any]]):
    """æ¸²æŸ“è¡¨æ ¼è§†å›¾"""
    
    # å‡†å¤‡è¡¨æ ¼æ•°æ®
    table_data = []
    for result in results:
        table_data.append({
            'æ—¶é—´': safe_timestamp_to_datetime(result.get('timestamp', 0)).strftime('%m-%d %H:%M'),
            'è‚¡ç¥¨': result.get('stock_symbol', 'unknown'),
            'åˆ†æå¸ˆ': ', '.join(result.get('analysts', [])[:2]) + ('...' if len(result.get('analysts', [])) > 2 else ''),
            'çŠ¶æ€': 'âœ…' if result.get('status') == 'completed' else 'âŒ',
            'æ”¶è—': 'â­' if result.get('is_favorite', False) else '',
            'æ ‡ç­¾': ', '.join(result.get('tags', [])[:2]) + ('...' if len(result.get('tags', [])) > 2 else ''),
            'æ‘˜è¦': (result.get('summary', '')[:50] + '...') if len(result.get('summary', '')) > 50 else result.get('summary', '')
        })
    
    if table_data:
        df = pd.DataFrame(table_data)
        st.dataframe(df, use_container_width=True)

def render_results_cards(results: List[Dict[str, Any]]):
    """æ¸²æŸ“å¡ç‰‡è§†å›¾"""
    
    # åˆ†é¡µè®¾ç½®
    page_size = st.selectbox("æ¯é¡µæ˜¾ç¤º", [5, 10, 20, 50], index=1)
    total_pages = (len(results) + page_size - 1) // page_size
    
    if total_pages > 1:
        page = st.number_input("é¡µç ", min_value=1, max_value=total_pages, value=1) - 1
    else:
        page = 0
    
    # è·å–å½“å‰é¡µæ•°æ®
    start_idx = page * page_size
    end_idx = min(start_idx + page_size, len(results))
    page_results = results[start_idx:end_idx]
    
    # æ˜¾ç¤ºç»“æœå¡ç‰‡
    for i, result in enumerate(page_results):
        analysis_id = result.get('analysis_id', '')
        
        with st.container():
            # å¡ç‰‡å¤´éƒ¨
            col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
            
            with col1:
                st.markdown(f"### ğŸ“Š {result.get('stock_symbol', 'unknown')}")
                st.caption(f"ğŸ• {safe_timestamp_to_datetime(result.get('timestamp', 0)).strftime('%Y-%m-%d %H:%M:%S')}")
            
            with col2:
                # æ”¶è—æŒ‰é’®
                is_favorite = result.get('is_favorite', False)
                if st.button("â­" if is_favorite else "â˜†", key=f"fav_{start_idx + i}"):
                    toggle_favorite(analysis_id)
                    st.rerun()
            
            with col3:
                # æŸ¥çœ‹è¯¦æƒ…æŒ‰é’®
                result_id = result.get('_id') or result.get('analysis_id') or f"result_{start_idx + i}"
                current_expanded = st.session_state.get('expanded_result_id') == result_id
                button_text = "ğŸ”¼ æ”¶èµ·" if current_expanded else "ğŸ‘ï¸ è¯¦æƒ…"

                if st.button(button_text, key=f"view_{start_idx + i}"):
                    if current_expanded:
                        # å¦‚æœå½“å‰å·²å±•å¼€ï¼Œåˆ™æ”¶èµ·
                        st.session_state['expanded_result_id'] = None
                    else:
                        # å±•å¼€å½“å‰ç»“æœçš„è¯¦æƒ…
                        st.session_state['expanded_result_id'] = result_id
                        st.session_state['selected_result_for_detail'] = result
                    st.rerun()
            
            with col4:
                # çŠ¶æ€æ˜¾ç¤º
                status_icon = "âœ…" if result.get('status') == 'completed' else "âŒ"
                st.markdown(f"**çŠ¶æ€**: {status_icon}")
            
            # å¡ç‰‡å†…å®¹
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.write(f"**åˆ†æå¸ˆ**: {', '.join(result.get('analysts', []))}")
                st.write(f"**ç ”ç©¶æ·±åº¦**: {result.get('research_depth', 'unknown')}")

                # æ˜¾ç¤ºåˆ†ææ‘˜è¦
                if result.get('summary'):
                    summary = result['summary'][:150] + "..." if len(result['summary']) > 150 else result['summary']
                    st.write(f"**æ‘˜è¦**: {summary}")
            
            with col2:
                # æ˜¾ç¤ºæ ‡ç­¾
                tags = result.get('tags', [])
                if tags:
                    st.write("**æ ‡ç­¾**:")
                    for tag in tags[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªæ ‡ç­¾
                        st.markdown(f"`{tag}`")
                    if len(tags) > 3:
                        st.caption(f"è¿˜æœ‰ {len(tags) - 3} ä¸ªæ ‡ç­¾...")

            # æ˜¾ç¤ºæŠ˜å è¯¦æƒ…
            result_id = result.get('_id') or result.get('analysis_id') or f"result_{start_idx + i}"
            if st.session_state.get('expanded_result_id') == result_id:
                show_expanded_detail(result)

            st.divider()
    
    # æ˜¾ç¤ºåˆ†é¡µä¿¡æ¯
    if total_pages > 1:
        st.info(f"ç¬¬ {page + 1} é¡µï¼Œå…± {total_pages} é¡µï¼Œæ€»è®¡ {len(results)} æ¡è®°å½•")
    
    # æ³¨æ„ï¼šè¯¦æƒ…ç°åœ¨ä»¥æŠ˜å æ–¹å¼æ˜¾ç¤ºåœ¨æ¯ä¸ªç»“æœä¸‹æ–¹

# å¼¹çª—åŠŸèƒ½å·²ç§»é™¤ï¼Œè¯¦æƒ…ç°åœ¨ä»¥æŠ˜å æ–¹å¼æ˜¾ç¤º

def toggle_favorite(analysis_id):
    """åˆ‡æ¢æ”¶è—çŠ¶æ€"""
    favorites = load_favorites()
    if analysis_id in favorites:
        favorites.remove(analysis_id)
    else:
        favorites.append(analysis_id)
    save_favorites(favorites)

def render_results_comparison(results: List[Dict[str, Any]]):
    """æ¸²æŸ“ç»“æœå¯¹æ¯”åŠŸèƒ½"""
    
    st.subheader("ğŸ”„ åˆ†æç»“æœå¯¹æ¯”")
    
    if len(results) < 2:
        st.warning("è‡³å°‘éœ€è¦2ä¸ªåˆ†æç»“æœæ‰èƒ½è¿›è¡Œå¯¹æ¯”")
        return
    
    # é€‰æ‹©è¦å¯¹æ¯”çš„ç»“æœ
    col1, col2 = st.columns(2)
    
    result_options = []
    for i, result in enumerate(results[:20]):  # é™åˆ¶é€‰é¡¹æ•°é‡
        option = f"{result.get('stock_symbol', 'unknown')} - {safe_timestamp_to_datetime(result.get('timestamp', 0)).strftime('%m-%d %H:%M')}"
        result_options.append((option, i))
    
    with col1:
        st.write("**é€‰æ‹©ç»“æœA**")
        selected_a = st.selectbox("ç»“æœA", result_options, format_func=lambda x: x[0], key="compare_a")
        result_a = results[selected_a[1]]
    
    with col2:
        st.write("**é€‰æ‹©ç»“æœB**")
        selected_b = st.selectbox("ç»“æœB", result_options, format_func=lambda x: x[0], key="compare_b")
        result_b = results[selected_b[1]]
    
    if selected_a[1] == selected_b[1]:
        st.warning("è¯·é€‰æ‹©ä¸åŒçš„åˆ†æç»“æœè¿›è¡Œå¯¹æ¯”")
        return
    
    # å¯¹æ¯”æ˜¾ç¤º
    st.markdown("---")
    
    # åŸºæœ¬ä¿¡æ¯å¯¹æ¯”
    st.subheader("ğŸ“‹ åŸºæœ¬ä¿¡æ¯å¯¹æ¯”")
    
    comparison_data = {
        'é¡¹ç›®': ['è‚¡ç¥¨ä»£ç ', 'åˆ†ææ—¶é—´', 'åˆ†æå¸ˆ', 'ç ”ç©¶æ·±åº¦', 'çŠ¶æ€'],
        'ç»“æœA': [
            result_a.get('stock_symbol', 'unknown'),
            safe_timestamp_to_datetime(result_a.get('timestamp', 0)).strftime('%Y-%m-%d %H:%M'),
            ', '.join(result_a.get('analysts', [])),
            str(result_a.get('research_depth', 'unknown')),
            'å®Œæˆ' if result_a.get('status') == 'completed' else 'å¤±è´¥'
        ],
        'ç»“æœB': [
            result_b.get('stock_symbol', 'unknown'),
            safe_timestamp_to_datetime(result_b.get('timestamp', 0)).strftime('%Y-%m-%d %H:%M'),
            ', '.join(result_b.get('analysts', [])),
            str(result_b.get('research_depth', 'unknown')),
            'å®Œæˆ' if result_b.get('status') == 'completed' else 'å¤±è´¥'
        ]
    }
    
    df_comparison = pd.DataFrame(comparison_data)
    st.dataframe(df_comparison, use_container_width=True)
    
    # æ‘˜è¦å¯¹æ¯”
    if result_a.get('summary') or result_b.get('summary'):
        st.subheader("ğŸ“ åˆ†ææ‘˜è¦å¯¹æ¯”")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ç»“æœAæ‘˜è¦**")
            st.text_area("", value=result_a.get('summary', 'æš‚æ— æ‘˜è¦'), height=200, key="summary_a", disabled=True)
        
        with col2:
            st.write("**ç»“æœBæ‘˜è¦**")
            st.text_area("", value=result_b.get('summary', 'æš‚æ— æ‘˜è¦'), height=200, key="summary_b", disabled=True)
    
    # æ€§èƒ½å¯¹æ¯”
    perf_a = result_a.get('performance', {})
    perf_b = result_b.get('performance', {})
    
    if perf_a or perf_b:
        st.subheader("âš¡ æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ç»“æœAæ€§èƒ½**")
            if perf_a:
                st.json(perf_a)
            else:
                st.info("æš‚æ— æ€§èƒ½æ•°æ®")
        
        with col2:
            st.write("**ç»“æœBæ€§èƒ½**")
            if perf_b:
                st.json(perf_b)
            else:
                st.info("æš‚æ— æ€§èƒ½æ•°æ®")

def render_results_charts(results: List[Dict[str, Any]]):
    """æ¸²æŸ“åˆ†æç»“æœç»Ÿè®¡å›¾è¡¨"""
    
    st.subheader("ğŸ“ˆ ç»Ÿè®¡å›¾è¡¨")
    
    # æŒ‰è‚¡ç¥¨ç»Ÿè®¡
    st.subheader("ğŸ“Š æŒ‰è‚¡ç¥¨ç»Ÿè®¡")
    stock_counts = {}
    for result in results:
        stock = result.get('stock_symbol', 'unknown')
        stock_counts[stock] = stock_counts.get(stock, 0) + 1
    
    if stock_counts:
        # åªæ˜¾ç¤ºå‰10ä¸ªæœ€å¸¸åˆ†æçš„è‚¡ç¥¨
        top_stocks = sorted(stock_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        stocks = [item[0] for item in top_stocks]
        counts = [item[1] for item in top_stocks]
        
        fig_bar = px.bar(
            x=stocks,
            y=counts,
            title="æœ€å¸¸åˆ†æçš„è‚¡ç¥¨ (å‰10å)",
            labels={'x': 'è‚¡ç¥¨ä»£ç ', 'y': 'åˆ†ææ¬¡æ•°'},
            color=counts,
            color_continuous_scale='viridis'
        )
        st.plotly_chart(fig_bar, use_container_width=True)
    
    # æŒ‰æ—¶é—´ç»Ÿè®¡
    st.subheader("ğŸ“… æ¯æ—¥åˆ†æè¶‹åŠ¿")
    daily_results = {}
    for result in results:
        date_str = safe_timestamp_to_datetime(result.get('timestamp', 0)).strftime('%Y-%m-%d')
        daily_results[date_str] = daily_results.get(date_str, 0) + 1
    
    if daily_results:
        dates = sorted(daily_results.keys())
        counts = [daily_results[date] for date in dates]
        
        fig_line = go.Figure()
        fig_line.add_trace(go.Scatter(
            x=dates,
            y=counts,
            mode='lines+markers',
            name='æ¯æ—¥åˆ†ææ•°',
            line=dict(color='#2E8B57', width=3),
            marker=dict(size=8, color='#FF6B6B'),
            fill='tonexty'
        ))
        fig_line.update_layout(
            title="æ¯æ—¥åˆ†æè¶‹åŠ¿",
            xaxis_title="æ—¥æœŸ",
            yaxis_title="åˆ†ææ•°é‡",
            hovermode='x unified'
        )
        st.plotly_chart(fig_line, use_container_width=True)
    
    # æŒ‰åˆ†æå¸ˆç±»å‹ç»Ÿè®¡
    st.subheader("ğŸ‘¥ åˆ†æå¸ˆä½¿ç”¨åˆ†å¸ƒ")
    analyst_counts = {}
    for result in results:
        analysts = result.get('analysts', [])
        for analyst in analysts:
            analyst_counts[analyst] = analyst_counts.get(analyst, 0) + 1
    
    if analyst_counts:
        fig_pie = px.pie(
            values=list(analyst_counts.values()),
            names=list(analyst_counts.keys()),
            title="åˆ†æå¸ˆä½¿ç”¨åˆ†å¸ƒ",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        st.plotly_chart(fig_pie, use_container_width=True)
    
    # æˆåŠŸç‡ç»Ÿè®¡
    st.subheader("âœ… åˆ†ææˆåŠŸç‡ç»Ÿè®¡")
    success_data = {'æˆåŠŸ': 0, 'å¤±è´¥': 0}
    for result in results:
        if result.get('status') == 'completed':
            success_data['æˆåŠŸ'] += 1
        else:
            success_data['å¤±è´¥'] += 1
    
    if success_data['æˆåŠŸ'] + success_data['å¤±è´¥'] > 0:
        fig_success = px.pie(
            values=list(success_data.values()),
            names=list(success_data.keys()),
            title="åˆ†ææˆåŠŸç‡",
            color_discrete_map={'æˆåŠŸ': '#4CAF50', 'å¤±è´¥': '#F44336'}
        )
        st.plotly_chart(fig_success, use_container_width=True)
    
    # æ ‡ç­¾ä½¿ç”¨ç»Ÿè®¡
    tags_data = load_tags()
    if tags_data:
        st.subheader("ğŸ·ï¸ æ ‡ç­¾ä½¿ç”¨ç»Ÿè®¡")
        tag_counts = {}
        for tag_list in tags_data.values():
            for tag in tag_list:
                tag_counts[tag] = tag_counts.get(tag, 0) + 1
        
        if tag_counts:
            # åªæ˜¾ç¤ºå‰10ä¸ªæœ€å¸¸ç”¨çš„æ ‡ç­¾
            top_tags = sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:10]
            tags = [item[0] for item in top_tags]
            counts = [item[1] for item in top_tags]
            
            fig_tags = px.bar(
                x=tags,
                y=counts,
                title="æœ€å¸¸ç”¨æ ‡ç­¾ (å‰10å)",
                labels={'x': 'æ ‡ç­¾', 'y': 'ä½¿ç”¨æ¬¡æ•°'},
                color=counts,
                color_continuous_scale='plasma'
            )
            fig_tags.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig_tags, use_container_width=True)

def render_tags_management(results: List[Dict[str, Any]]):
    """æ¸²æŸ“æ ‡ç­¾ç®¡ç†åŠŸèƒ½"""
    
    st.subheader("ğŸ·ï¸ æ ‡ç­¾ç®¡ç†")
    
    # è·å–æ‰€æœ‰æ ‡ç­¾
    all_tags = set()
    tags_data = load_tags()
    for tag_list in tags_data.values():
        all_tags.update(tag_list)
    
    # æ ‡ç­¾ç»Ÿè®¡
    if all_tags:
        st.write("**ç°æœ‰æ ‡ç­¾ç»Ÿè®¡**")
        tag_counts = {}
        for tag_list in tags_data.values():
            for tag in tag_list:
                tag_counts[tag] = tag_counts.get(tag, 0) + 1
        
        # æ˜¾ç¤ºæ ‡ç­¾äº‘
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # åˆ›å»ºæ ‡ç­¾äº‘å¯è§†åŒ–
            if tag_counts:
                fig = px.bar(
                    x=list(tag_counts.keys()),
                    y=list(tag_counts.values()),
                    title="æ ‡ç­¾ä½¿ç”¨é¢‘ç‡",
                    labels={'x': 'æ ‡ç­¾', 'y': 'ä½¿ç”¨æ¬¡æ•°'}
                )
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.write("**æ ‡ç­¾åˆ—è¡¨**")
            for tag, count in sorted(tag_counts.items(), key=lambda x: x[1], reverse=True):
                st.write(f"â€¢ {tag} ({count})")
    
    # æ‰¹é‡æ ‡ç­¾æ“ä½œ
    st.markdown("---")
    st.write("**æ‰¹é‡æ ‡ç­¾æ“ä½œ**")
    
    # é€‰æ‹©è¦æ“ä½œçš„ç»“æœ
    if results:
        selected_results = st.multiselect(
            "é€‰æ‹©åˆ†æç»“æœ",
            options=range(len(results)),
            format_func=lambda i: f"{results[i].get('stock_symbol', 'unknown')} - {safe_timestamp_to_datetime(results[i].get('timestamp', 0)).strftime('%m-%d %H:%M')}",
            max_selections=10
        )
        
        if selected_results:
            col1, col2 = st.columns(2)
            
            with col1:
                # æ·»åŠ æ ‡ç­¾
                new_tag = st.text_input("æ–°æ ‡ç­¾åç§°", placeholder="è¾“å…¥æ ‡ç­¾åç§°")
                if st.button("â• æ·»åŠ æ ‡ç­¾") and new_tag:
                    for idx in selected_results:
                        analysis_id = results[idx].get('analysis_id', '')
                        if analysis_id:
                            add_tag_to_analysis(analysis_id, new_tag)
                    st.success(f"å·²ä¸º {len(selected_results)} ä¸ªç»“æœæ·»åŠ æ ‡ç­¾: {new_tag}")
                    st.rerun()
            
            with col2:
                # ç§»é™¤æ ‡ç­¾
                if all_tags:
                    remove_tag = st.selectbox("é€‰æ‹©è¦ç§»é™¤çš„æ ‡ç­¾", sorted(all_tags))
                    if st.button("â– ç§»é™¤æ ‡ç­¾") and remove_tag:
                        for idx in selected_results:
                            analysis_id = results[idx].get('analysis_id', '')
                            if analysis_id:
                                remove_tag_from_analysis(analysis_id, remove_tag)
                        st.success(f"å·²ä» {len(selected_results)} ä¸ªç»“æœç§»é™¤æ ‡ç­¾: {remove_tag}")
                        st.rerun()

def render_results_export(results: List[Dict[str, Any]]):
    """æ¸²æŸ“åˆ†æç»“æœå¯¼å‡ºåŠŸèƒ½"""
    
    st.subheader("ğŸ“¤ å¯¼å‡ºåˆ†æç»“æœ")
    
    if not results:
        st.warning("æ²¡æœ‰å¯å¯¼å‡ºçš„åˆ†æç»“æœ")
        return
    
    # å¯¼å‡ºé€‰é¡¹
    export_type = st.selectbox("é€‰æ‹©å¯¼å‡ºå†…å®¹", ["æ‘˜è¦ä¿¡æ¯", "å®Œæ•´æ•°æ®"])
    export_format = st.selectbox("é€‰æ‹©å¯¼å‡ºæ ¼å¼", ["CSV", "JSON", "Excel"])
    
    if st.button("ğŸ“¥ å¯¼å‡ºç»“æœ"):
        try:
            if export_type == "æ‘˜è¦ä¿¡æ¯":
                # å¯¼å‡ºæ‘˜è¦ä¿¡æ¯
                summary_data = []
                for result in results:
                    summary_data.append({
                        'åˆ†ææ—¶é—´': safe_timestamp_to_datetime(result.get('timestamp', 0)).strftime('%Y-%m-%d %H:%M:%S'),
                        'è‚¡ç¥¨ä»£ç ': result.get('stock_symbol', 'unknown'),
                        'åˆ†æå¸ˆ': ', '.join(result.get('analysts', [])),
                        'ç ”ç©¶æ·±åº¦': result.get('research_depth', 'unknown'),
                        'çŠ¶æ€': result.get('status', 'unknown'),
                        'æ‘˜è¦': result.get('summary', '')[:100] + '...' if len(result.get('summary', '')) > 100 else result.get('summary', '')
                    })
                
                if export_format == "CSV":
                    df = pd.DataFrame(summary_data)
                    csv_data = df.to_csv(index=False, encoding='utf-8-sig')
                    
                    st.download_button(
                        label="ä¸‹è½½ CSV æ–‡ä»¶",
                        data=csv_data,
                        file_name=f"analysis_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
                
                elif export_format == "JSON":
                    json_data = json.dumps(summary_data, ensure_ascii=False, indent=2)
                    
                    st.download_button(
                        label="ä¸‹è½½ JSON æ–‡ä»¶",
                        data=json_data,
                        file_name=f"analysis_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json"
                    )
                
                elif export_format == "Excel":
                    df = pd.DataFrame(summary_data)
                    
                    from io import BytesIO
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        df.to_excel(writer, index=False, sheet_name='åˆ†ææ‘˜è¦')
                    
                    excel_data = output.getvalue()
                    
                    st.download_button(
                        label="ä¸‹è½½ Excel æ–‡ä»¶",
                        data=excel_data,
                        file_name=f"analysis_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            
            else:  # å®Œæ•´æ•°æ®
                if export_format == "JSON":
                    json_data = json.dumps(results, ensure_ascii=False, indent=2)
                    
                    st.download_button(
                        label="ä¸‹è½½å®Œæ•´æ•°æ® JSON æ–‡ä»¶",
                        data=json_data,
                        file_name=f"analysis_full_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json"
                    )
                else:
                    st.warning("å®Œæ•´æ•°æ®åªæ”¯æŒ JSON æ ¼å¼å¯¼å‡º")
            
            st.success(f"âœ… {export_format} æ–‡ä»¶å‡†å¤‡å®Œæˆï¼Œè¯·ç‚¹å‡»ä¸‹è½½æŒ‰é’®")
            
        except Exception as e:
            st.error(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")

def render_results_comparison(results: List[Dict[str, Any]]):
    """æ¸²æŸ“åˆ†æç»“æœå¯¹æ¯”"""
    
    st.subheader("ğŸ” åˆ†æç»“æœå¯¹æ¯”")
    
    if len(results) < 2:
        st.info("è‡³å°‘éœ€è¦2ä¸ªåˆ†æç»“æœæ‰èƒ½è¿›è¡Œå¯¹æ¯”")
        return
    
    # é€‰æ‹©è¦å¯¹æ¯”çš„åˆ†æç»“æœ
    st.write("**é€‰æ‹©è¦å¯¹æ¯”çš„åˆ†æç»“æœï¼š**")
    
    col1, col2 = st.columns(2)
    
    # å‡†å¤‡é€‰é¡¹
    result_options = []
    for i, result in enumerate(results[:20]):  # é™åˆ¶å‰20ä¸ª
        option = f"{result.get('stock_symbol', 'unknown')} - {safe_timestamp_to_datetime(result.get('timestamp', 0)).strftime('%m-%d %H:%M')}"
        result_options.append((option, i))
    
    with col1:
        st.write("**åˆ†æç»“æœ A**")
        selected_a = st.selectbox(
            "é€‰æ‹©ç¬¬ä¸€ä¸ªåˆ†æç»“æœ", 
            result_options, 
            format_func=lambda x: x[0],
            key="compare_a"
        )
        result_a = results[selected_a[1]]
    
    with col2:
        st.write("**åˆ†æç»“æœ B**")
        selected_b = st.selectbox(
            "é€‰æ‹©ç¬¬äºŒä¸ªåˆ†æç»“æœ", 
            result_options, 
            format_func=lambda x: x[0],
            key="compare_b"
        )
        result_b = results[selected_b[1]]
    
    if selected_a[1] == selected_b[1]:
        st.warning("è¯·é€‰æ‹©ä¸åŒçš„åˆ†æç»“æœè¿›è¡Œå¯¹æ¯”")
        return
    
    # åŸºæœ¬ä¿¡æ¯å¯¹æ¯”
    st.subheader("ğŸ“Š åŸºæœ¬ä¿¡æ¯å¯¹æ¯”")
    
    comparison_data = {
        "é¡¹ç›®": ["è‚¡ç¥¨ä»£ç ", "åˆ†ææ—¶é—´", "åˆ†æå¸ˆæ•°é‡", "ç ”ç©¶æ·±åº¦", "çŠ¶æ€", "æ ‡ç­¾æ•°é‡"],
        "åˆ†æç»“æœ A": [
            result_a.get('stock_symbol', 'unknown'),
            safe_timestamp_to_datetime(result_a.get('timestamp', 0)).strftime('%Y-%m-%d %H:%M'),
            len(result_a.get('analysts', [])),
            result_a.get('research_depth', 'unknown'),
            "âœ… å®Œæˆ" if result_a.get('status') == 'completed' else "âŒ å¤±è´¥",
            len(result_a.get('tags', []))
        ],
        "åˆ†æç»“æœ B": [
            result_b.get('stock_symbol', 'unknown'),
            safe_timestamp_to_datetime(result_b.get('timestamp', 0)).strftime('%Y-%m-%d %H:%M'),
            len(result_b.get('analysts', [])),
            result_b.get('research_depth', 'unknown'),
            "âœ… å®Œæˆ" if result_b.get('status') == 'completed' else "âŒ å¤±è´¥",
            len(result_b.get('tags', []))
        ]
    }
    
    import pandas as pd
    df_comparison = pd.DataFrame(comparison_data)
    st.dataframe(df_comparison, use_container_width=True)
    
    # æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”
    perf_a = result_a.get('performance', {})
    perf_b = result_b.get('performance', {})
    
    if perf_a or perf_b:
        st.subheader("âš¡ æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”")
        
        # åˆå¹¶æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡é”®
        all_perf_keys = set(perf_a.keys()) | set(perf_b.keys())
        
        if all_perf_keys:
            perf_comparison = {
                "æŒ‡æ ‡": list(all_perf_keys),
                "åˆ†æç»“æœ A": [perf_a.get(key, "N/A") for key in all_perf_keys],
                "åˆ†æç»“æœ B": [perf_b.get(key, "N/A") for key in all_perf_keys]
            }
            
            df_perf = pd.DataFrame(perf_comparison)
            st.dataframe(df_perf, use_container_width=True)
    
    # æ ‡ç­¾å¯¹æ¯”
    tags_a = set(result_a.get('tags', []))
    tags_b = set(result_b.get('tags', []))
    
    if tags_a or tags_b:
        st.subheader("ğŸ·ï¸ æ ‡ç­¾å¯¹æ¯”")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.write("**å…±åŒæ ‡ç­¾**")
            common_tags = tags_a & tags_b
            if common_tags:
                for tag in common_tags:
                    st.markdown(f"âœ… `{tag}`")
            else:
                st.write("æ— å…±åŒæ ‡ç­¾")
        
        with col2:
            st.write("**ä»…åœ¨ç»“æœAä¸­**")
            only_a = tags_a - tags_b
            if only_a:
                for tag in only_a:
                    st.markdown(f"ğŸ”µ `{tag}`")
            else:
                st.write("æ— ç‹¬æœ‰æ ‡ç­¾")
        
        with col3:
            st.write("**ä»…åœ¨ç»“æœBä¸­**")
            only_b = tags_b - tags_a
            if only_b:
                for tag in only_b:
                    st.markdown(f"ğŸ”´ `{tag}`")
            else:
                st.write("æ— ç‹¬æœ‰æ ‡ç­¾")
    
    # æ‘˜è¦å¯¹æ¯”
    summary_a = result_a.get('summary', '')
    summary_b = result_b.get('summary', '')
    
    if summary_a or summary_b:
        st.subheader("ğŸ“ åˆ†ææ‘˜è¦å¯¹æ¯”")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**åˆ†æç»“æœ A æ‘˜è¦**")
            if summary_a:
                st.markdown(summary_a)
            else:
                st.write("æ— æ‘˜è¦")
        
        with col2:
            st.write("**åˆ†æç»“æœ B æ‘˜è¦**")
            if summary_b:
                st.markdown(summary_b)
            else:
                st.write("æ— æ‘˜è¦")
    
    # è¯¦ç»†å†…å®¹å¯¹æ¯”
    st.subheader("ğŸ“Š è¯¦ç»†å†…å®¹å¯¹æ¯”")
    
    # å®šä¹‰è¦å¯¹æ¯”çš„å…³é”®å­—æ®µ
    comparison_fields = [
        ('market_report', 'ğŸ“ˆ å¸‚åœºæŠ€æœ¯åˆ†æ'),
        ('fundamentals_report', 'ğŸ’° åŸºæœ¬é¢åˆ†æ'),
        ('sentiment_report', 'ğŸ’­ å¸‚åœºæƒ…ç»ªåˆ†æ'),
        ('news_report', 'ğŸ“° æ–°é—»äº‹ä»¶åˆ†æ'),
        ('risk_assessment', 'âš ï¸ é£é™©è¯„ä¼°'),
        ('investment_plan', 'ğŸ“‹ æŠ•èµ„å»ºè®®'),
        ('final_trade_decision', 'ğŸ¯ æœ€ç»ˆäº¤æ˜“å†³ç­–')
    ]
    
    # åˆ›å»ºå¯¹æ¯”æ ‡ç­¾é¡µ
    available_fields = []
    for field_key, field_name in comparison_fields:
        if (field_key in result_a and result_a[field_key]) or (field_key in result_b and result_b[field_key]):
            available_fields.append((field_key, field_name))
    
    if available_fields:
        tabs = st.tabs([field_name for _, field_name in available_fields])
        
        for i, (tab, (field_key, field_name)) in enumerate(zip(tabs, available_fields)):
            with tab:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**åˆ†æç»“æœ A**")
                    content_a = result_a.get(field_key, '')
                    if content_a:
                        if isinstance(content_a, str):
                            st.markdown(content_a)
                        else:
                            st.write(content_a)
                    else:
                        st.write("æ— æ­¤é¡¹åˆ†æ")
                
                with col2:
                    st.write("**åˆ†æç»“æœ B**")
                    content_b = result_b.get(field_key, '')
                    if content_b:
                        if isinstance(content_b, str):
                            st.markdown(content_b)
                        else:
                            st.write(content_b)
                    else:
                        st.write("æ— æ­¤é¡¹åˆ†æ")

def render_detailed_analysis(results: List[Dict[str, Any]]):
    """æ¸²æŸ“è¯¦ç»†åˆ†æ"""
    
    st.subheader("ğŸ“Š è¯¦ç»†åˆ†æ")
    
    if not results:
        st.info("æ²¡æœ‰å¯åˆ†æçš„æ•°æ®")
        return
    
    # é€‰æ‹©è¦æŸ¥çœ‹çš„åˆ†æç»“æœ
    result_options = []
    for i, result in enumerate(results[:50]):  # æ˜¾ç¤ºå‰50ä¸ª
        option = f"{result.get('stock_symbol', 'unknown')} - {safe_timestamp_to_datetime(result.get('timestamp', 0)).strftime('%m-%d %H:%M')}"
        result_options.append((option, i))
    
    if result_options:
        selected_option = st.selectbox(
            "é€‰æ‹©åˆ†æç»“æœ", 
            result_options, 
            format_func=lambda x: x[0]
        )
        selected_result = results[selected_option[1]]
        
        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("è‚¡ç¥¨ä»£ç ", selected_result.get('stock_symbol', 'unknown'))
            st.metric("åˆ†æå¸ˆæ•°é‡", len(selected_result.get('analysts', [])))
        
        with col2:
            analysis_time = safe_timestamp_to_datetime(selected_result.get('timestamp', 0))
            st.metric("åˆ†ææ—¶é—´", analysis_time.strftime('%m-%d %H:%M'))
            status = "âœ… å®Œæˆ" if selected_result.get('status') == 'completed' else "âŒ å¤±è´¥"
            st.metric("çŠ¶æ€", status)
        
        with col3:
            st.metric("ç ”ç©¶æ·±åº¦", selected_result.get('research_depth', 'unknown'))
            tags = selected_result.get('tags', [])
            st.metric("æ ‡ç­¾æ•°é‡", len(tags))
        
        # æ˜¾ç¤ºæ ‡ç­¾
        if tags:
            st.write("**æ ‡ç­¾**:")
            tag_cols = st.columns(min(len(tags), 5))
            for i, tag in enumerate(tags):
                with tag_cols[i % 5]:
                    st.markdown(f"`{tag}`")
        
        # æ˜¾ç¤ºåˆ†ææ‘˜è¦
        if selected_result.get('summary'):
            st.subheader("ğŸ“ åˆ†ææ‘˜è¦")
            st.markdown(selected_result['summary'])
        
        # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
        performance = selected_result.get('performance', {})
        if performance:
            st.subheader("âš¡ æ€§èƒ½æŒ‡æ ‡")
            perf_cols = st.columns(len(performance))
            for i, (key, value) in enumerate(performance.items()):
                with perf_cols[i]:
                    st.metric(key.replace('_', ' ').title(), f"{value:.2f}" if isinstance(value, (int, float)) else str(value))
        
        # æ˜¾ç¤ºå®Œæ•´åˆ†æç»“æœ
        if st.checkbox("æ˜¾ç¤ºå®Œæ•´åˆ†æç»“æœ"):
            render_detailed_analysis_content(selected_result)

def render_detailed_analysis_content(selected_result):
    """æ¸²æŸ“è¯¦ç»†åˆ†æç»“æœå†…å®¹"""
    st.subheader("ğŸ“Š å®Œæ•´åˆ†ææ•°æ®")

    # æ£€æŸ¥æ˜¯å¦æœ‰æŠ¥å‘Šæ•°æ®ï¼ˆæ”¯æŒæ–‡ä»¶ç³»ç»Ÿå’ŒMongoDBï¼‰
    if 'reports' in selected_result and selected_result['reports']:
        # æ˜¾ç¤ºæ–‡ä»¶ç³»ç»Ÿä¸­çš„æŠ¥å‘Š
        reports = selected_result['reports']
        
        if not reports:
            st.warning("è¯¥åˆ†æç»“æœæ²¡æœ‰å¯ç”¨çš„æŠ¥å‘Šå†…å®¹")
            return
        
        # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„æŠ¥å‘Š
        print(f"ğŸ” [å¼¹çª—è°ƒè¯•] æ•°æ®æ¥æº: {selected_result.get('source', 'æœªçŸ¥')}")
        print(f"ğŸ” [å¼¹çª—è°ƒè¯•] å¯ç”¨æŠ¥å‘Šæ•°é‡: {len(reports)}")
        print(f"ğŸ” [å¼¹çª—è°ƒè¯•] æŠ¥å‘Šç±»å‹: {list(reports.keys())}")

        # åˆ›å»ºæ ‡ç­¾é¡µæ˜¾ç¤ºä¸åŒçš„æŠ¥å‘Š
        report_tabs = list(reports.keys())

        # ä¸ºæŠ¥å‘Šåç§°æ·»åŠ ä¸­æ–‡æ ‡é¢˜å’Œå›¾æ ‡
        report_display_names = {
            'final_trade_decision': 'ğŸ¯ æœ€ç»ˆäº¤æ˜“å†³ç­–',
            'fundamentals_report': 'ğŸ’° åŸºæœ¬é¢åˆ†æ',
            'technical_report': 'ğŸ“ˆ æŠ€æœ¯é¢åˆ†æ',
            'market_sentiment_report': 'ğŸ’­ å¸‚åœºæƒ…ç»ªåˆ†æ',
            'risk_assessment_report': 'âš ï¸ é£é™©è¯„ä¼°',
            'price_target_report': 'ğŸ¯ ç›®æ ‡ä»·æ ¼åˆ†æ',
            'summary_report': 'ğŸ“‹ åˆ†ææ‘˜è¦',
            'news_analysis_report': 'ğŸ“° æ–°é—»åˆ†æ',
            'social_media_report': 'ğŸ“± ç¤¾äº¤åª’ä½“åˆ†æ'
        }
        
        # åˆ›å»ºæ˜¾ç¤ºåç§°åˆ—è¡¨
        tab_names = []
        for report_key in report_tabs:
            display_name = report_display_names.get(report_key, f"ğŸ“„ {report_key.replace('_', ' ').title()}")
            tab_names.append(display_name)
            print(f"ğŸ” [å¼¹çª—è°ƒè¯•] æ·»åŠ æ ‡ç­¾: {display_name}")

        print(f"ğŸ” [å¼¹çª—è°ƒè¯•] æ€»æ ‡ç­¾æ•°: {len(tab_names)}")
        
        if len(tab_names) == 1:
            # åªæœ‰ä¸€ä¸ªæŠ¥å‘Šï¼Œç›´æ¥æ˜¾ç¤º
            st.markdown(f"### {tab_names[0]}")
            st.markdown("---")
            st.markdown(reports[report_tabs[0]])
        else:
            # å¤šä¸ªæŠ¥å‘Šï¼Œä½¿ç”¨æ ‡ç­¾é¡µ
            tabs = st.tabs(tab_names)
            
            for i, (tab, report_key) in enumerate(zip(tabs, report_tabs)):
                with tab:
                    st.markdown(reports[report_key])
        
        return
    
    # æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼ç¾åŒ–æ ‡ç­¾é¡µ
    st.markdown("""
    <style>
    /* æ ‡ç­¾é¡µå®¹å™¨æ ·å¼ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background-color: #f8f9fa;
        padding: 8px;
        border-radius: 10px;
        margin-bottom: 20px;
    }

    /* å•ä¸ªæ ‡ç­¾é¡µæ ·å¼ */
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding: 8px 16px;
        background-color: #ffffff;
        border-radius: 8px;
        border: 1px solid #e1e5e9;
        color: #495057;
        font-weight: 500;
        transition: all 0.3s ease;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }

    /* æ ‡ç­¾é¡µæ‚¬åœæ•ˆæœ */
    .stTabs [data-baseweb="tab"]:hover {
        background-color: #e3f2fd;
        border-color: #2196f3;
        transform: translateY(-1px);
        box-shadow: 0 2px 8px rgba(33,150,243,0.2);
    }

    /* é€‰ä¸­çš„æ ‡ç­¾é¡µæ ·å¼ */
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
        border-color: #667eea !important;
        box-shadow: 0 4px 12px rgba(102,126,234,0.3) !important;
        transform: translateY(-2px);
    }

    /* æ ‡ç­¾é¡µå†…å®¹åŒºåŸŸ */
    .stTabs [data-baseweb="tab-panel"] {
        padding: 20px;
        background-color: #ffffff;
        border-radius: 10px;
        border: 1px solid #e1e5e9;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }

    /* æ ‡ç­¾é¡µæ–‡å­—æ ·å¼ */
    .stTabs [data-baseweb="tab"] p {
        margin: 0;
        font-size: 14px;
        font-weight: 600;
    }

    /* é€‰ä¸­æ ‡ç­¾é¡µçš„æ–‡å­—æ ·å¼ */
    .stTabs [aria-selected="true"] p {
        color: white !important;
        text-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }
    </style>
    """, unsafe_allow_html=True)
    
    # å®šä¹‰åˆ†ææ¨¡å—
    analysis_modules = [
        {
            'key': 'market_report',
            'title': 'ğŸ“ˆ å¸‚åœºæŠ€æœ¯åˆ†æ',
            'icon': 'ğŸ“ˆ',
            'description': 'æŠ€æœ¯æŒ‡æ ‡ã€ä»·æ ¼è¶‹åŠ¿ã€æ”¯æ’‘é˜»åŠ›ä½åˆ†æ'
        },
        {
            'key': 'fundamentals_report',
            'title': 'ğŸ’° åŸºæœ¬é¢åˆ†æ',
            'icon': 'ğŸ’°',
            'description': 'è´¢åŠ¡æ•°æ®ã€ä¼°å€¼æ°´å¹³ã€ç›ˆåˆ©èƒ½åŠ›åˆ†æ'
        },
        {
            'key': 'sentiment_report',
            'title': 'ğŸ’­ å¸‚åœºæƒ…ç»ªåˆ†æ',
            'icon': 'ğŸ’­',
            'description': 'æŠ•èµ„è€…æƒ…ç»ªã€ç¤¾äº¤åª’ä½“æƒ…ç»ªæŒ‡æ ‡'
        },
        {
            'key': 'news_report',
            'title': 'ğŸ“° æ–°é—»äº‹ä»¶åˆ†æ',
            'icon': 'ğŸ“°',
            'description': 'ç›¸å…³æ–°é—»äº‹ä»¶ã€å¸‚åœºåŠ¨æ€å½±å“åˆ†æ'
        },
        {
            'key': 'risk_assessment',
            'title': 'âš ï¸ é£é™©è¯„ä¼°',
            'icon': 'âš ï¸',
            'description': 'é£é™©å› ç´ è¯†åˆ«ã€é£é™©ç­‰çº§è¯„ä¼°'
        },
        {
            'key': 'investment_plan',
            'title': 'ğŸ“‹ æŠ•èµ„å»ºè®®',
            'icon': 'ğŸ“‹',
            'description': 'å…·ä½“æŠ•èµ„ç­–ç•¥ã€ä»“ä½ç®¡ç†å»ºè®®'
        },
        {
            'key': 'investment_debate_state',
            'title': 'ğŸ”¬ ç ”ç©¶å›¢é˜Ÿå†³ç­–',
            'icon': 'ğŸ”¬',
            'description': 'å¤šå¤´/ç©ºå¤´ç ”ç©¶å‘˜è¾©è®ºåˆ†æï¼Œç ”ç©¶ç»ç†ç»¼åˆå†³ç­–'
        },
        {
            'key': 'trader_investment_plan',
            'title': 'ğŸ’¼ äº¤æ˜“å›¢é˜Ÿè®¡åˆ’',
            'icon': 'ğŸ’¼',
            'description': 'ä¸“ä¸šäº¤æ˜“å‘˜åˆ¶å®šçš„å…·ä½“äº¤æ˜“æ‰§è¡Œè®¡åˆ’'
        },
        {
            'key': 'risk_debate_state',
            'title': 'âš–ï¸ é£é™©ç®¡ç†å›¢é˜Ÿ',
            'icon': 'âš–ï¸',
            'description': 'æ¿€è¿›/ä¿å®ˆ/ä¸­æ€§åˆ†æå¸ˆé£é™©è¯„ä¼°ï¼ŒæŠ•èµ„ç»„åˆç»ç†æœ€ç»ˆå†³ç­–'
        },
        {
            'key': 'final_trade_decision',
            'title': 'ğŸ¯ æœ€ç»ˆäº¤æ˜“å†³ç­–',
            'icon': 'ğŸ¯',
            'description': 'ç»¼åˆæ‰€æœ‰å›¢é˜Ÿåˆ†æåçš„æœ€ç»ˆæŠ•èµ„å†³ç­–'
        }
    ]
    
    # è¿‡æ»¤å‡ºæœ‰æ•°æ®çš„æ¨¡å—
    available_modules = []
    for module in analysis_modules:
        if module['key'] in selected_result and selected_result[module['key']]:
            # æ£€æŸ¥å­—å…¸ç±»å‹çš„æ•°æ®æ˜¯å¦æœ‰å®é™…å†…å®¹
            if isinstance(selected_result[module['key']], dict):
                # å¯¹äºå­—å…¸ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰éç©ºçš„å€¼
                has_content = any(v for v in selected_result[module['key']].values() if v)
                if has_content:
                    available_modules.append(module)
            else:
                # å¯¹äºå­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹ï¼Œç›´æ¥æ·»åŠ 
                available_modules.append(module)

    if not available_modules:
        # å¦‚æœæ²¡æœ‰é¢„å®šä¹‰æ¨¡å—çš„æ•°æ®ï¼Œæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„åˆ†ææ•°æ®
        st.info("ğŸ“Š æ˜¾ç¤ºå®Œæ•´åˆ†ææŠ¥å‘Šæ•°æ®")
        
        # æ’é™¤ä¸€äº›åŸºç¡€å­—æ®µï¼Œåªæ˜¾ç¤ºåˆ†æç›¸å…³çš„æ•°æ®
        excluded_keys = {'analysis_id', 'timestamp', 'stock_symbol', 'analysts', 
                        'research_depth', 'status', 'summary', 'performance', 
                        'is_favorite', 'tags', 'full_data'}
        
        # è·å–æ‰€æœ‰åˆ†æç›¸å…³çš„æ•°æ®
        analysis_data = {}
        for key, value in selected_result.items():
            if key not in excluded_keys and value:
                analysis_data[key] = value
        
        # å¦‚æœæœ‰full_dataå­—æ®µï¼Œä¼˜å…ˆä½¿ç”¨å®ƒ
        if 'full_data' in selected_result and selected_result['full_data']:
            full_data = selected_result['full_data']
            if isinstance(full_data, dict):
                for key, value in full_data.items():
                    if key not in excluded_keys and value:
                        analysis_data[key] = value
        
        if analysis_data:
            # åˆ›å»ºåŠ¨æ€æ ‡ç­¾é¡µæ˜¾ç¤ºæ‰€æœ‰åˆ†ææ•°æ®
            tab_names = []
            tab_data = []
            
            for key, value in analysis_data.items():
                # æ ¼å¼åŒ–æ ‡ç­¾é¡µåç§°
                tab_name = key.replace('_', ' ').title()
                if 'report' in key.lower():
                    tab_name = f"ğŸ“Š {tab_name}"
                elif 'analysis' in key.lower():
                    tab_name = f"ğŸ” {tab_name}"
                elif 'decision' in key.lower():
                    tab_name = f"ğŸ¯ {tab_name}"
                elif 'plan' in key.lower():
                    tab_name = f"ğŸ“‹ {tab_name}"
                else:
                    tab_name = f"ğŸ“„ {tab_name}"
                
                tab_names.append(tab_name)
                tab_data.append((key, value))
            
            # åˆ›å»ºæ ‡ç­¾é¡µ
            tabs = st.tabs(tab_names)
            
            for i, (tab, (key, value)) in enumerate(zip(tabs, tab_data)):
                with tab:
                    st.markdown(f"## {tab_names[i]}")
                    st.markdown("---")
                    
                    # æ ¹æ®æ•°æ®ç±»å‹æ˜¾ç¤ºå†…å®¹
                    if isinstance(value, str):
                        # å¦‚æœæ˜¯é•¿æ–‡æœ¬ï¼Œä½¿ç”¨markdownæ˜¾ç¤º
                        if len(value) > 100:
                            st.markdown(value)
                        else:
                            st.write(value)
                    elif isinstance(value, dict):
                        # å­—å…¸ç±»å‹ï¼Œé€’å½’æ˜¾ç¤º
                        for sub_key, sub_value in value.items():
                            if sub_value:
                                st.subheader(sub_key.replace('_', ' ').title())
                                if isinstance(sub_value, str):
                                    st.markdown(sub_value)
                                else:
                                    st.write(sub_value)
                    elif isinstance(value, list):
                        # åˆ—è¡¨ç±»å‹
                        for idx, item in enumerate(value):
                            st.subheader(f"é¡¹ç›® {idx + 1}")
                            if isinstance(item, str):
                                st.markdown(item)
                            else:
                                st.write(item)
                    else:
                        # å…¶ä»–ç±»å‹ç›´æ¥æ˜¾ç¤º
                        st.write(value)
        else:
            # å¦‚æœçœŸçš„æ²¡æœ‰ä»»ä½•åˆ†ææ•°æ®ï¼Œæ˜¾ç¤ºåŸå§‹JSON
            st.warning("ğŸ“Š è¯¥åˆ†æç»“æœæš‚æ— è¯¦ç»†æŠ¥å‘Šæ•°æ®")
            with st.expander("æŸ¥çœ‹åŸå§‹æ•°æ®"):
                st.json(selected_result)
        return

    # åªä¸ºæœ‰æ•°æ®çš„æ¨¡å—åˆ›å»ºæ ‡ç­¾é¡µ
    tabs = st.tabs([module['title'] for module in available_modules])

    for i, (tab, module) in enumerate(zip(tabs, available_modules)):
        with tab:
            # åœ¨å†…å®¹åŒºåŸŸæ˜¾ç¤ºå›¾æ ‡å’Œæè¿°
            st.markdown(f"## {module['icon']} {module['title']}")
            st.markdown(f"*{module['description']}*")
            st.markdown("---")

            # æ ¼å¼åŒ–æ˜¾ç¤ºå†…å®¹
            content = selected_result[module['key']]
            if isinstance(content, str):
                st.markdown(content)
            elif isinstance(content, dict):
                # ç‰¹æ®Šå¤„ç†å›¢é˜Ÿå†³ç­–æŠ¥å‘Šçš„å­—å…¸ç»“æ„
                if module['key'] == 'investment_debate_state':
                    render_investment_debate_content(content)
                elif module['key'] == 'risk_debate_state':
                    render_risk_debate_content(content)
                else:
                    # æ™®é€šå­—å…¸æ ¼å¼åŒ–æ˜¾ç¤º
                    for key, value in content.items():
                        if value:  # åªæ˜¾ç¤ºéç©ºå€¼
                            st.subheader(key.replace('_', ' ').title())
                            if isinstance(value, str):
                                st.markdown(value)
                            else:
                                st.write(value)
            else:
                st.write(content)

def render_investment_debate_content(content):
    """æ¸²æŸ“æŠ•èµ„è¾©è®ºå†…å®¹"""
    if 'bull_analyst_report' in content and content['bull_analyst_report']:
        st.subheader("ğŸ‚ å¤šå¤´åˆ†æå¸ˆè§‚ç‚¹")
        st.markdown(content['bull_analyst_report'])
    
    if 'bear_analyst_report' in content and content['bear_analyst_report']:
        st.subheader("ğŸ» ç©ºå¤´åˆ†æå¸ˆè§‚ç‚¹")
        st.markdown(content['bear_analyst_report'])
    
    if 'research_manager_decision' in content and content['research_manager_decision']:
        st.subheader("ğŸ‘¨â€ğŸ’¼ ç ”ç©¶ç»ç†å†³ç­–")
        st.markdown(content['research_manager_decision'])

def render_risk_debate_content(content):
    """æ¸²æŸ“é£é™©è¾©è®ºå†…å®¹"""
    if 'aggressive_analyst_report' in content and content['aggressive_analyst_report']:
        st.subheader("ğŸ”¥ æ¿€è¿›åˆ†æå¸ˆè§‚ç‚¹")
        st.markdown(content['aggressive_analyst_report'])
    
    if 'conservative_analyst_report' in content and content['conservative_analyst_report']:
        st.subheader("ğŸ›¡ï¸ ä¿å®ˆåˆ†æå¸ˆè§‚ç‚¹")
        st.markdown(content['conservative_analyst_report'])
    
    if 'neutral_analyst_report' in content and content['neutral_analyst_report']:
        st.subheader("âš–ï¸ ä¸­æ€§åˆ†æå¸ˆè§‚ç‚¹")
        st.markdown(content['neutral_analyst_report'])
    
    if 'portfolio_manager_decision' in content and content['portfolio_manager_decision']:
        st.subheader("ğŸ‘¨â€ğŸ’¼ æŠ•èµ„ç»„åˆç»ç†å†³ç­–")
        st.markdown(content['portfolio_manager_decision'])

def save_analysis_result(analysis_id: str, stock_symbol: str, analysts: List[str],
                        research_depth: int, result_data: Dict, status: str = "completed"):
    """ä¿å­˜åˆ†æç»“æœ"""
    try:
        from web.utils.async_progress_tracker import safe_serialize

        # åˆ›å»ºç»“æœæ¡ç›®ï¼Œä½¿ç”¨å®‰å…¨åºåˆ—åŒ–
        result_entry = {
            'analysis_id': analysis_id,
            'timestamp': datetime.now().timestamp(),
            'stock_symbol': stock_symbol,
            'analysts': analysts,
            'research_depth': research_depth,
            'status': status,
            'summary': safe_serialize(result_data.get('summary', '')),
            'performance': safe_serialize(result_data.get('performance', {})),
            'full_data': safe_serialize(result_data)
        }

        # 1. ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        results_dir = get_analysis_results_dir()
        result_file = results_dir / f"analysis_{analysis_id}.json"

        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result_entry, f, ensure_ascii=False, indent=2)

        # 2. ä¿å­˜åˆ°MongoDBï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if MONGODB_AVAILABLE:
            try:
                print(f"ğŸ’¾ [MongoDBä¿å­˜] å¼€å§‹ä¿å­˜åˆ†æç»“æœ: {analysis_id}")
                mongodb_manager = MongoDBReportManager()

                # ä½¿ç”¨æ ‡å‡†çš„save_analysis_reportæ–¹æ³•ï¼Œç¡®ä¿æ•°æ®ç»“æ„ä¸€è‡´
                analysis_results = {
                    'stock_symbol': result_entry.get('stock_symbol', ''),
                    'analysts': result_entry.get('analysts', []),
                    'research_depth': result_entry.get('research_depth', 1),
                    'summary': result_entry.get('summary', ''),
                    'model_info': result_entry.get('model_info', 'Unknown')  # ğŸ”¥ æ·»åŠ æ¨¡å‹ä¿¡æ¯å­—æ®µ
                }

                # å°è¯•ä»æ–‡ä»¶ç³»ç»Ÿè¯»å–æŠ¥å‘Šå†…å®¹
                reports = {}
                try:
                    # æ„å»ºæŠ¥å‘Šç›®å½•è·¯å¾„
                    from pathlib import Path
                    import os

                    # è·å–å½“å‰æ—¥æœŸ
                    current_date = datetime.now().strftime('%Y-%m-%d')

                    # æ„å»ºæŠ¥å‘Šè·¯å¾„
                    project_root = Path(__file__).parent.parent.parent
                    reports_dir = project_root / "data" / "analysis_results" / stock_symbol / current_date / "reports"

                    # ç¡®ä¿è·¯å¾„åœ¨Windowsä¸Šæ­£ç¡®æ˜¾ç¤ºï¼ˆé¿å…åŒåæ–œæ ï¼‰
                    reports_dir_str = os.path.normpath(str(reports_dir))
                    print(f"ğŸ” [MongoDBä¿å­˜] æŸ¥æ‰¾æŠ¥å‘Šç›®å½•: {reports_dir_str}")

                    if reports_dir.exists():
                        # è¯»å–æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
                        for report_file in reports_dir.glob("*.md"):
                            try:
                                with open(report_file, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                    report_name = report_file.stem
                                    reports[report_name] = content
                                    print(f"âœ… [MongoDBä¿å­˜] è¯»å–æŠ¥å‘Š: {report_name} ({len(content)} å­—ç¬¦)")
                            except Exception as e:
                                print(f"âš ï¸ [MongoDBä¿å­˜] è¯»å–æŠ¥å‘Šæ–‡ä»¶å¤±è´¥ {report_file}: {e}")

                        print(f"ğŸ“Š [MongoDBä¿å­˜] å…±è¯»å– {len(reports)} ä¸ªæŠ¥å‘Šæ–‡ä»¶")
                    else:
                        print(f"âš ï¸ [MongoDBä¿å­˜] æŠ¥å‘Šç›®å½•ä¸å­˜åœ¨: {reports_dir_str}")

                except Exception as e:
                    print(f"âš ï¸ [MongoDBä¿å­˜] è¯»å–æŠ¥å‘Šæ–‡ä»¶å¼‚å¸¸: {e}")
                    reports = {}

                # ä½¿ç”¨æ ‡å‡†ä¿å­˜æ–¹æ³•ï¼Œç¡®ä¿å­—æ®µç»“æ„ä¸€è‡´
                success = mongodb_manager.save_analysis_report(
                    stock_symbol=result_entry.get('stock_symbol', ''),
                    analysis_results=analysis_results,
                    reports=reports
                )

                if success:
                    print(f"âœ… [MongoDBä¿å­˜] åˆ†æç»“æœå·²ä¿å­˜åˆ°MongoDB: {analysis_id} (åŒ…å« {len(reports)} ä¸ªæŠ¥å‘Š)")
                else:
                    print(f"âŒ [MongoDBä¿å­˜] ä¿å­˜å¤±è´¥: {analysis_id}")

            except Exception as e:
                print(f"âŒ [MongoDBä¿å­˜] ä¿å­˜å¼‚å¸¸: {e}")
                logger.error(f"MongoDBä¿å­˜å¼‚å¸¸: {e}")

        return True

    except Exception as e:
        print(f"âŒ [ä¿å­˜åˆ†æç»“æœ] ä¿å­˜å¤±è´¥: {e}")
        logger.error(f"ä¿å­˜åˆ†æç»“æœå¼‚å¸¸: {e}")
        return False

def show_expanded_detail(result):
    """æ˜¾ç¤ºå±•å¼€çš„è¯¦æƒ…å†…å®¹"""

    # åˆ›å»ºè¯¦æƒ…å®¹å™¨
    with st.container():
        st.markdown("---")
        st.markdown("### ğŸ“Š è¯¦ç»†åˆ†ææŠ¥å‘Š")

        # æ£€æŸ¥æ˜¯å¦æœ‰æŠ¥å‘Šæ•°æ®
        if 'reports' not in result or not result['reports']:
            # å¦‚æœæ²¡æœ‰reportså­—æ®µï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–åˆ†ææ•°æ®
            if result.get('summary'):
                st.subheader("ğŸ“ åˆ†ææ‘˜è¦")
                st.markdown(result['summary'])

            # æ£€æŸ¥æ˜¯å¦æœ‰full_dataä¸­çš„æŠ¥å‘Š
            if 'full_data' in result and result['full_data']:
                full_data = result['full_data']
                if isinstance(full_data, dict):
                    # æ˜¾ç¤ºfull_dataä¸­çš„åˆ†æå†…å®¹
                    analysis_fields = [
                        ('market_report', 'ğŸ“ˆ å¸‚åœºåˆ†æ'),
                        ('fundamentals_report', 'ğŸ’° åŸºæœ¬é¢åˆ†æ'),
                        ('sentiment_report', 'ğŸ’­ æƒ…æ„Ÿåˆ†æ'),
                        ('news_report', 'ğŸ“° æ–°é—»åˆ†æ'),
                        ('risk_assessment', 'âš ï¸ é£é™©è¯„ä¼°'),
                        ('investment_plan', 'ğŸ“‹ æŠ•èµ„å»ºè®®'),
                        ('final_trade_decision', 'ğŸ¯ æœ€ç»ˆå†³ç­–')
                    ]

                    available_reports = []
                    for field_key, field_name in analysis_fields:
                        if field_key in full_data and full_data[field_key]:
                            available_reports.append((field_key, field_name, full_data[field_key]))

                    if available_reports:
                        # åˆ›å»ºæ ‡ç­¾é¡µæ˜¾ç¤ºåˆ†æå†…å®¹
                        tab_names = [name for _, name, _ in available_reports]
                        tabs = st.tabs(tab_names)

                        for i, (tab, (field_key, field_name, content)) in enumerate(zip(tabs, available_reports)):
                            with tab:
                                if isinstance(content, str):
                                    st.markdown(content)
                                elif isinstance(content, dict):
                                    for key, value in content.items():
                                        if value:
                                            st.subheader(key.replace('_', ' ').title())
                                            st.markdown(str(value))
                                else:
                                    st.write(content)
                    else:
                        st.info("æš‚æ— è¯¦ç»†åˆ†ææŠ¥å‘Š")
                else:
                    st.info("æš‚æ— è¯¦ç»†åˆ†ææŠ¥å‘Š")
            else:
                st.info("æš‚æ— è¯¦ç»†åˆ†ææŠ¥å‘Š")
            return

        # è·å–æŠ¥å‘Šæ•°æ®
        reports = result['reports']

        # ä¸ºæŠ¥å‘Šåç§°æ·»åŠ ä¸­æ–‡æ ‡é¢˜å’Œå›¾æ ‡
        report_display_names = {
            'final_trade_decision': 'ğŸ¯ æœ€ç»ˆäº¤æ˜“å†³ç­–',
            'fundamentals_report': 'ğŸ’° åŸºæœ¬é¢åˆ†æ',
            'technical_report': 'ğŸ“ˆ æŠ€æœ¯é¢åˆ†æ',
            'market_sentiment_report': 'ğŸ’­ å¸‚åœºæƒ…ç»ªåˆ†æ',
            'risk_assessment_report': 'âš ï¸ é£é™©è¯„ä¼°',
            'price_target_report': 'ğŸ¯ ç›®æ ‡ä»·æ ¼åˆ†æ',
            'summary_report': 'ğŸ“‹ åˆ†ææ‘˜è¦',
            'news_analysis_report': 'ğŸ“° æ–°é—»åˆ†æ',
            'news_report': 'ğŸ“° æ–°é—»åˆ†æ',
            'market_report': 'ğŸ“ˆ å¸‚åœºåˆ†æ',
            'social_media_report': 'ğŸ“± ç¤¾äº¤åª’ä½“åˆ†æ',
            'bull_state': 'ğŸ‚ å¤šå¤´è§‚ç‚¹',
            'bear_state': 'ğŸ» ç©ºå¤´è§‚ç‚¹',
            'trader_state': 'ğŸ’¼ äº¤æ˜“å‘˜åˆ†æ',
            'invest_judge_state': 'âš–ï¸ æŠ•èµ„åˆ¤æ–­',
            'research_team_state': 'ğŸ”¬ ç ”ç©¶å›¢é˜Ÿè§‚ç‚¹',
            'risk_debate_state': 'âš ï¸ é£é™©ç®¡ç†è®¨è®º',
            'research_team_decision': 'ğŸ”¬ ç ”ç©¶å›¢é˜Ÿå†³ç­–',
            'risk_management_decision': 'ğŸ›¡ï¸ é£é™©ç®¡ç†å†³ç­–',
            'investment_plan': 'ğŸ“‹ æŠ•èµ„è®¡åˆ’',
            'trader_investment_plan': 'ğŸ’¼ äº¤æ˜“å‘˜æŠ•èµ„è®¡åˆ’',
            'investment_debate_state': 'ğŸ’¬ æŠ•èµ„è®¨è®ºçŠ¶æ€'
        }

        # åˆ›å»ºæ ‡ç­¾é¡µæ˜¾ç¤ºä¸åŒçš„æŠ¥å‘Š
        report_tabs = list(reports.keys())
        tab_names = []
        for report_key in report_tabs:
            display_name = report_display_names.get(report_key, f"ğŸ“„ {report_key.replace('_', ' ').title()}")
            tab_names.append(display_name)

        if len(tab_names) == 1:
            # åªæœ‰ä¸€ä¸ªæŠ¥å‘Šï¼Œç›´æ¥æ˜¾ç¤ºå†…å®¹ï¼ˆä¸æ·»åŠ é¢å¤–æ ‡é¢˜ï¼Œé¿å…é‡å¤ï¼‰
            report_content = reports[report_tabs[0]]
            # å¦‚æœæŠ¥å‘Šå†…å®¹å·²ç»åŒ…å«æ ‡é¢˜ï¼Œç›´æ¥æ˜¾ç¤ºï¼›å¦åˆ™æ·»åŠ æ ‡é¢˜
            if not report_content.strip().startswith('#'):
                st.markdown(f"### {tab_names[0]}")
                st.markdown("---")
            st.markdown(report_content)
        else:
            # å¤šä¸ªæŠ¥å‘Šï¼Œä½¿ç”¨æ ‡ç­¾é¡µ
            tabs = st.tabs(tab_names)

            for i, (tab, report_key) in enumerate(zip(tabs, report_tabs)):
                with tab:
                    st.markdown(reports[report_key])

        st.markdown("---")