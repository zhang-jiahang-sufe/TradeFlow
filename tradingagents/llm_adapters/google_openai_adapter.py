"""
Google AI OpenAIå…¼å®¹é€‚é…å™¨
ä¸º TradingAgents æä¾›Google AI (Gemini)æ¨¡å‹çš„ OpenAI å…¼å®¹æ¥å£
è§£å†³Googleæ¨¡å‹å·¥å…·è°ƒç”¨æ ¼å¼ä¸åŒ¹é…çš„é—®é¢˜
"""

import os
from typing import Any, Dict, List, Optional, Union, Sequence
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.tools import BaseTool
from langchain_core.messages import BaseMessage, AIMessage, HumanMessage, SystemMessage
from langchain_core.outputs import LLMResult
from pydantic import Field, SecretStr
from ..config.config_manager import token_tracker

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('agents')


class ChatGoogleOpenAI(ChatGoogleGenerativeAI):
    """
    Google AI OpenAI å…¼å®¹é€‚é…å™¨
    ç»§æ‰¿ ChatGoogleGenerativeAIï¼Œä¼˜åŒ–å·¥å…·è°ƒç”¨å’Œå†…å®¹æ ¼å¼å¤„ç†
    è§£å†³Googleæ¨¡å‹å·¥å…·è°ƒç”¨è¿”å›æ ¼å¼ä¸ç³»ç»ŸæœŸæœ›ä¸åŒ¹é…çš„é—®é¢˜
    """

    def __init__(self, base_url: Optional[str] = None, **kwargs):
        """
        åˆå§‹åŒ– Google AI OpenAI å…¼å®¹å®¢æˆ·ç«¯

        Args:
            base_url: è‡ªå®šä¹‰ API ç«¯ç‚¹ï¼ˆå¯é€‰ï¼‰
                     å¦‚æœæä¾›ï¼Œå°†é€šè¿‡ client_options ä¼ é€’ç»™ Google AI SDK
                     æ”¯æŒæ ¼å¼ï¼š
                     - https://generativelanguage.googleapis.com/v1beta
                     - https://generativelanguage.googleapis.com/v1 (è‡ªåŠ¨è½¬æ¢ä¸º v1beta)
                     - è‡ªå®šä¹‰ä»£ç†åœ°å€
            **kwargs: å…¶ä»–å‚æ•°
        """

        # ğŸ” [DEBUG] è¯»å–ç¯å¢ƒå˜é‡å‰çš„æ—¥å¿—
        logger.info("ğŸ” [Googleåˆå§‹åŒ–] å¼€å§‹åˆå§‹åŒ– ChatGoogleOpenAI")
        logger.info(f"ğŸ” [Googleåˆå§‹åŒ–] kwargs ä¸­æ˜¯å¦åŒ…å« google_api_key: {'google_api_key' in kwargs}")
        logger.info(f"ğŸ” [Googleåˆå§‹åŒ–] ä¼ å…¥çš„ base_url: {base_url}")

        # è®¾ç½® Google AI çš„é»˜è®¤é…ç½®
        kwargs.setdefault("temperature", 0.1)
        kwargs.setdefault("max_tokens", 2000)

        # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨ kwargs ä¸­ä¼ å…¥çš„ API Keyï¼ˆæ¥è‡ªæ•°æ®åº“é…ç½®ï¼‰
        google_api_key = kwargs.get("google_api_key")

        # å¦‚æœ kwargs ä¸­æ²¡æœ‰ API Keyï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–
        if not google_api_key:
            # å¯¼å…¥ API Key éªŒè¯å·¥å…·
            try:
                from app.utils.api_key_utils import is_valid_api_key
            except ImportError:
                def is_valid_api_key(key):
                    if not key or len(key) <= 10:
                        return False
                    if key.startswith('your_') or key.startswith('your-'):
                        return False
                    if key.endswith('_here') or key.endswith('-here'):
                        return False
                    if '...' in key:
                        return False
                    return True

            # æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­çš„ API Key
            env_api_key = os.getenv("GOOGLE_API_KEY")
            logger.info(f"ğŸ” [Googleåˆå§‹åŒ–] ä»ç¯å¢ƒå˜é‡è¯»å– GOOGLE_API_KEY: {'æœ‰å€¼' if env_api_key else 'ç©º'}")

            # éªŒè¯ç¯å¢ƒå˜é‡ä¸­çš„ API Key æ˜¯å¦æœ‰æ•ˆï¼ˆæ’é™¤å ä½ç¬¦ï¼‰
            if env_api_key and is_valid_api_key(env_api_key):
                logger.info(f"âœ… [Googleåˆå§‹åŒ–] ç¯å¢ƒå˜é‡ä¸­çš„ API Key æœ‰æ•ˆï¼Œé•¿åº¦: {len(env_api_key)}, å‰10ä½: {env_api_key[:10]}...")
                google_api_key = env_api_key
            elif env_api_key:
                logger.warning("âš ï¸ [Googleåˆå§‹åŒ–] ç¯å¢ƒå˜é‡ä¸­çš„ API Key æ— æ•ˆï¼ˆå¯èƒ½æ˜¯å ä½ç¬¦ï¼‰ï¼Œå°†è¢«å¿½ç•¥")
                google_api_key = None
            else:
                logger.warning("âš ï¸ [Googleåˆå§‹åŒ–] GOOGLE_API_KEY ç¯å¢ƒå˜é‡ä¸ºç©º")
                google_api_key = None
        else:
            logger.info("âœ… [Googleåˆå§‹åŒ–] ä½¿ç”¨ kwargs ä¸­ä¼ å…¥çš„ API Keyï¼ˆæ¥è‡ªæ•°æ®åº“é…ç½®ï¼‰")

        logger.info(f"ğŸ” [Googleåˆå§‹åŒ–] æœ€ç»ˆä½¿ç”¨çš„ API Key: {'æœ‰å€¼' if google_api_key else 'ç©º'}")

        if not google_api_key:
            logger.error("âŒ [Googleåˆå§‹åŒ–] API Key æ£€æŸ¥å¤±è´¥ï¼Œå³å°†æŠ›å‡ºå¼‚å¸¸")
            raise ValueError(
                "Google API key not found. Please configure API key in web interface "
                "(Settings -> LLM Providers) or set GOOGLE_API_KEY environment variable."
            )

        kwargs["google_api_key"] = google_api_key

        # ğŸ”§ å¤„ç†è‡ªå®šä¹‰ base_url
        if base_url:
            # ç§»é™¤æœ«å°¾çš„æ–œæ 
            base_url = base_url.rstrip('/')
            logger.info(f"ğŸ” [Googleåˆå§‹åŒ–] å¤„ç† base_url: {base_url}")

            # ğŸ” æ£€æµ‹æ˜¯å¦æ˜¯ Google å®˜æ–¹åŸŸå
            is_google_official = 'generativelanguage.googleapis.com' in base_url

            if is_google_official:
                # âœ… Google å®˜æ–¹åŸŸåï¼šæå–åŸŸåéƒ¨åˆ†ï¼ŒSDK ä¼šè‡ªåŠ¨æ·»åŠ  /v1beta
                # ä¾‹å¦‚ï¼šhttps://generativelanguage.googleapis.com/v1beta -> https://generativelanguage.googleapis.com
                #      https://generativelanguage.googleapis.com/v1 -> https://generativelanguage.googleapis.com
                if base_url.endswith('/v1beta'):
                    api_endpoint = base_url[:-7]  # ç§»é™¤ /v1beta (7ä¸ªå­—ç¬¦)
                    logger.info(f"ğŸ” [Googleå®˜æ–¹] ä» base_url æå–åŸŸå: {api_endpoint}")
                elif base_url.endswith('/v1'):
                    api_endpoint = base_url[:-3]  # ç§»é™¤ /v1 (3ä¸ªå­—ç¬¦)
                    logger.info(f"ğŸ” [Googleå®˜æ–¹] ä» base_url æå–åŸŸå: {api_endpoint}")
                else:
                    # å¦‚æœæ²¡æœ‰ç‰ˆæœ¬åç¼€ï¼Œç›´æ¥ä½¿ç”¨
                    api_endpoint = base_url
                    logger.info(f"ğŸ” [Googleå®˜æ–¹] ä½¿ç”¨å®Œæ•´ base_url ä½œä¸ºåŸŸå: {api_endpoint}")

                logger.info(f"âœ… [Googleå®˜æ–¹] SDK ä¼šè‡ªåŠ¨æ·»åŠ  /v1beta è·¯å¾„")
            else:
                # ğŸ”„ ä¸­è½¬åœ°å€ï¼šç›´æ¥ä½¿ç”¨å®Œæ•´ URLï¼Œä¸è®© SDK æ·»åŠ  /v1beta
                # ä¸­è½¬æœåŠ¡é€šå¸¸å·²ç»åŒ…å«äº†å®Œæ•´çš„è·¯å¾„æ˜ å°„
                api_endpoint = base_url
                logger.info(f"ğŸ”„ [ä¸­è½¬åœ°å€] æ£€æµ‹åˆ°éå®˜æ–¹åŸŸåï¼Œä½¿ç”¨å®Œæ•´ URL: {api_endpoint}")
                logger.info(f"   ä¸­è½¬æœåŠ¡é€šå¸¸å·²åŒ…å«å®Œæ•´è·¯å¾„ï¼Œä¸éœ€è¦ SDK æ·»åŠ  /v1beta")

            # é€šè¿‡ client_options ä¼ é€’è‡ªå®šä¹‰ç«¯ç‚¹
            # å‚è€ƒ: https://github.com/langchain-ai/langchain-google/issues/783
            kwargs["client_options"] = {"api_endpoint": api_endpoint}
            logger.info(f"âœ… [Googleåˆå§‹åŒ–] è®¾ç½® client_options.api_endpoint: {api_endpoint}")
        else:
            logger.info(f"ğŸ” [Googleåˆå§‹åŒ–] æœªæä¾› base_urlï¼Œä½¿ç”¨é»˜è®¤ç«¯ç‚¹")

        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(**kwargs)

        logger.info(f"âœ… Google AI OpenAI å…¼å®¹é€‚é…å™¨åˆå§‹åŒ–æˆåŠŸ")
        logger.info(f"   æ¨¡å‹: {kwargs.get('model', 'gemini-pro')}")
        logger.info(f"   æ¸©åº¦: {kwargs.get('temperature', 0.1)}")
        logger.info(f"   æœ€å¤§Token: {kwargs.get('max_tokens', 2000)}")
        if base_url:
            logger.info(f"   è‡ªå®šä¹‰ç«¯ç‚¹: {base_url}")

    @property
    def model_name(self) -> str:
        """
        è¿”å›æ¨¡å‹åç§°ï¼ˆå…¼å®¹æ€§å±æ€§ï¼‰
        ç§»é™¤ 'models/' å‰ç¼€ï¼Œè¿”å›çº¯æ¨¡å‹åç§°
        """
        model = self.model
        if model and model.startswith("models/"):
            return model[7:]  # ç§»é™¤ "models/" å‰ç¼€
        return model or "unknown"
    
    def _generate(self, messages: List[BaseMessage], stop: Optional[List[str]] = None, **kwargs) -> LLMResult:
        """é‡å†™ç”Ÿæˆæ–¹æ³•ï¼Œä¼˜åŒ–å·¥å…·è°ƒç”¨å¤„ç†å’Œå†…å®¹æ ¼å¼"""

        try:
            # è°ƒç”¨çˆ¶ç±»çš„ç”Ÿæˆæ–¹æ³•
            result = super()._generate(messages, stop, **kwargs)

            # ä¼˜åŒ–è¿”å›å†…å®¹æ ¼å¼
            # æ³¨æ„ï¼šresult.generations æ˜¯äºŒç»´åˆ—è¡¨ [[ChatGeneration]]
            if result and result.generations:
                for generation_list in result.generations:
                    if isinstance(generation_list, list):
                        for generation in generation_list:
                            if hasattr(generation, 'message') and generation.message:
                                # ä¼˜åŒ–æ¶ˆæ¯å†…å®¹æ ¼å¼
                                self._optimize_message_content(generation.message)
                    else:
                        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœä¸æ˜¯åˆ—è¡¨ï¼Œç›´æ¥å¤„ç†
                        if hasattr(generation_list, 'message') and generation_list.message:
                            self._optimize_message_content(generation_list.message)

            # è¿½è¸ª token ä½¿ç”¨é‡
            self._track_token_usage(result, kwargs)

            return result

        except Exception as e:
            logger.error(f"âŒ Google AI ç”Ÿæˆå¤±è´¥: {e}")
            logger.exception(e)  # æ‰“å°å®Œæ•´çš„å †æ ˆè·Ÿè¸ª

            # æ£€æŸ¥æ˜¯å¦ä¸º API Key æ— æ•ˆé”™è¯¯
            error_str = str(e)
            if 'API_KEY_INVALID' in error_str or 'API key not valid' in error_str:
                error_content = "Google AI API Key æ— æ•ˆæˆ–æœªé…ç½®ã€‚\n\nè¯·æ£€æŸ¥ï¼š\n1. GOOGLE_API_KEY ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®é…ç½®\n2. API Key æ˜¯å¦æœ‰æ•ˆï¼ˆè®¿é—® https://ai.google.dev/ è·å–ï¼‰\n3. æ˜¯å¦å¯ç”¨äº† Gemini API\n\nå»ºè®®ï¼šä½¿ç”¨å…¶ä»– AI æ¨¡å‹ï¼ˆå¦‚é˜¿é‡Œç™¾ç‚¼ã€DeepSeekï¼‰"
            elif 'Connection' in error_str or 'Network' in error_str:
                error_content = f"Google AI ç½‘ç»œè¿æ¥å¤±è´¥: {error_str}\n\nè¯·æ£€æŸ¥ï¼š\n1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n2. æ˜¯å¦éœ€è¦ç§‘å­¦ä¸Šç½‘\n3. é˜²ç«å¢™è®¾ç½®"
            else:
                error_content = f"Google AI è°ƒç”¨å¤±è´¥: {error_str}\n\nè¯·æ£€æŸ¥é…ç½®æˆ–ä½¿ç”¨å…¶ä»– AI æ¨¡å‹"

            # è¿”å›ä¸€ä¸ªåŒ…å«é”™è¯¯ä¿¡æ¯çš„ç»“æœï¼Œè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
            from langchain_core.outputs import ChatGeneration
            error_message = AIMessage(content=error_content)
            error_generation = ChatGeneration(message=error_message)
            return LLMResult(generations=[[error_generation]])
    
    def _optimize_message_content(self, message: BaseMessage):
        """ä¼˜åŒ–æ¶ˆæ¯å†…å®¹æ ¼å¼ï¼Œç¡®ä¿åŒ…å«æ–°é—»ç‰¹å¾å…³é”®è¯"""
        
        if not isinstance(message, AIMessage) or not message.content:
            return
        
        content = message.content
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·è°ƒç”¨è¿”å›çš„æ–°é—»å†…å®¹
        if self._is_news_content(content):
            # ä¼˜åŒ–æ–°é—»å†…å®¹æ ¼å¼ï¼Œæ·»åŠ å¿…è¦çš„å…³é”®è¯
            optimized_content = self._enhance_news_content(content)
            message.content = optimized_content
            
            logger.debug(f"ğŸ”§ [Googleé€‚é…å™¨] ä¼˜åŒ–æ–°é—»å†…å®¹æ ¼å¼")
            logger.debug(f"   åŸå§‹é•¿åº¦: {len(content)} å­—ç¬¦")
            logger.debug(f"   ä¼˜åŒ–åé•¿åº¦: {len(optimized_content)} å­—ç¬¦")
    
    def _is_news_content(self, content: str) -> bool:
        """åˆ¤æ–­å†…å®¹æ˜¯å¦ä¸ºæ–°é—»å†…å®¹"""
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ–°é—»ç›¸å…³çš„å…³é”®è¯
        news_indicators = [
            "è‚¡ç¥¨", "å…¬å¸", "å¸‚åœº", "æŠ•èµ„", "è´¢ç»", "è¯åˆ¸", "äº¤æ˜“",
            "æ¶¨è·Œ", "ä¸šç»©", "è´¢æŠ¥", "åˆ†æ", "é¢„æµ‹", "æ¶ˆæ¯", "å…¬å‘Š"
        ]
        
        return any(indicator in content for indicator in news_indicators) and len(content) > 200
    
    def _enhance_news_content(self, content: str) -> str:
        """å¢å¼ºæ–°é—»å†…å®¹ï¼Œæ·»åŠ å¿…è¦çš„æ ¼å¼åŒ–ä¿¡æ¯"""
        
        import datetime
        current_date = datetime.datetime.now().strftime("%Y-%m-%d")
        
        # å¦‚æœå†…å®¹ç¼ºå°‘å¿…è¦çš„æ–°é—»ç‰¹å¾ï¼Œæ·»åŠ å®ƒä»¬
        enhanced_content = content
        
        # æ·»åŠ å‘å¸ƒæ—¶é—´ä¿¡æ¯ï¼ˆå¦‚æœç¼ºå°‘ï¼‰
        if "å‘å¸ƒæ—¶é—´" not in content and "æ—¶é—´" not in content:
            enhanced_content = f"å‘å¸ƒæ—¶é—´: {current_date}\n\n{enhanced_content}"
        
        # æ·»åŠ æ–°é—»æ ‡é¢˜æ ‡è¯†ï¼ˆå¦‚æœç¼ºå°‘ï¼‰
        if "æ–°é—»æ ‡é¢˜" not in content and "æ ‡é¢˜" not in content:
            # å°è¯•ä»å†…å®¹ä¸­æå–ç¬¬ä¸€è¡Œä½œä¸ºæ ‡é¢˜
            lines = enhanced_content.split('\n')
            if lines:
                first_line = lines[0].strip()
                if len(first_line) < 100:  # å¯èƒ½æ˜¯æ ‡é¢˜
                    enhanced_content = f"æ–°é—»æ ‡é¢˜: {first_line}\n\n{enhanced_content}"
        
        # æ·»åŠ æ–‡ç« æ¥æºä¿¡æ¯ï¼ˆå¦‚æœç¼ºå°‘ï¼‰
        if "æ–‡ç« æ¥æº" not in content and "æ¥æº" not in content:
            enhanced_content = f"{enhanced_content}\n\næ–‡ç« æ¥æº: Google AI æ™ºèƒ½åˆ†æ"
        
        return enhanced_content
    
    def _track_token_usage(self, result: LLMResult, kwargs: Dict[str, Any]):
        """è¿½è¸ª token ä½¿ç”¨é‡"""
        
        try:
            # ä»ç»“æœä¸­æå– token ä½¿ç”¨ä¿¡æ¯
            if hasattr(result, 'llm_output') and result.llm_output:
                token_usage = result.llm_output.get('token_usage', {})
                
                input_tokens = token_usage.get('prompt_tokens', 0)
                output_tokens = token_usage.get('completion_tokens', 0)
                
                if input_tokens > 0 or output_tokens > 0:
                    # ç”Ÿæˆä¼šè¯ID
                    session_id = kwargs.get('session_id', f"google_openai_{hash(str(kwargs))%10000}")
                    analysis_type = kwargs.get('analysis_type', 'stock_analysis')
                    
                    # ä½¿ç”¨ TokenTracker è®°å½•ä½¿ç”¨é‡
                    token_tracker.track_usage(
                        provider="google",
                        model_name=self.model,
                        input_tokens=input_tokens,
                        output_tokens=output_tokens,
                        session_id=session_id,
                        analysis_type=analysis_type
                    )
                    
                    logger.debug(f"ğŸ“Š [Googleé€‚é…å™¨] Tokenä½¿ç”¨é‡: è¾“å…¥={input_tokens}, è¾“å‡º={output_tokens}")
                    
        except Exception as track_error:
            # token è¿½è¸ªå¤±è´¥ä¸åº”è¯¥å½±å“ä¸»è¦åŠŸèƒ½
            logger.error(f"âš ï¸ Googleé€‚é…å™¨ Token è¿½è¸ªå¤±è´¥: {track_error}")


# æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
GOOGLE_OPENAI_MODELS = {
    # Gemini 2.5 ç³»åˆ— - æœ€æ–°éªŒè¯æ¨¡å‹
    "gemini-2.5-pro": {
        "description": "Gemini 2.5 Pro - æœ€æ–°æ——èˆ°æ¨¡å‹ï¼ŒåŠŸèƒ½å¼ºå¤§ (16.68s)",
        "context_length": 32768,
        "supports_function_calling": True,
        "recommended_for": ["å¤æ‚æ¨ç†", "ä¸“ä¸šåˆ†æ", "é«˜è´¨é‡è¾“å‡º"],
        "avg_response_time": 16.68
    },
    "gemini-2.5-flash": {
        "description": "Gemini 2.5 Flash - æœ€æ–°å¿«é€Ÿæ¨¡å‹ (2.73s)",
        "context_length": 32768,
        "supports_function_calling": True,
        "recommended_for": ["å¿«é€Ÿå“åº”", "å®æ—¶åˆ†æ", "é«˜é¢‘ä½¿ç”¨"],
        "avg_response_time": 2.73
    },
    "gemini-2.5-flash-lite-preview-06-17": {
        "description": "Gemini 2.5 Flash Lite Preview - è¶…å¿«å“åº” (1.45s)",
        "context_length": 32768,
        "supports_function_calling": True,
        "recommended_for": ["è¶…å¿«å“åº”", "å®æ—¶äº¤äº’", "é«˜é¢‘è°ƒç”¨"],
        "avg_response_time": 1.45
    },
    # Gemini 2.0 ç³»åˆ—
    "gemini-2.0-flash": {
        "description": "Gemini 2.0 Flash - æ–°ä¸€ä»£å¿«é€Ÿæ¨¡å‹ (1.87s)",
        "context_length": 32768,
        "supports_function_calling": True,
        "recommended_for": ["å¿«é€Ÿå“åº”", "å®æ—¶åˆ†æ"],
        "avg_response_time": 1.87
    },
    # Gemini 1.5 ç³»åˆ—
    "gemini-1.5-pro": {
        "description": "Gemini 1.5 Pro - å¼ºå¤§æ€§èƒ½ï¼Œå¹³è¡¡é€‰æ‹© (2.25s)",
        "context_length": 32768,
        "supports_function_calling": True,
        "recommended_for": ["å¤æ‚åˆ†æ", "ä¸“ä¸šä»»åŠ¡", "æ·±åº¦æ€è€ƒ"],
        "avg_response_time": 2.25
    },
    "gemini-1.5-flash": {
        "description": "Gemini 1.5 Flash - å¿«é€Ÿå“åº”ï¼Œå¤‡ç”¨é€‰æ‹© (2.87s)",
        "context_length": 32768,
        "supports_function_calling": True,
        "recommended_for": ["å¿«é€Ÿä»»åŠ¡", "æ—¥å¸¸å¯¹è¯", "ç®€å•åˆ†æ"],
        "avg_response_time": 2.87
    },
    # ç»å…¸æ¨¡å‹
    "gemini-pro": {
        "description": "Gemini Pro - ç»å…¸æ¨¡å‹ï¼Œç¨³å®šå¯é ",
        "context_length": 32768,
        "supports_function_calling": True,
        "recommended_for": ["é€šç”¨ä»»åŠ¡", "ç¨³å®šæ€§è¦æ±‚é«˜çš„åœºæ™¯"]
    }
}


def get_available_google_models() -> Dict[str, Dict[str, Any]]:
    """è·å–å¯ç”¨çš„ Google AI æ¨¡å‹åˆ—è¡¨"""
    return GOOGLE_OPENAI_MODELS


def create_google_openai_llm(
    model: str = "gemini-2.5-flash-lite-preview-06-17",
    google_api_key: Optional[str] = None,
    base_url: Optional[str] = None,
    temperature: float = 0.1,
    max_tokens: int = 2000,
    **kwargs
) -> ChatGoogleOpenAI:
    """
    åˆ›å»º Google AI OpenAI å…¼å®¹ LLM å®ä¾‹çš„ä¾¿æ·å‡½æ•°

    Args:
        model: æ¨¡å‹åç§°
        google_api_key: Google API Key
        base_url: è‡ªå®šä¹‰ API ç«¯ç‚¹ï¼ˆå¯é€‰ï¼‰
        temperature: æ¸©åº¦å‚æ•°
        max_tokens: æœ€å¤§ token æ•°
        **kwargs: å…¶ä»–å‚æ•°

    Returns:
        ChatGoogleOpenAI å®ä¾‹
    """

    return ChatGoogleOpenAI(
        model=model,
        google_api_key=google_api_key,
        base_url=base_url,
        temperature=temperature,
        max_tokens=max_tokens,
        **kwargs
    )


def test_google_openai_connection(
    model: str = "gemini-2.0-flash",
    google_api_key: Optional[str] = None
) -> bool:
    """æµ‹è¯• Google AI OpenAI å…¼å®¹æ¥å£è¿æ¥"""
    
    try:
        logger.info(f"ğŸ§ª æµ‹è¯• Google AI OpenAI å…¼å®¹æ¥å£è¿æ¥")
        logger.info(f"   æ¨¡å‹: {model}")
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        llm = create_google_openai_llm(
            model=model,
            google_api_key=google_api_key,
            max_tokens=50
        )
        
        # å‘é€æµ‹è¯•æ¶ˆæ¯
        response = llm.invoke("ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚")
        
        if response and hasattr(response, 'content') and response.content:
            logger.info(f"âœ… Google AI OpenAI å…¼å®¹æ¥å£è¿æ¥æˆåŠŸ")
            logger.info(f"   å“åº”: {response.content[:100]}...")
            return True
        else:
            logger.error(f"âŒ Google AI OpenAI å…¼å®¹æ¥å£å“åº”ä¸ºç©º")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Google AI OpenAI å…¼å®¹æ¥å£è¿æ¥å¤±è´¥: {e}")
        return False


def test_google_openai_function_calling(
    model: str = "gemini-2.5-flash-lite-preview-06-17",
    google_api_key: Optional[str] = None
) -> bool:
    """æµ‹è¯• Google AI OpenAI å…¼å®¹æ¥å£çš„ Function Calling"""
    
    try:
        logger.info(f"ğŸ§ª æµ‹è¯• Google AI Function Calling")
        logger.info(f"   æ¨¡å‹: {model}")
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        llm = create_google_openai_llm(
            model=model,
            google_api_key=google_api_key,
            max_tokens=200
        )
        
        # å®šä¹‰æµ‹è¯•å·¥å…·
        from langchain_core.tools import tool
        
        @tool
        def test_news_tool(query: str) -> str:
            """æµ‹è¯•æ–°é—»å·¥å…·ï¼Œè¿”å›æ¨¡æ‹Ÿæ–°é—»å†…å®¹"""
            return f"""å‘å¸ƒæ—¶é—´: 2024-01-15
æ–°é—»æ ‡é¢˜: {query}ç›¸å…³å¸‚åœºåŠ¨æ€
æ–‡ç« æ¥æº: æµ‹è¯•æ–°é—»æº

è¿™æ˜¯ä¸€æ¡å…³äº{query}çš„æµ‹è¯•æ–°é—»å†…å®¹ã€‚è¯¥å…¬å¸è¿‘æœŸè¡¨ç°è‰¯å¥½ï¼Œå¸‚åœºå‰æ™¯çœ‹å¥½ã€‚
æŠ•èµ„è€…å¯¹æ­¤è¡¨ç¤ºå…³æ³¨ï¼Œåˆ†æå¸ˆç»™å‡ºç§¯æè¯„ä»·ã€‚"""
        
        # ç»‘å®šå·¥å…·
        llm_with_tools = llm.bind_tools([test_news_tool])
        
        # æµ‹è¯•å·¥å…·è°ƒç”¨
        response = llm_with_tools.invoke("è¯·ä½¿ç”¨test_news_toolæŸ¥è¯¢'è‹¹æœå…¬å¸'çš„æ–°é—»")
        
        logger.info(f"âœ… Google AI Function Calling æµ‹è¯•å®Œæˆ")
        logger.info(f"   å“åº”ç±»å‹: {type(response)}")
        
        if hasattr(response, 'tool_calls') and response.tool_calls:
            logger.info(f"   å·¥å…·è°ƒç”¨æ•°é‡: {len(response.tool_calls)}")
            return True
        else:
            logger.info(f"   å“åº”å†…å®¹: {getattr(response, 'content', 'No content')}")
            return True  # å³ä½¿æ²¡æœ‰å·¥å…·è°ƒç”¨ä¹Ÿç®—æˆåŠŸï¼Œå› ä¸ºæ¨¡å‹å¯èƒ½é€‰æ‹©ä¸è°ƒç”¨å·¥å…·
            
    except Exception as e:
        logger.error(f"âŒ Google AI Function Calling æµ‹è¯•å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    """æµ‹è¯•è„šæœ¬"""
    logger.info(f"ğŸ§ª Google AI OpenAI å…¼å®¹é€‚é…å™¨æµ‹è¯•")
    logger.info(f"=" * 50)
    
    # æµ‹è¯•è¿æ¥
    connection_ok = test_google_openai_connection()
    
    if connection_ok:
        # æµ‹è¯• Function Calling
        function_calling_ok = test_google_openai_function_calling()
        
        if function_calling_ok:
            logger.info(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Google AI OpenAI å…¼å®¹é€‚é…å™¨å·¥ä½œæ­£å¸¸")
        else:
            logger.error(f"\nâš ï¸ Function Calling æµ‹è¯•å¤±è´¥")
    else:
        logger.error(f"\nâŒ è¿æ¥æµ‹è¯•å¤±è´¥")