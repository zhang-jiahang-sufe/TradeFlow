#!/usr/bin/env python3
"""
æ•°æ®æºç®¡ç†å™¨
ç»Ÿä¸€ç®¡ç†ä¸­å›½è‚¡ç¥¨æ•°æ®æºçš„é€‰æ‹©å’Œåˆ‡æ¢ï¼Œæ”¯æŒTushareã€AKShareã€BaoStockç­‰
"""

import os
import time
from typing import Dict, List, Optional, Any
from enum import Enum
import warnings
import pandas as pd
import numpy as np

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('agents')
warnings.filterwarnings('ignore')

# å¯¼å…¥ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
from tradingagents.utils.logging_init import setup_dataflow_logging
logger = setup_dataflow_logging()

# å¯¼å…¥ç»Ÿä¸€æ•°æ®æºç¼–ç 
from tradingagents.constants import DataSourceCode


class ChinaDataSource(Enum):
    """
    ä¸­å›½è‚¡ç¥¨æ•°æ®æºæšä¸¾

    æ³¨æ„ï¼šè¿™ä¸ªæšä¸¾ä¸ tradingagents.constants.DataSourceCode ä¿æŒåŒæ­¥
    å€¼ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®æºç¼–ç 
    """
    MONGODB = DataSourceCode.MONGODB  # MongoDBæ•°æ®åº“ç¼“å­˜ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    TUSHARE = DataSourceCode.TUSHARE
    AKSHARE = DataSourceCode.AKSHARE
    BAOSTOCK = DataSourceCode.BAOSTOCK


class USDataSource(Enum):
    """
    ç¾è‚¡æ•°æ®æºæšä¸¾

    æ³¨æ„ï¼šè¿™ä¸ªæšä¸¾ä¸ tradingagents.constants.DataSourceCode ä¿æŒåŒæ­¥
    å€¼ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®æºç¼–ç 
    """
    MONGODB = DataSourceCode.MONGODB  # MongoDBæ•°æ®åº“ç¼“å­˜ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    YFINANCE = DataSourceCode.YFINANCE  # Yahoo Financeï¼ˆå…è´¹ï¼Œè‚¡ç¥¨ä»·æ ¼å’ŒæŠ€æœ¯æŒ‡æ ‡ï¼‰
    ALPHA_VANTAGE = DataSourceCode.ALPHA_VANTAGE  # Alpha Vantageï¼ˆåŸºæœ¬é¢å’Œæ–°é—»ï¼‰
    FINNHUB = DataSourceCode.FINNHUB  # Finnhubï¼ˆå¤‡ç”¨æ•°æ®æºï¼‰





class DataSourceManager:
    """æ•°æ®æºç®¡ç†å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®æºç®¡ç†å™¨"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨MongoDBç¼“å­˜
        self.use_mongodb_cache = self._check_mongodb_enabled()

        self.default_source = self._get_default_source()
        self.available_sources = self._check_available_sources()
        self.current_source = self.default_source

        # åˆå§‹åŒ–ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨
        self.cache_manager = None
        self.cache_enabled = False
        try:
            from .cache import get_cache
            self.cache_manager = get_cache()
            self.cache_enabled = True
            logger.info(f"âœ… ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨å·²å¯ç”¨")
        except Exception as e:
            logger.warning(f"âš ï¸ ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

        logger.info(f"ğŸ“Š æ•°æ®æºç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   MongoDBç¼“å­˜: {'âœ… å·²å¯ç”¨' if self.use_mongodb_cache else 'âŒ æœªå¯ç”¨'}")
        logger.info(f"   ç»Ÿä¸€ç¼“å­˜: {'âœ… å·²å¯ç”¨' if self.cache_enabled else 'âŒ æœªå¯ç”¨'}")
        logger.info(f"   é»˜è®¤æ•°æ®æº: {self.default_source.value}")
        logger.info(f"   å¯ç”¨æ•°æ®æº: {[s.value for s in self.available_sources]}")

    def _check_mongodb_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨MongoDBç¼“å­˜"""
        from tradingagents.config.runtime_settings import use_app_cache_enabled
        return use_app_cache_enabled()

    def _get_data_source_priority_order(self, symbol: Optional[str] = None) -> List[ChinaDataSource]:
        """
        ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆç”¨äºé™çº§ï¼‰

        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼Œç”¨äºè¯†åˆ«å¸‚åœºç±»å‹ï¼ˆAè‚¡/ç¾è‚¡/æ¸¯è‚¡ï¼‰

        Returns:
            æŒ‰ä¼˜å…ˆçº§æ’åºçš„æ•°æ®æºåˆ—è¡¨ï¼ˆä¸åŒ…å«MongoDBï¼Œå› ä¸ºMongoDBæ˜¯æœ€é«˜ä¼˜å…ˆçº§ï¼‰
        """
        # ğŸ”¥ è¯†åˆ«å¸‚åœºç±»å‹
        market_category = self._identify_market_category(symbol)

        try:
            # ğŸ”¥ ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®ï¼ˆä½¿ç”¨åŒæ­¥å®¢æˆ·ç«¯ï¼‰
            from app.core.database import get_mongo_db_sync
            db = get_mongo_db_sync()
            config_collection = db.system_configs

            # è·å–æœ€æ–°çš„æ¿€æ´»é…ç½®
            config_data = config_collection.find_one(
                {"is_active": True},
                sort=[("version", -1)]
            )

            if config_data and config_data.get('data_source_configs'):
                data_source_configs = config_data.get('data_source_configs', [])

                # ğŸ”¥ è¿‡æ»¤å‡ºå¯ç”¨çš„æ•°æ®æºï¼Œå¹¶æŒ‰å¸‚åœºåˆ†ç±»è¿‡æ»¤
                enabled_sources = []
                for ds in data_source_configs:
                    if not ds.get('enabled', True):
                        continue

                    # æ£€æŸ¥æ•°æ®æºæ˜¯å¦å±äºå½“å‰å¸‚åœºåˆ†ç±»
                    market_categories = ds.get('market_categories', [])
                    if market_categories and market_category:
                        # å¦‚æœæ•°æ®æºé…ç½®äº†å¸‚åœºåˆ†ç±»ï¼Œåªé€‰æ‹©åŒ¹é…çš„æ•°æ®æº
                        if market_category not in market_categories:
                            continue

                    enabled_sources.append(ds)

                # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆæ•°å­—è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
                enabled_sources.sort(key=lambda x: x.get('priority', 0), reverse=True)

                # è½¬æ¢ä¸º ChinaDataSource æšä¸¾ï¼ˆä½¿ç”¨ç»Ÿä¸€ç¼–ç ï¼‰
                source_mapping = {
                    DataSourceCode.TUSHARE: ChinaDataSource.TUSHARE,
                    DataSourceCode.AKSHARE: ChinaDataSource.AKSHARE,
                    DataSourceCode.BAOSTOCK: ChinaDataSource.BAOSTOCK,
                }

                result = []
                for ds in enabled_sources:
                    ds_type = ds.get('type', '').lower()
                    if ds_type in source_mapping:
                        source = source_mapping[ds_type]
                        # æ’é™¤ MongoDBï¼ˆMongoDB æ˜¯æœ€é«˜ä¼˜å…ˆçº§ï¼Œä¸å‚ä¸é™çº§ï¼‰
                        if source != ChinaDataSource.MONGODB and source in self.available_sources:
                            result.append(source)

                if result:
                    logger.info(f"âœ… [æ•°æ®æºä¼˜å…ˆçº§] å¸‚åœº={market_category or 'å…¨éƒ¨'}, ä»æ•°æ®åº“è¯»å–: {[s.value for s in result]}")
                    return result
                else:
                    logger.warning(f"âš ï¸ [æ•°æ®æºä¼˜å…ˆçº§] å¸‚åœº={market_category or 'å…¨éƒ¨'}, æ•°æ®åº“é…ç½®ä¸­æ²¡æœ‰å¯ç”¨çš„æ•°æ®æºï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
            else:
                logger.warning("âš ï¸ [æ•°æ®æºä¼˜å…ˆçº§] æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®æºé…ç½®ï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
        except Exception as e:
            logger.warning(f"âš ï¸ [æ•°æ®æºä¼˜å…ˆçº§] ä»æ•°æ®åº“è¯»å–å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")

        # ğŸ”¥ å›é€€åˆ°é»˜è®¤é¡ºåºï¼ˆå…¼å®¹æ€§ï¼‰
        # é»˜è®¤é¡ºåºï¼šAKShare > Tushare > BaoStock
        default_order = [
            ChinaDataSource.AKSHARE,
            ChinaDataSource.TUSHARE,
            ChinaDataSource.BAOSTOCK,
        ]
        # åªè¿”å›å¯ç”¨çš„æ•°æ®æº
        return [s for s in default_order if s in self.available_sources]

    def _identify_market_category(self, symbol: Optional[str]) -> Optional[str]:
        """
        è¯†åˆ«è‚¡ç¥¨ä»£ç æ‰€å±çš„å¸‚åœºåˆ†ç±»

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            å¸‚åœºåˆ†ç±»IDï¼ˆa_shares/us_stocks/hk_stocksï¼‰ï¼Œå¦‚æœæ— æ³•è¯†åˆ«åˆ™è¿”å›None
        """
        if not symbol:
            return None

        try:
            from tradingagents.utils.stock_utils import StockUtils, StockMarket

            market = StockUtils.identify_stock_market(symbol)

            # æ˜ å°„åˆ°å¸‚åœºåˆ†ç±»ID
            market_mapping = {
                StockMarket.CHINA_A: 'a_shares',
                StockMarket.US: 'us_stocks',
                StockMarket.HONG_KONG: 'hk_stocks',
            }

            category = market_mapping.get(market)
            if category:
                logger.debug(f"ğŸ” [å¸‚åœºè¯†åˆ«] {symbol} â†’ {category}")
            return category
        except Exception as e:
            logger.warning(f"âš ï¸ [å¸‚åœºè¯†åˆ«] è¯†åˆ«å¤±è´¥: {e}")
            return None

    def _get_default_source(self) -> ChinaDataSource:
        """è·å–é»˜è®¤æ•°æ®æº"""
        # å¦‚æœå¯ç”¨MongoDBç¼“å­˜ï¼ŒMongoDBä½œä¸ºæœ€é«˜ä¼˜å…ˆçº§æ•°æ®æº
        if self.use_mongodb_cache:
            return ChinaDataSource.MONGODB

        # ä»ç¯å¢ƒå˜é‡è·å–ï¼Œé»˜è®¤ä½¿ç”¨AKShareä½œä¸ºç¬¬ä¸€ä¼˜å…ˆçº§æ•°æ®æº
        env_source = os.getenv('DEFAULT_CHINA_DATA_SOURCE', DataSourceCode.AKSHARE).lower()

        # æ˜ å°„åˆ°æšä¸¾ï¼ˆä½¿ç”¨ç»Ÿä¸€ç¼–ç ï¼‰
        source_mapping = {
            DataSourceCode.TUSHARE: ChinaDataSource.TUSHARE,
            DataSourceCode.AKSHARE: ChinaDataSource.AKSHARE,
            DataSourceCode.BAOSTOCK: ChinaDataSource.BAOSTOCK,
        }

        return source_mapping.get(env_source, ChinaDataSource.AKSHARE)

    # ==================== Tushareæ•°æ®æ¥å£ ====================

    def get_china_stock_data_tushare(self, symbol: str, start_date: str, end_date: str) -> str:
        """
        ä½¿ç”¨Tushareè·å–ä¸­å›½Aè‚¡å†å²æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            str: æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®æŠ¥å‘Š
        """
        # ä¸´æ—¶åˆ‡æ¢åˆ°Tushareæ•°æ®æº
        original_source = self.current_source
        self.current_source = ChinaDataSource.TUSHARE

        try:
            result = self._get_tushare_data(symbol, start_date, end_date)
            return result
        finally:
            # æ¢å¤åŸå§‹æ•°æ®æº
            self.current_source = original_source

    def get_fundamentals_data(self, symbol: str) -> str:
        """
        è·å–åŸºæœ¬é¢æ•°æ®ï¼Œæ”¯æŒå¤šæ•°æ®æºå’Œè‡ªåŠ¨é™çº§
        ä¼˜å…ˆçº§ï¼šMongoDB â†’ Tushare â†’ AKShare â†’ ç”Ÿæˆåˆ†æ

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            str: åŸºæœ¬é¢åˆ†ææŠ¥å‘Š
        """
        logger.info(f"ğŸ“Š [æ•°æ®æ¥æº: {self.current_source.value}] å¼€å§‹è·å–åŸºæœ¬é¢æ•°æ®: {symbol}",
                   extra={
                       'symbol': symbol,
                       'data_source': self.current_source.value,
                       'event_type': 'fundamentals_fetch_start'
                   })

        start_time = time.time()

        try:
            # æ ¹æ®æ•°æ®æºè°ƒç”¨ç›¸åº”çš„è·å–æ–¹æ³•
            if self.current_source == ChinaDataSource.MONGODB:
                result = self._get_mongodb_fundamentals(symbol)
            elif self.current_source == ChinaDataSource.TUSHARE:
                result = self._get_tushare_fundamentals(symbol)
            elif self.current_source == ChinaDataSource.AKSHARE:
                result = self._get_akshare_fundamentals(symbol)
            else:
                # å…¶ä»–æ•°æ®æºæš‚ä¸æ”¯æŒåŸºæœ¬é¢æ•°æ®ï¼Œç”ŸæˆåŸºæœ¬åˆ†æ
                result = self._generate_fundamentals_analysis(symbol)

            # æ£€æŸ¥ç»“æœ
            duration = time.time() - start_time
            result_length = len(result) if result else 0

            if result and "âŒ" not in result:
                logger.info(f"âœ… [æ•°æ®æ¥æº: {self.current_source.value}] æˆåŠŸè·å–åŸºæœ¬é¢æ•°æ®: {symbol} ({result_length}å­—ç¬¦, è€—æ—¶{duration:.2f}ç§’)",
                           extra={
                               'symbol': symbol,
                               'data_source': self.current_source.value,
                               'duration': duration,
                               'result_length': result_length,
                               'event_type': 'fundamentals_fetch_success'
                           })
                return result
            else:
                logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}å¤±è´¥] åŸºæœ¬é¢æ•°æ®è´¨é‡å¼‚å¸¸ï¼Œå°è¯•é™çº§: {symbol}",
                              extra={
                                  'symbol': symbol,
                                  'data_source': self.current_source.value,
                                  'event_type': 'fundamentals_fetch_fallback'
                              })
                return self._try_fallback_fundamentals(symbol)

        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"âŒ [æ•°æ®æ¥æº: {self.current_source.value}å¼‚å¸¸] è·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {symbol} - {e}",
                        extra={
                            'symbol': symbol,
                            'data_source': self.current_source.value,
                            'duration': duration,
                            'error': str(e),
                            'event_type': 'fundamentals_fetch_exception'
                        }, exc_info=True)
            return self._try_fallback_fundamentals(symbol)

    def get_china_stock_fundamentals_tushare(self, symbol: str) -> str:
        """
        ä½¿ç”¨Tushareè·å–ä¸­å›½è‚¡ç¥¨åŸºæœ¬é¢æ•°æ®ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            str: åŸºæœ¬é¢åˆ†ææŠ¥å‘Š
        """
        # é‡å®šå‘åˆ°ç»Ÿä¸€æ¥å£
        return self._get_tushare_fundamentals(symbol)

    def get_news_data(self, symbol: str = None, hours_back: int = 24, limit: int = 20) -> List[Dict[str, Any]]:
        """
        è·å–æ–°é—»æ•°æ®çš„ç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒå¤šæ•°æ®æºå’Œè‡ªåŠ¨é™çº§
        ä¼˜å…ˆçº§ï¼šMongoDB â†’ Tushare â†’ AKShare

        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼Œä¸ºç©ºåˆ™è·å–å¸‚åœºæ–°é—»
            hours_back: å›æº¯å°æ—¶æ•°
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            List[Dict]: æ–°é—»æ•°æ®åˆ—è¡¨
        """
        logger.info(f"ğŸ“° [æ•°æ®æ¥æº: {self.current_source.value}] å¼€å§‹è·å–æ–°é—»æ•°æ®: {symbol or 'å¸‚åœºæ–°é—»'}, å›æº¯{hours_back}å°æ—¶",
                   extra={
                       'symbol': symbol,
                       'hours_back': hours_back,
                       'limit': limit,
                       'data_source': self.current_source.value,
                       'event_type': 'news_fetch_start'
                   })

        start_time = time.time()

        try:
            # æ ¹æ®æ•°æ®æºè°ƒç”¨ç›¸åº”çš„è·å–æ–¹æ³•
            if self.current_source == ChinaDataSource.MONGODB:
                result = self._get_mongodb_news(symbol, hours_back, limit)
            elif self.current_source == ChinaDataSource.TUSHARE:
                result = self._get_tushare_news(symbol, hours_back, limit)
            elif self.current_source == ChinaDataSource.AKSHARE:
                result = self._get_akshare_news(symbol, hours_back, limit)
            else:
                # å…¶ä»–æ•°æ®æºæš‚ä¸æ”¯æŒæ–°é—»æ•°æ®
                logger.warning(f"âš ï¸ æ•°æ®æº {self.current_source.value} ä¸æ”¯æŒæ–°é—»æ•°æ®")
                result = []

            # æ£€æŸ¥ç»“æœ
            duration = time.time() - start_time
            result_count = len(result) if result else 0

            if result and result_count > 0:
                logger.info(f"âœ… [æ•°æ®æ¥æº: {self.current_source.value}] æˆåŠŸè·å–æ–°é—»æ•°æ®: {symbol or 'å¸‚åœºæ–°é—»'} ({result_count}æ¡, è€—æ—¶{duration:.2f}ç§’)",
                           extra={
                               'symbol': symbol,
                               'data_source': self.current_source.value,
                               'news_count': result_count,
                               'duration': duration,
                               'event_type': 'news_fetch_success'
                           })
                return result
            else:
                logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}] æœªè·å–åˆ°æ–°é—»æ•°æ®: {symbol or 'å¸‚åœºæ–°é—»'}ï¼Œå°è¯•é™çº§",
                              extra={
                                  'symbol': symbol,
                                  'data_source': self.current_source.value,
                                  'duration': duration,
                                  'event_type': 'news_fetch_fallback'
                              })
                return self._try_fallback_news(symbol, hours_back, limit)

        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"âŒ [æ•°æ®æ¥æº: {self.current_source.value}å¼‚å¸¸] è·å–æ–°é—»æ•°æ®å¤±è´¥: {symbol or 'å¸‚åœºæ–°é—»'} - {e}",
                        extra={
                            'symbol': symbol,
                            'data_source': self.current_source.value,
                            'duration': duration,
                            'error': str(e),
                            'event_type': 'news_fetch_exception'
                        }, exc_info=True)
            return self._try_fallback_news(symbol, hours_back, limit)

    def _check_available_sources(self) -> List[ChinaDataSource]:
        """
        æ£€æŸ¥å¯ç”¨çš„æ•°æ®æº

        æ£€æŸ¥é€»è¾‘ï¼š
        1. æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦å®‰è£…ï¼ˆæŠ€æœ¯å¯ç”¨æ€§ï¼‰
        2. æ£€æŸ¥æ•°æ®åº“é…ç½®ä¸­æ˜¯å¦å¯ç”¨ï¼ˆä¸šåŠ¡å¯ç”¨æ€§ï¼‰

        Returns:
            å¯ç”¨ä¸”å·²å¯ç”¨çš„æ•°æ®æºåˆ—è¡¨
        """
        available = []

        # ğŸ”¥ ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®ï¼Œè·å–å¯ç”¨çŠ¶æ€
        enabled_sources_in_db = set()
        try:
            from app.core.database import get_mongo_db_sync
            db = get_mongo_db_sync()
            config_collection = db.system_configs

            # è·å–æœ€æ–°çš„æ¿€æ´»é…ç½®
            config_data = config_collection.find_one(
                {"is_active": True},
                sort=[("version", -1)]
            )

            if config_data and config_data.get('data_source_configs'):
                data_source_configs = config_data.get('data_source_configs', [])

                # æå–å·²å¯ç”¨çš„æ•°æ®æºç±»å‹
                for ds in data_source_configs:
                    if ds.get('enabled', True):
                        ds_type = ds.get('type', '').lower()
                        enabled_sources_in_db.add(ds_type)

                logger.info(f"âœ… [æ•°æ®æºé…ç½®] ä»æ•°æ®åº“è¯»å–åˆ°å·²å¯ç”¨çš„æ•°æ®æº: {enabled_sources_in_db}")
            else:
                logger.warning("âš ï¸ [æ•°æ®æºé…ç½®] æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®æºé…ç½®ï¼Œå°†æ£€æŸ¥æ‰€æœ‰å·²å®‰è£…çš„æ•°æ®æº")
                # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®ï¼Œé»˜è®¤æ‰€æœ‰æ•°æ®æºéƒ½å¯ç”¨
                enabled_sources_in_db = {'mongodb', 'tushare', 'akshare', 'baostock'}
        except Exception as e:
            logger.warning(f"âš ï¸ [æ•°æ®æºé…ç½®] ä»æ•°æ®åº“è¯»å–å¤±è´¥: {e}ï¼Œå°†æ£€æŸ¥æ‰€æœ‰å·²å®‰è£…çš„æ•°æ®æº")
            # å¦‚æœè¯»å–å¤±è´¥ï¼Œé»˜è®¤æ‰€æœ‰æ•°æ®æºéƒ½å¯ç”¨
            enabled_sources_in_db = {'mongodb', 'tushare', 'akshare', 'baostock'}

        # æ£€æŸ¥MongoDBï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if self.use_mongodb_cache and 'mongodb' in enabled_sources_in_db:
            try:
                from tradingagents.dataflows.cache.mongodb_cache_adapter import get_mongodb_cache_adapter
                adapter = get_mongodb_cache_adapter()
                if adapter.use_app_cache and adapter.db is not None:
                    available.append(ChinaDataSource.MONGODB)
                    logger.info("âœ… MongoDBæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰")
                else:
                    logger.warning("âš ï¸ MongoDBæ•°æ®æºä¸å¯ç”¨: æ•°æ®åº“æœªè¿æ¥")
            except Exception as e:
                logger.warning(f"âš ï¸ MongoDBæ•°æ®æºä¸å¯ç”¨: {e}")
        elif self.use_mongodb_cache and 'mongodb' not in enabled_sources_in_db:
            logger.info("â„¹ï¸ MongoDBæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®
        datasource_configs = self._get_datasource_configs_from_db()

        # æ£€æŸ¥Tushare
        if 'tushare' in enabled_sources_in_db:
            try:
                import tushare as ts
                # ä¼˜å…ˆä»æ•°æ®åº“é…ç½®è¯»å– API Keyï¼Œå…¶æ¬¡ä»ç¯å¢ƒå˜é‡è¯»å–
                token = datasource_configs.get('tushare', {}).get('api_key') or os.getenv('TUSHARE_TOKEN')
                if token:
                    available.append(ChinaDataSource.TUSHARE)
                    source = "æ•°æ®åº“é…ç½®" if datasource_configs.get('tushare', {}).get('api_key') else "ç¯å¢ƒå˜é‡"
                    logger.info(f"âœ… Tushareæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨ (API Keyæ¥æº: {source})")
                else:
                    logger.warning("âš ï¸ Tushareæ•°æ®æºä¸å¯ç”¨: API Keyæœªé…ç½®ï¼ˆæ•°æ®åº“å’Œç¯å¢ƒå˜é‡å‡æœªæ‰¾åˆ°ï¼‰")
            except ImportError:
                logger.warning("âš ï¸ Tushareæ•°æ®æºä¸å¯ç”¨: åº“æœªå®‰è£…")
        else:
            logger.info("â„¹ï¸ Tushareæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # æ£€æŸ¥AKShare
        if 'akshare' in enabled_sources_in_db:
            try:
                import akshare as ak
                available.append(ChinaDataSource.AKSHARE)
                logger.info("âœ… AKShareæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨")
            except ImportError:
                logger.warning("âš ï¸ AKShareæ•°æ®æºä¸å¯ç”¨: åº“æœªå®‰è£…")
        else:
            logger.info("â„¹ï¸ AKShareæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # æ£€æŸ¥BaoStock
        if 'baostock' in enabled_sources_in_db:
            try:
                import baostock as bs
                available.append(ChinaDataSource.BAOSTOCK)
                logger.info(f"âœ… BaoStockæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨")
            except ImportError:
                logger.warning(f"âš ï¸ BaoStockæ•°æ®æºä¸å¯ç”¨: åº“æœªå®‰è£…")
        else:
            logger.info("â„¹ï¸ BaoStockæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # TDX (é€šè¾¾ä¿¡) å·²ç§»é™¤
        # ä¸å†æ£€æŸ¥å’Œæ”¯æŒ TDX æ•°æ®æº

        return available

    def _get_datasource_configs_from_db(self) -> dict:
        """ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®ï¼ˆåŒ…æ‹¬ API Keyï¼‰"""
        try:
            from app.core.database import get_mongo_db_sync
            db = get_mongo_db_sync()

            # ä» system_configs é›†åˆè¯»å–æ¿€æ´»çš„é…ç½®
            config = db.system_configs.find_one({"is_active": True})
            if not config:
                return {}

            # æå–æ•°æ®æºé…ç½®
            datasource_configs = config.get('data_source_configs', [])

            # æ„å»ºé…ç½®å­—å…¸ {æ•°æ®æºåç§°: {api_key, api_secret, ...}}
            result = {}
            for ds_config in datasource_configs:
                name = ds_config.get('name', '').lower()
                result[name] = {
                    'api_key': ds_config.get('api_key', ''),
                    'api_secret': ds_config.get('api_secret', ''),
                    'config_params': ds_config.get('config_params', {})
                }

            return result
        except Exception as e:
            logger.warning(f"âš ï¸ ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®å¤±è´¥: {e}")
            return {}

    def get_current_source(self) -> ChinaDataSource:
        """è·å–å½“å‰æ•°æ®æº"""
        return self.current_source

    def set_current_source(self, source: ChinaDataSource) -> bool:
        """è®¾ç½®å½“å‰æ•°æ®æº"""
        if source in self.available_sources:
            self.current_source = source
            logger.info(f"âœ… æ•°æ®æºå·²åˆ‡æ¢åˆ°: {source.value}")
            return True
        else:
            logger.error(f"âŒ æ•°æ®æºä¸å¯ç”¨: {source.value}")
            return False

    def get_data_adapter(self):
        """è·å–å½“å‰æ•°æ®æºçš„é€‚é…å™¨"""
        if self.current_source == ChinaDataSource.MONGODB:
            return self._get_mongodb_adapter()
        elif self.current_source == ChinaDataSource.TUSHARE:
            return self._get_tushare_adapter()
        elif self.current_source == ChinaDataSource.AKSHARE:
            return self._get_akshare_adapter()
        elif self.current_source == ChinaDataSource.BAOSTOCK:
            return self._get_baostock_adapter()
        # TDX å·²ç§»é™¤
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æº: {self.current_source}")

    def _get_mongodb_adapter(self):
        """è·å–MongoDBé€‚é…å™¨"""
        try:
            from tradingagents.dataflows.cache.mongodb_cache_adapter import get_mongodb_cache_adapter
            return get_mongodb_cache_adapter()
        except ImportError as e:
            logger.error(f"âŒ MongoDBé€‚é…å™¨å¯¼å…¥å¤±è´¥: {e}")
            return None

    def _get_tushare_adapter(self):
        """è·å–Tushareæä¾›å™¨ï¼ˆåŸadapterå·²åºŸå¼ƒï¼Œç°åœ¨ç›´æ¥ä½¿ç”¨providerï¼‰"""
        try:
            from .providers.china.tushare import get_tushare_provider
            return get_tushare_provider()
        except ImportError as e:
            logger.error(f"âŒ Tushareæä¾›å™¨å¯¼å…¥å¤±è´¥: {e}")
            return None

    def _get_akshare_adapter(self):
        """è·å–AKShareé€‚é…å™¨"""
        try:
            from .providers.china.akshare import get_akshare_provider
            return get_akshare_provider()
        except ImportError as e:
            logger.error(f"âŒ AKShareé€‚é…å™¨å¯¼å…¥å¤±è´¥: {e}")
            return None

    def _get_baostock_adapter(self):
        """è·å–BaoStocké€‚é…å™¨"""
        try:
            from .providers.china.baostock import get_baostock_provider
            return get_baostock_provider()
        except ImportError as e:
            logger.error(f"âŒ BaoStocké€‚é…å™¨å¯¼å…¥å¤±è´¥: {e}")
            return None

    # TDX é€‚é…å™¨å·²ç§»é™¤
    # def _get_tdx_adapter(self):
    #     """è·å–TDXé€‚é…å™¨ (å·²ç§»é™¤)"""
    #     logger.error(f"âŒ TDXæ•°æ®æºå·²ä¸å†æ”¯æŒ")
    #     return None

    def _get_cached_data(self, symbol: str, start_date: str = None, end_date: str = None, max_age_hours: int = 24) -> Optional[pd.DataFrame]:
        """
        ä»ç¼“å­˜è·å–æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            max_age_hours: æœ€å¤§ç¼“å­˜æ—¶é—´ï¼ˆå°æ—¶ï¼‰

        Returns:
            DataFrame: ç¼“å­˜çš„æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        if not self.cache_enabled or not self.cache_manager:
            return None

        try:
            cache_key = self.cache_manager.find_cached_stock_data(
                symbol=symbol,
                start_date=start_date,
                end_date=end_date,
                max_age_hours=max_age_hours
            )

            if cache_key:
                cached_data = self.cache_manager.load_stock_data(cache_key)
                if cached_data is not None and hasattr(cached_data, 'empty') and not cached_data.empty:
                    logger.debug(f"ğŸ“¦ ä»ç¼“å­˜è·å–{symbol}æ•°æ®: {len(cached_data)}æ¡")
                    return cached_data
        except Exception as e:
            logger.warning(f"âš ï¸ ä»ç¼“å­˜è¯»å–æ•°æ®å¤±è´¥: {e}")

        return None

    def _save_to_cache(self, symbol: str, data: pd.DataFrame, start_date: str = None, end_date: str = None):
        """
        ä¿å­˜æ•°æ®åˆ°ç¼“å­˜

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data: æ•°æ®
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
        """
        if not self.cache_enabled or not self.cache_manager:
            return

        try:
            if data is not None and hasattr(data, 'empty') and not data.empty:
                self.cache_manager.save_stock_data(symbol, data, start_date, end_date)
                logger.debug(f"ğŸ’¾ ä¿å­˜{symbol}æ•°æ®åˆ°ç¼“å­˜: {len(data)}æ¡")
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿å­˜æ•°æ®åˆ°ç¼“å­˜å¤±è´¥: {e}")

    def _get_volume_safely(self, data: pd.DataFrame) -> float:
        """
        å®‰å…¨è·å–æˆäº¤é‡æ•°æ®

        Args:
            data: è‚¡ç¥¨æ•°æ®DataFrame

        Returns:
            float: æˆäº¤é‡ï¼Œå¦‚æœè·å–å¤±è´¥è¿”å›0
        """
        try:
            if 'volume' in data.columns:
                return data['volume'].iloc[-1]
            elif 'vol' in data.columns:
                return data['vol'].iloc[-1]
            else:
                return 0
        except Exception:
            return 0

    def _format_stock_data_response(self, data: pd.DataFrame, symbol: str, stock_name: str,
                                    start_date: str, end_date: str) -> str:
        """
        æ ¼å¼åŒ–è‚¡ç¥¨æ•°æ®å“åº”ï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡ï¼‰

        Args:
            data: è‚¡ç¥¨æ•°æ®DataFrame
            symbol: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            str: æ ¼å¼åŒ–çš„æ•°æ®æŠ¥å‘Šï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡ï¼‰
        """
        try:
            original_data_count = len(data)
            logger.info(f"ğŸ“Š [æŠ€æœ¯æŒ‡æ ‡] å¼€å§‹è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ŒåŸå§‹æ•°æ®: {original_data_count}æ¡")

            # ğŸ”§ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆä½¿ç”¨å®Œæ•´æ•°æ®ï¼‰
            # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åº
            if 'date' in data.columns:
                data = data.sort_values('date')

            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
            data['ma5'] = data['close'].rolling(window=5, min_periods=1).mean()
            data['ma10'] = data['close'].rolling(window=10, min_periods=1).mean()
            data['ma20'] = data['close'].rolling(window=20, min_periods=1).mean()
            data['ma60'] = data['close'].rolling(window=60, min_periods=1).mean()

            # è®¡ç®—RSIï¼ˆç›¸å¯¹å¼ºå¼±æŒ‡æ ‡ï¼‰- åŒèŠ±é¡ºé£æ ¼ï¼šä½¿ç”¨ä¸­å›½å¼SMAï¼ˆEMA with adjust=Trueï¼‰
            # å‚è€ƒï¼šhttps://blog.csdn.net/u011218867/article/details/117427927
            # åŒèŠ±é¡º/é€šè¾¾ä¿¡çš„RSIä½¿ç”¨SMAå‡½æ•°ï¼Œç­‰ä»·äºpandasçš„ewm(com=N-1, adjust=True)
            delta = data['close'].diff()
            gain = delta.where(delta > 0, 0)
            loss = -delta.where(delta < 0, 0)

            # RSI6 - ä½¿ç”¨ä¸­å›½å¼SMA
            avg_gain6 = gain.ewm(com=5, adjust=True).mean()  # com = N - 1
            avg_loss6 = loss.ewm(com=5, adjust=True).mean()
            rs6 = avg_gain6 / avg_loss6.replace(0, np.nan)
            data['rsi6'] = 100 - (100 / (1 + rs6))

            # RSI12 - ä½¿ç”¨ä¸­å›½å¼SMA
            avg_gain12 = gain.ewm(com=11, adjust=True).mean()
            avg_loss12 = loss.ewm(com=11, adjust=True).mean()
            rs12 = avg_gain12 / avg_loss12.replace(0, np.nan)
            data['rsi12'] = 100 - (100 / (1 + rs12))

            # RSI24 - ä½¿ç”¨ä¸­å›½å¼SMA
            avg_gain24 = gain.ewm(com=23, adjust=True).mean()
            avg_loss24 = loss.ewm(com=23, adjust=True).mean()
            rs24 = avg_gain24 / avg_loss24.replace(0, np.nan)
            data['rsi24'] = 100 - (100 / (1 + rs24))

            # ä¿ç•™RSI14ä½œä¸ºå›½é™…æ ‡å‡†å‚è€ƒï¼ˆä½¿ç”¨ç®€å•ç§»åŠ¨å¹³å‡ï¼‰
            gain14 = gain.rolling(window=14, min_periods=1).mean()
            loss14 = loss.rolling(window=14, min_periods=1).mean()
            rs14 = gain14 / loss14.replace(0, np.nan)
            data['rsi14'] = 100 - (100 / (1 + rs14))

            # è®¡ç®—MACD
            ema12 = data['close'].ewm(span=12, adjust=False).mean()
            ema26 = data['close'].ewm(span=26, adjust=False).mean()
            data['macd_dif'] = ema12 - ema26
            data['macd_dea'] = data['macd_dif'].ewm(span=9, adjust=False).mean()
            data['macd'] = (data['macd_dif'] - data['macd_dea']) * 2

            # è®¡ç®—å¸ƒæ—å¸¦
            data['boll_mid'] = data['close'].rolling(window=20, min_periods=1).mean()
            std = data['close'].rolling(window=20, min_periods=1).std()
            data['boll_upper'] = data['boll_mid'] + 2 * std
            data['boll_lower'] = data['boll_mid'] - 2 * std

            logger.info(f"âœ… [æŠ€æœ¯æŒ‡æ ‡] æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")

            # ğŸ”§ åªä¿ç•™æœ€å3-5å¤©çš„æ•°æ®ç”¨äºå±•ç¤ºï¼ˆå‡å°‘tokenæ¶ˆè€—ï¼‰
            display_rows = min(5, len(data))
            display_data = data.tail(display_rows)
            latest_data = data.iloc[-1]

            # ğŸ” [è°ƒè¯•æ—¥å¿—] æ‰“å°æœ€è¿‘5å¤©çš„åŸå§‹æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡
            logger.info(f"ğŸ” [æŠ€æœ¯æŒ‡æ ‡è¯¦æƒ…] ===== æœ€è¿‘{display_rows}ä¸ªäº¤æ˜“æ—¥æ•°æ® =====")
            for i, (idx, row) in enumerate(display_data.iterrows(), 1):
                logger.info(f"ğŸ” [æŠ€æœ¯æŒ‡æ ‡è¯¦æƒ…] ç¬¬{i}å¤© ({row.get('date', 'N/A')}):")
                logger.info(f"   ä»·æ ¼: å¼€={row.get('open', 0):.2f}, é«˜={row.get('high', 0):.2f}, ä½={row.get('low', 0):.2f}, æ”¶={row.get('close', 0):.2f}")
                logger.info(f"   MA: MA5={row.get('ma5', 0):.2f}, MA10={row.get('ma10', 0):.2f}, MA20={row.get('ma20', 0):.2f}, MA60={row.get('ma60', 0):.2f}")
                logger.info(f"   MACD: DIF={row.get('macd_dif', 0):.4f}, DEA={row.get('macd_dea', 0):.4f}, MACD={row.get('macd', 0):.4f}")
                logger.info(f"   RSI: RSI6={row.get('rsi6', 0):.2f}, RSI12={row.get('rsi12', 0):.2f}, RSI24={row.get('rsi24', 0):.2f} (åŒèŠ±é¡ºé£æ ¼)")
                logger.info(f"   RSI14: {row.get('rsi14', 0):.2f} (å›½é™…æ ‡å‡†)")
                logger.info(f"   BOLL: ä¸Š={row.get('boll_upper', 0):.2f}, ä¸­={row.get('boll_mid', 0):.2f}, ä¸‹={row.get('boll_lower', 0):.2f}")

            logger.info(f"ğŸ” [æŠ€æœ¯æŒ‡æ ‡è¯¦æƒ…] ===== æ•°æ®è¯¦æƒ…ç»“æŸ =====")

            # è®¡ç®—æœ€æ–°ä»·æ ¼å’Œæ¶¨è·Œå¹…
            latest_price = latest_data.get('close', 0)
            prev_close = data.iloc[-2].get('close', latest_price) if len(data) > 1 else latest_price
            change = latest_price - prev_close
            change_pct = (change / prev_close * 100) if prev_close != 0 else 0

            # æ ¼å¼åŒ–æ•°æ®æŠ¥å‘Š
            result = f"ğŸ“Š {stock_name}({symbol}) - æŠ€æœ¯åˆ†ææ•°æ®\n"
            result += f"æ•°æ®æœŸé—´: {start_date} è‡³ {end_date}\n"
            result += f"æ•°æ®æ¡æ•°: {original_data_count}æ¡ (å±•ç¤ºæœ€è¿‘{display_rows}ä¸ªäº¤æ˜“æ—¥)\n\n"

            result += f"ğŸ’° æœ€æ–°ä»·æ ¼: Â¥{latest_price:.2f}\n"
            result += f"ğŸ“ˆ æ¶¨è·Œé¢: {change:+.2f} ({change_pct:+.2f}%)\n\n"

            # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
            result += f"ğŸ“Š ç§»åŠ¨å¹³å‡çº¿ (MA):\n"
            result += f"   MA5:  Â¥{latest_data['ma5']:.2f}"
            if latest_price > latest_data['ma5']:
                result += " (ä»·æ ¼åœ¨MA5ä¸Šæ–¹ â†‘)\n"
            else:
                result += " (ä»·æ ¼åœ¨MA5ä¸‹æ–¹ â†“)\n"

            result += f"   MA10: Â¥{latest_data['ma10']:.2f}"
            if latest_price > latest_data['ma10']:
                result += " (ä»·æ ¼åœ¨MA10ä¸Šæ–¹ â†‘)\n"
            else:
                result += " (ä»·æ ¼åœ¨MA10ä¸‹æ–¹ â†“)\n"

            result += f"   MA20: Â¥{latest_data['ma20']:.2f}"
            if latest_price > latest_data['ma20']:
                result += " (ä»·æ ¼åœ¨MA20ä¸Šæ–¹ â†‘)\n"
            else:
                result += " (ä»·æ ¼åœ¨MA20ä¸‹æ–¹ â†“)\n"

            result += f"   MA60: Â¥{latest_data['ma60']:.2f}"
            if latest_price > latest_data['ma60']:
                result += " (ä»·æ ¼åœ¨MA60ä¸Šæ–¹ â†‘)\n\n"
            else:
                result += " (ä»·æ ¼åœ¨MA60ä¸‹æ–¹ â†“)\n\n"

            # MACDæŒ‡æ ‡
            result += f"ğŸ“ˆ MACDæŒ‡æ ‡:\n"
            result += f"   DIF:  {latest_data['macd_dif']:.3f}\n"
            result += f"   DEA:  {latest_data['macd_dea']:.3f}\n"
            result += f"   MACD: {latest_data['macd']:.3f}"
            if latest_data['macd'] > 0:
                result += " (å¤šå¤´ â†‘)\n"
            else:
                result += " (ç©ºå¤´ â†“)\n"

            # åˆ¤æ–­é‡‘å‰/æ­»å‰
            if len(data) > 1:
                prev_dif = data.iloc[-2]['macd_dif']
                prev_dea = data.iloc[-2]['macd_dea']
                curr_dif = latest_data['macd_dif']
                curr_dea = latest_data['macd_dea']

                if prev_dif <= prev_dea and curr_dif > curr_dea:
                    result += "   âš ï¸ MACDé‡‘å‰ä¿¡å·ï¼ˆDIFä¸Šç©¿DEAï¼‰\n\n"
                elif prev_dif >= prev_dea and curr_dif < curr_dea:
                    result += "   âš ï¸ MACDæ­»å‰ä¿¡å·ï¼ˆDIFä¸‹ç©¿DEAï¼‰\n\n"
                else:
                    result += "\n"
            else:
                result += "\n"

            # RSIæŒ‡æ ‡ - åŒèŠ±é¡ºé£æ ¼ (6, 12, 24)
            rsi6 = latest_data['rsi6']
            rsi12 = latest_data['rsi12']
            rsi24 = latest_data['rsi24']
            result += f"ğŸ“‰ RSIæŒ‡æ ‡ (åŒèŠ±é¡ºé£æ ¼):\n"
            result += f"   RSI6:  {rsi6:.2f}"
            if rsi6 >= 80:
                result += " (è¶…ä¹° âš ï¸)\n"
            elif rsi6 <= 20:
                result += " (è¶…å– âš ï¸)\n"
            else:
                result += "\n"

            result += f"   RSI12: {rsi12:.2f}"
            if rsi12 >= 80:
                result += " (è¶…ä¹° âš ï¸)\n"
            elif rsi12 <= 20:
                result += " (è¶…å– âš ï¸)\n"
            else:
                result += "\n"

            result += f"   RSI24: {rsi24:.2f}"
            if rsi24 >= 80:
                result += " (è¶…ä¹° âš ï¸)\n"
            elif rsi24 <= 20:
                result += " (è¶…å– âš ï¸)\n"
            else:
                result += "\n"

            # åˆ¤æ–­RSIè¶‹åŠ¿
            if rsi6 > rsi12 > rsi24:
                result += "   è¶‹åŠ¿: å¤šå¤´æ’åˆ— â†‘\n\n"
            elif rsi6 < rsi12 < rsi24:
                result += "   è¶‹åŠ¿: ç©ºå¤´æ’åˆ— â†“\n\n"
            else:
                result += "   è¶‹åŠ¿: éœ‡è¡æ•´ç† â†”\n\n"

            # å¸ƒæ—å¸¦
            result += f"ğŸ“Š å¸ƒæ—å¸¦ (BOLL):\n"
            result += f"   ä¸Šè½¨: Â¥{latest_data['boll_upper']:.2f}\n"
            result += f"   ä¸­è½¨: Â¥{latest_data['boll_mid']:.2f}\n"
            result += f"   ä¸‹è½¨: Â¥{latest_data['boll_lower']:.2f}\n"

            # åˆ¤æ–­ä»·æ ¼åœ¨å¸ƒæ—å¸¦çš„ä½ç½®
            boll_position = (latest_price - latest_data['boll_lower']) / (latest_data['boll_upper'] - latest_data['boll_lower']) * 100
            result += f"   ä»·æ ¼ä½ç½®: {boll_position:.1f}%"
            if boll_position >= 80:
                result += " (æ¥è¿‘ä¸Šè½¨ï¼Œå¯èƒ½è¶…ä¹° âš ï¸)\n\n"
            elif boll_position <= 20:
                result += " (æ¥è¿‘ä¸‹è½¨ï¼Œå¯èƒ½è¶…å– âš ï¸)\n\n"
            else:
                result += " (ä¸­æ€§åŒºåŸŸ)\n\n"

            # ä»·æ ¼ç»Ÿè®¡
            result += f"ğŸ“Š ä»·æ ¼ç»Ÿè®¡ (æœ€è¿‘{display_rows}ä¸ªäº¤æ˜“æ—¥):\n"
            result += f"   æœ€é«˜ä»·: Â¥{display_data['high'].max():.2f}\n"
            result += f"   æœ€ä½ä»·: Â¥{display_data['low'].min():.2f}\n"
            result += f"   å¹³å‡ä»·: Â¥{display_data['close'].mean():.2f}\n"

            # é˜²å¾¡æ€§è·å–æˆäº¤é‡æ•°æ®
            volume_value = self._get_volume_safely(display_data)
            result += f"   å¹³å‡æˆäº¤é‡: {volume_value:,.0f}è‚¡\n"

            return result

        except Exception as e:
            logger.error(f"âŒ æ ¼å¼åŒ–æ•°æ®å“åº”å¤±è´¥: {e}", exc_info=True)
            return f"âŒ æ ¼å¼åŒ–{symbol}æ•°æ®å¤±è´¥: {e}"

    def get_stock_dataframe(self, symbol: str, start_date: str = None, end_date: str = None, period: str = "daily") -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨æ•°æ®çš„ DataFrame æ¥å£ï¼Œæ”¯æŒå¤šæ•°æ®æºå’Œè‡ªåŠ¨é™çº§

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            period: æ•°æ®å‘¨æœŸï¼ˆdaily/weekly/monthlyï¼‰ï¼Œé»˜è®¤ä¸ºdaily

        Returns:
            pd.DataFrame: è‚¡ç¥¨æ•°æ® DataFrameï¼Œåˆ—æ ‡å‡†ï¼šopen, high, low, close, vol, amount, date
        """
        logger.info(f"ğŸ“Š [DataFrameæ¥å£] è·å–è‚¡ç¥¨æ•°æ®: {symbol} ({start_date} åˆ° {end_date})")

        try:
            # å°è¯•å½“å‰æ•°æ®æº
            df = None
            if self.current_source == ChinaDataSource.MONGODB:
                from tradingagents.dataflows.cache.mongodb_cache_adapter import get_mongodb_cache_adapter
                adapter = get_mongodb_cache_adapter()
                df = adapter.get_historical_data(symbol, start_date, end_date, period=period)
            elif self.current_source == ChinaDataSource.TUSHARE:
                from .providers.china.tushare import get_tushare_provider
                provider = get_tushare_provider()
                df = provider.get_daily_data(symbol, start_date, end_date)
            elif self.current_source == ChinaDataSource.AKSHARE:
                from .providers.china.akshare import get_akshare_provider
                provider = get_akshare_provider()
                df = provider.get_stock_data(symbol, start_date, end_date)
            elif self.current_source == ChinaDataSource.BAOSTOCK:
                from .providers.china.baostock import get_baostock_provider
                provider = get_baostock_provider()
                df = provider.get_stock_data(symbol, start_date, end_date)

            if df is not None and not df.empty:
                logger.info(f"âœ… [DataFrameæ¥å£] ä» {self.current_source.value} è·å–æˆåŠŸ: {len(df)}æ¡")
                return self._standardize_dataframe(df)

            # é™çº§åˆ°å…¶ä»–æ•°æ®æº
            logger.warning(f"âš ï¸ [DataFrameæ¥å£] {self.current_source.value} å¤±è´¥ï¼Œå°è¯•é™çº§")
            for source in self.available_sources:
                if source == self.current_source:
                    continue
                try:
                    if source == ChinaDataSource.MONGODB:
                        from tradingagents.dataflows.cache.mongodb_cache_adapter import get_mongodb_cache_adapter
                        adapter = get_mongodb_cache_adapter()
                        df = adapter.get_historical_data(symbol, start_date, end_date, period=period)
                    elif source == ChinaDataSource.TUSHARE:
                        from .providers.china.tushare import get_tushare_provider
                        provider = get_tushare_provider()
                        df = provider.get_daily_data(symbol, start_date, end_date)
                    elif source == ChinaDataSource.AKSHARE:
                        from .providers.china.akshare import get_akshare_provider
                        provider = get_akshare_provider()
                        df = provider.get_stock_data(symbol, start_date, end_date)
                    elif source == ChinaDataSource.BAOSTOCK:
                        from .providers.china.baostock import get_baostock_provider
                        provider = get_baostock_provider()
                        df = provider.get_stock_data(symbol, start_date, end_date)

                    if df is not None and not df.empty:
                        logger.info(f"âœ… [DataFrameæ¥å£] é™çº§åˆ° {source.value} æˆåŠŸ: {len(df)}æ¡")
                        return self._standardize_dataframe(df)
                except Exception as e:
                    logger.warning(f"âš ï¸ [DataFrameæ¥å£] {source.value} å¤±è´¥: {e}")
                    continue

            logger.error(f"âŒ [DataFrameæ¥å£] æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥: {symbol}")
            return pd.DataFrame()

        except Exception as e:
            logger.error(f"âŒ [DataFrameæ¥å£] è·å–å¤±è´¥: {e}", exc_info=True)
            return pd.DataFrame()

    def _standardize_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ ‡å‡†åŒ– DataFrame åˆ—åå’Œæ ¼å¼

        Args:
            df: åŸå§‹ DataFrame

        Returns:
            pd.DataFrame: æ ‡å‡†åŒ–åçš„ DataFrame
        """
        if df is None or df.empty:
            return pd.DataFrame()

        out = df.copy()

        # åˆ—åæ˜ å°„
        colmap = {
            # English
            'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close',
            'Volume': 'vol', 'Amount': 'amount', 'symbol': 'code', 'Symbol': 'code',
            # Already lower
            'open': 'open', 'high': 'high', 'low': 'low', 'close': 'close',
            'vol': 'vol', 'volume': 'vol', 'amount': 'amount', 'code': 'code',
            'date': 'date', 'trade_date': 'date',
            # Chinese (AKShare common)
            'æ—¥æœŸ': 'date', 'å¼€ç›˜': 'open', 'æœ€é«˜': 'high', 'æœ€ä½': 'low', 'æ”¶ç›˜': 'close',
            'æˆäº¤é‡': 'vol', 'æˆäº¤é¢': 'amount', 'æ¶¨è·Œå¹…': 'pct_change', 'æ¶¨è·Œé¢': 'change',
        }
        out = out.rename(columns={c: colmap.get(c, c) for c in out.columns})

        # ç¡®ä¿æ—¥æœŸæ’åº
        if 'date' in out.columns:
            try:
                out['date'] = pd.to_datetime(out['date'])
                out = out.sort_values('date')
            except Exception:
                pass

        # è®¡ç®—æ¶¨è·Œå¹…ï¼ˆå¦‚æœç¼ºå¤±ï¼‰
        if 'pct_change' not in out.columns and 'close' in out.columns:
            out['pct_change'] = out['close'].pct_change() * 100.0

        return out

    def get_stock_data(self, symbol: str, start_date: str = None, end_date: str = None, period: str = "daily") -> str:
        """
        è·å–è‚¡ç¥¨æ•°æ®çš„ç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒå¤šå‘¨æœŸæ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            period: æ•°æ®å‘¨æœŸï¼ˆdaily/weekly/monthlyï¼‰ï¼Œé»˜è®¤ä¸ºdaily

        Returns:
            str: æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®
        """
        # è®°å½•è¯¦ç»†çš„è¾“å…¥å‚æ•°
        logger.info(f"ğŸ“Š [æ•°æ®æ¥æº: {self.current_source.value}] å¼€å§‹è·å–{period}æ•°æ®: {symbol}",
                   extra={
                       'symbol': symbol,
                       'start_date': start_date,
                       'end_date': end_date,
                       'period': period,
                       'data_source': self.current_source.value,
                       'event_type': 'data_fetch_start'
                   })

        # æ·»åŠ è¯¦ç»†çš„è‚¡ç¥¨ä»£ç è¿½è¸ªæ—¥å¿—
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] DataSourceManager.get_stock_data æ¥æ”¶åˆ°çš„è‚¡ç¥¨ä»£ç : '{symbol}' (ç±»å‹: {type(symbol)})")
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç é•¿åº¦: {len(str(symbol))}")
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç å­—ç¬¦: {list(str(symbol))}")
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] å½“å‰æ•°æ®æº: {self.current_source.value}")

        start_time = time.time()

        try:
            # æ ¹æ®æ•°æ®æºè°ƒç”¨ç›¸åº”çš„è·å–æ–¹æ³•
            actual_source = None  # å®é™…ä½¿ç”¨çš„æ•°æ®æº

            if self.current_source == ChinaDataSource.MONGODB:
                result, actual_source = self._get_mongodb_data(symbol, start_date, end_date, period)
            elif self.current_source == ChinaDataSource.TUSHARE:
                logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è°ƒç”¨ Tushare æ•°æ®æºï¼Œä¼ å…¥å‚æ•°: symbol='{symbol}', period='{period}'")
                result = self._get_tushare_data(symbol, start_date, end_date, period)
                actual_source = "tushare"
            elif self.current_source == ChinaDataSource.AKSHARE:
                result = self._get_akshare_data(symbol, start_date, end_date, period)
                actual_source = "akshare"
            elif self.current_source == ChinaDataSource.BAOSTOCK:
                result = self._get_baostock_data(symbol, start_date, end_date, period)
                actual_source = "baostock"
            # TDX å·²ç§»é™¤
            else:
                result = f"âŒ ä¸æ”¯æŒçš„æ•°æ®æº: {self.current_source.value}"
                actual_source = None

            # è®°å½•è¯¦ç»†çš„è¾“å‡ºç»“æœ
            duration = time.time() - start_time
            result_length = len(result) if result else 0
            is_success = result and "âŒ" not in result and "é”™è¯¯" not in result

            # ä½¿ç”¨å®é™…æ•°æ®æºåç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ current_source
            display_source = actual_source or self.current_source.value

            if is_success:
                logger.info(f"âœ… [æ•°æ®æ¥æº: {display_source}] æˆåŠŸè·å–è‚¡ç¥¨æ•°æ®: {symbol} ({result_length}å­—ç¬¦, è€—æ—¶{duration:.2f}ç§’)",
                           extra={
                               'symbol': symbol,
                               'start_date': start_date,
                               'end_date': end_date,
                               'data_source': display_source,
                               'actual_source': actual_source,
                               'requested_source': self.current_source.value,
                               'duration': duration,
                               'result_length': result_length,
                               'result_preview': result[:200] + '...' if result_length > 200 else result,
                               'event_type': 'data_fetch_success'
                           })
                return result
            else:
                logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}å¤±è´¥] æ•°æ®è´¨é‡å¼‚å¸¸ï¼Œå°è¯•é™çº§åˆ°å…¶ä»–æ•°æ®æº: {symbol}",
                              extra={
                                  'symbol': symbol,
                                  'start_date': start_date,
                                  'end_date': end_date,
                                  'data_source': self.current_source.value,
                                  'duration': duration,
                                  'result_length': result_length,
                                  'result_preview': result[:200] + '...' if result_length > 200 else result,
                                  'event_type': 'data_fetch_warning'
                              })

                # æ•°æ®è´¨é‡å¼‚å¸¸æ—¶ä¹Ÿå°è¯•é™çº§åˆ°å…¶ä»–æ•°æ®æº
                fallback_result = self._try_fallback_sources(symbol, start_date, end_date)
                if fallback_result and "âŒ" not in fallback_result and "é”™è¯¯" not in fallback_result:
                    logger.info(f"âœ… [æ•°æ®æ¥æº: å¤‡ç”¨æ•°æ®æº] é™çº§æˆåŠŸè·å–æ•°æ®: {symbol}")
                    return fallback_result
                else:
                    logger.error(f"âŒ [æ•°æ®æ¥æº: æ‰€æœ‰æ•°æ®æºå¤±è´¥] æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å–æœ‰æ•ˆæ•°æ®: {symbol}")
                    return result  # è¿”å›åŸå§‹ç»“æœï¼ˆåŒ…å«é”™è¯¯ä¿¡æ¯ï¼‰

        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"âŒ [æ•°æ®è·å–] å¼‚å¸¸å¤±è´¥: {e}",
                        extra={
                            'symbol': symbol,
                            'start_date': start_date,
                            'end_date': end_date,
                            'data_source': self.current_source.value,
                            'duration': duration,
                            'error': str(e),
                            'event_type': 'data_fetch_exception'
                        }, exc_info=True)
            return self._try_fallback_sources(symbol, start_date, end_date)

    def _get_mongodb_data(self, symbol: str, start_date: str, end_date: str, period: str = "daily") -> tuple[str, str | None]:
        """
        ä»MongoDBè·å–å¤šå‘¨æœŸæ•°æ® - åŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—

        Returns:
            tuple[str, str | None]: (ç»“æœå­—ç¬¦ä¸², å®é™…ä½¿ç”¨çš„æ•°æ®æºåç§°)
        """
        logger.debug(f"ğŸ“Š [MongoDB] è°ƒç”¨å‚æ•°: symbol={symbol}, start_date={start_date}, end_date={end_date}, period={period}")

        try:
            from tradingagents.dataflows.cache.mongodb_cache_adapter import get_mongodb_cache_adapter
            adapter = get_mongodb_cache_adapter()

            # ä»MongoDBè·å–æŒ‡å®šå‘¨æœŸçš„å†å²æ•°æ®
            df = adapter.get_historical_data(symbol, start_date, end_date, period=period)

            if df is not None and not df.empty:
                logger.info(f"âœ… [æ•°æ®æ¥æº: MongoDBç¼“å­˜] æˆåŠŸè·å–{period}æ•°æ®: {symbol} ({len(df)}æ¡è®°å½•)")

                # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ŒåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
                # è·å–è‚¡ç¥¨åç§°ï¼ˆä»DataFrameä¸­æå–æˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼‰
                stock_name = f'è‚¡ç¥¨{symbol}'
                if 'name' in df.columns and not df['name'].empty:
                    stock_name = df['name'].iloc[0]

                # è°ƒç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼‰
                result = self._format_stock_data_response(df, symbol, stock_name, start_date, end_date)

                logger.info(f"âœ… [MongoDB] å·²è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: MA5/10/20/60, MACD, RSI, BOLL")
                return result, "mongodb"
            else:
                # MongoDBæ²¡æœ‰æ•°æ®ï¼ˆadapterå†…éƒ¨å·²è®°å½•è¯¦ç»†çš„æ•°æ®æºä¿¡æ¯ï¼‰ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº
                logger.info(f"ğŸ”„ [MongoDB] æœªæ‰¾åˆ°{period}æ•°æ®: {symbol}ï¼Œå¼€å§‹å°è¯•å¤‡ç”¨æ•°æ®æº")
                return self._try_fallback_sources(symbol, start_date, end_date, period)

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: MongoDBå¼‚å¸¸] è·å–{period}æ•°æ®å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            # MongoDBå¼‚å¸¸ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº
            return self._try_fallback_sources(symbol, start_date, end_date, period)

    def _get_tushare_data(self, symbol: str, start_date: str, end_date: str, period: str = "daily") -> str:
        """ä½¿ç”¨Tushareè·å–å¤šå‘¨æœŸæ•°æ® - ä½¿ç”¨provider + ç»Ÿä¸€ç¼“å­˜"""
        logger.debug(f"ğŸ“Š [Tushare] è°ƒç”¨å‚æ•°: symbol={symbol}, start_date={start_date}, end_date={end_date}, period={period}")

        # æ·»åŠ è¯¦ç»†çš„è‚¡ç¥¨ä»£ç è¿½è¸ªæ—¥å¿—
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] _get_tushare_data æ¥æ”¶åˆ°çš„è‚¡ç¥¨ä»£ç : '{symbol}' (ç±»å‹: {type(symbol)})")
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç é•¿åº¦: {len(str(symbol))}")
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç å­—ç¬¦: {list(str(symbol))}")
        logger.info(f"ğŸ” [DataSourceManagerè¯¦ç»†æ—¥å¿—] _get_tushare_data å¼€å§‹æ‰§è¡Œ")
        logger.info(f"ğŸ” [DataSourceManagerè¯¦ç»†æ—¥å¿—] å½“å‰æ•°æ®æº: {self.current_source.value}")

        start_time = time.time()
        try:
            # 1. å…ˆå°è¯•ä»ç¼“å­˜è·å–
            cached_data = self._get_cached_data(symbol, start_date, end_date, max_age_hours=24)
            if cached_data is not None and not cached_data.empty:
                logger.info(f"âœ… [ç¼“å­˜å‘½ä¸­] ä»ç¼“å­˜è·å–{symbol}æ•°æ®")
                # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
                provider = self._get_tushare_adapter()
                if provider:
                    import asyncio
                    try:
                        loop = asyncio.get_event_loop()
                        if loop.is_closed():
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                    except RuntimeError:
                        # åœ¨çº¿ç¨‹æ± ä¸­æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)

                    stock_info = loop.run_until_complete(provider.get_stock_basic_info(symbol))
                    stock_name = stock_info.get('name', f'è‚¡ç¥¨{symbol}') if stock_info else f'è‚¡ç¥¨{symbol}'
                else:
                    stock_name = f'è‚¡ç¥¨{symbol}'

                # æ ¼å¼åŒ–è¿”å›
                return self._format_stock_data_response(cached_data, symbol, stock_name, start_date, end_date)

            # 2. ç¼“å­˜æœªå‘½ä¸­ï¼Œä»providerè·å–
            logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è°ƒç”¨ tushare_providerï¼Œä¼ å…¥å‚æ•°: symbol='{symbol}'")
            logger.info(f"ğŸ” [DataSourceManagerè¯¦ç»†æ—¥å¿—] å¼€å§‹è°ƒç”¨tushare_provider...")

            provider = self._get_tushare_adapter()
            if not provider:
                return f"âŒ Tushareæä¾›å™¨ä¸å¯ç”¨"

            # ä½¿ç”¨å¼‚æ­¥æ–¹æ³•è·å–å†å²æ•°æ®
            import asyncio
            try:
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
            except RuntimeError:
                # åœ¨çº¿ç¨‹æ± ä¸­æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

            data = loop.run_until_complete(provider.get_historical_data(symbol, start_date, end_date))

            if data is not None and not data.empty:
                # ä¿å­˜åˆ°ç¼“å­˜
                self._save_to_cache(symbol, data, start_date, end_date)

                # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆå¼‚æ­¥ï¼‰
                stock_info = loop.run_until_complete(provider.get_stock_basic_info(symbol))
                stock_name = stock_info.get('name', f'è‚¡ç¥¨{symbol}') if stock_info else f'è‚¡ç¥¨{symbol}'

                # æ ¼å¼åŒ–è¿”å›
                result = self._format_stock_data_response(data, symbol, stock_name, start_date, end_date)

                duration = time.time() - start_time
                logger.info(f"ğŸ” [DataSourceManagerè¯¦ç»†æ—¥å¿—] è°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {duration:.3f}ç§’")
                logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è¿”å›ç»“æœå‰200å­—ç¬¦: {result[:200] if result else 'None'}")
                logger.debug(f"ğŸ“Š [Tushare] è°ƒç”¨å®Œæˆ: è€—æ—¶={duration:.2f}s, ç»“æœé•¿åº¦={len(result) if result else 0}")

                return result
            else:
                result = f"âŒ æœªè·å–åˆ°{symbol}çš„æœ‰æ•ˆæ•°æ®"
                duration = time.time() - start_time
                logger.warning(f"âš ï¸ [Tushare] æœªè·å–åˆ°æ•°æ®ï¼Œè€—æ—¶={duration:.2f}s")
                return result
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"âŒ [Tushare] è°ƒç”¨å¤±è´¥: {e}, è€—æ—¶={duration:.2f}s", exc_info=True)
            logger.error(f"âŒ [DataSourceManagerè¯¦ç»†æ—¥å¿—] å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            logger.error(f"âŒ [DataSourceManagerè¯¦ç»†æ—¥å¿—] å¼‚å¸¸ä¿¡æ¯: {str(e)}")
            import traceback
            logger.error(f"âŒ [DataSourceManagerè¯¦ç»†æ—¥å¿—] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            raise

    def _get_akshare_data(self, symbol: str, start_date: str, end_date: str, period: str = "daily") -> str:
        """ä½¿ç”¨AKShareè·å–å¤šå‘¨æœŸæ•°æ® - åŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—"""
        logger.debug(f"ğŸ“Š [AKShare] è°ƒç”¨å‚æ•°: symbol={symbol}, start_date={start_date}, end_date={end_date}, period={period}")

        start_time = time.time()
        try:
            # ä½¿ç”¨AKShareçš„ç»Ÿä¸€æ¥å£
            from .providers.china.akshare import get_akshare_provider
            provider = get_akshare_provider()

            # ä½¿ç”¨å¼‚æ­¥æ–¹æ³•è·å–å†å²æ•°æ®
            import asyncio
            try:
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
            except RuntimeError:
                # åœ¨çº¿ç¨‹æ± ä¸­æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

            data = loop.run_until_complete(provider.get_historical_data(symbol, start_date, end_date, period))

            duration = time.time() - start_time

            if data is not None and not data.empty:
                # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ŒåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
                # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
                stock_info = loop.run_until_complete(provider.get_stock_basic_info(symbol))
                stock_name = stock_info.get('name', f'è‚¡ç¥¨{symbol}') if stock_info else f'è‚¡ç¥¨{symbol}'

                # è°ƒç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼‰
                result = self._format_stock_data_response(data, symbol, stock_name, start_date, end_date)

                logger.debug(f"ğŸ“Š [AKShare] è°ƒç”¨æˆåŠŸ: è€—æ—¶={duration:.2f}s, æ•°æ®æ¡æ•°={len(data)}, ç»“æœé•¿åº¦={len(result)}")
                logger.info(f"âœ… [AKShare] å·²è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: MA5/10/20/60, MACD, RSI, BOLL")
                return result
            else:
                result = f"âŒ æœªèƒ½è·å–{symbol}çš„è‚¡ç¥¨æ•°æ®"
                logger.warning(f"âš ï¸ [AKShare] æ•°æ®ä¸ºç©º: è€—æ—¶={duration:.2f}s")
                return result

        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"âŒ [AKShare] è°ƒç”¨å¤±è´¥: {e}, è€—æ—¶={duration:.2f}s", exc_info=True)
            return f"âŒ AKShareè·å–{symbol}æ•°æ®å¤±è´¥: {e}"

    def _get_baostock_data(self, symbol: str, start_date: str, end_date: str, period: str = "daily") -> str:
        """ä½¿ç”¨BaoStockè·å–å¤šå‘¨æœŸæ•°æ® - åŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—"""
        # ä½¿ç”¨BaoStockçš„ç»Ÿä¸€æ¥å£
        from .providers.china.baostock import get_baostock_provider
        provider = get_baostock_provider()

        # ä½¿ç”¨å¼‚æ­¥æ–¹æ³•è·å–å†å²æ•°æ®
        import asyncio
        try:
            loop = asyncio.get_event_loop()
            if loop.is_closed():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
        except RuntimeError:
            # åœ¨çº¿ç¨‹æ± ä¸­æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        data = loop.run_until_complete(provider.get_historical_data(symbol, start_date, end_date, period))

        if data is not None and not data.empty:
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ŒåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            stock_info = loop.run_until_complete(provider.get_stock_basic_info(symbol))
            stock_name = stock_info.get('name', f'è‚¡ç¥¨{symbol}') if stock_info else f'è‚¡ç¥¨{symbol}'

            # è°ƒç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–æ–¹æ³•ï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼‰
            result = self._format_stock_data_response(data, symbol, stock_name, start_date, end_date)

            logger.info(f"âœ… [BaoStock] å·²è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: MA5/10/20/60, MACD, RSI, BOLL")
            return result
        else:
            return f"âŒ æœªèƒ½è·å–{symbol}çš„è‚¡ç¥¨æ•°æ®"

    # TDX æ•°æ®è·å–æ–¹æ³•å·²ç§»é™¤
    # def _get_tdx_data(self, symbol: str, start_date: str, end_date: str, period: str = "daily") -> str:
    #     """ä½¿ç”¨TDXè·å–å¤šå‘¨æœŸæ•°æ® (å·²ç§»é™¤)"""
    #     logger.error(f"âŒ TDXæ•°æ®æºå·²ä¸å†æ”¯æŒ")
    #     return f"âŒ TDXæ•°æ®æºå·²ä¸å†æ”¯æŒ"

    def _get_volume_safely(self, data) -> float:
        """å®‰å…¨åœ°è·å–æˆäº¤é‡æ•°æ®ï¼Œæ”¯æŒå¤šç§åˆ—å"""
        try:
            # æ”¯æŒå¤šç§å¯èƒ½çš„æˆäº¤é‡åˆ—å
            volume_columns = ['volume', 'vol', 'turnover', 'trade_volume']

            for col in volume_columns:
                if col in data.columns:
                    logger.info(f"âœ… æ‰¾åˆ°æˆäº¤é‡åˆ—: {col}")
                    return data[col].sum()

            # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè®°å½•è­¦å‘Šå¹¶è¿”å›0
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æˆäº¤é‡åˆ—ï¼Œå¯ç”¨åˆ—: {list(data.columns)}")
            return 0

        except Exception as e:
            logger.error(f"âŒ è·å–æˆäº¤é‡å¤±è´¥: {e}")
            return 0

    def _try_fallback_sources(self, symbol: str, start_date: str, end_date: str, period: str = "daily") -> tuple[str, str | None]:
        """
        å°è¯•å¤‡ç”¨æ•°æ®æº - é¿å…é€’å½’è°ƒç”¨

        Returns:
            tuple[str, str | None]: (ç»“æœå­—ç¬¦ä¸², å®é™…ä½¿ç”¨çš„æ•°æ®æºåç§°)
        """
        logger.info(f"ğŸ”„ [{self.current_source.value}] å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æºè·å–{period}æ•°æ®: {symbol}")

        # ğŸ”¥ ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆæ ¹æ®è‚¡ç¥¨ä»£ç è¯†åˆ«å¸‚åœºï¼‰
        # æ³¨æ„ï¼šä¸åŒ…å«MongoDBï¼Œå› ä¸ºMongoDBæ˜¯æœ€é«˜ä¼˜å…ˆçº§ï¼Œå¦‚æœå¤±è´¥äº†å°±ä¸å†å°è¯•
        fallback_order = self._get_data_source_priority_order(symbol)

        for source in fallback_order:
            if source != self.current_source and source in self.available_sources:
                try:
                    logger.info(f"ğŸ”„ [å¤‡ç”¨æ•°æ®æº] å°è¯• {source.value} è·å–{period}æ•°æ®: {symbol}")

                    # ç›´æ¥è°ƒç”¨å…·ä½“çš„æ•°æ®æºæ–¹æ³•ï¼Œé¿å…é€’å½’
                    if source == ChinaDataSource.TUSHARE:
                        result = self._get_tushare_data(symbol, start_date, end_date, period)
                    elif source == ChinaDataSource.AKSHARE:
                        result = self._get_akshare_data(symbol, start_date, end_date, period)
                    elif source == ChinaDataSource.BAOSTOCK:
                        result = self._get_baostock_data(symbol, start_date, end_date, period)
                    # TDX å·²ç§»é™¤
                    else:
                        logger.warning(f"âš ï¸ æœªçŸ¥æ•°æ®æº: {source.value}")
                        continue

                    if "âŒ" not in result:
                        logger.info(f"âœ… [å¤‡ç”¨æ•°æ®æº-{source.value}] æˆåŠŸè·å–{period}æ•°æ®: {symbol}")
                        return result, source.value  # è¿”å›ç»“æœå’Œå®é™…ä½¿ç”¨çš„æ•°æ®æº
                    else:
                        logger.warning(f"âš ï¸ [å¤‡ç”¨æ•°æ®æº-{source.value}] è¿”å›é”™è¯¯ç»“æœ: {symbol}")

                except Exception as e:
                    logger.error(f"âŒ [å¤‡ç”¨æ•°æ®æº-{source.value}] è·å–å¤±è´¥: {symbol}, é”™è¯¯: {e}")
                    continue

        logger.error(f"âŒ [æ‰€æœ‰æ•°æ®æºå¤±è´¥] æ— æ³•è·å–{period}æ•°æ®: {symbol}")
        return f"âŒ æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å–{symbol}çš„{period}æ•°æ®", None

    def get_stock_info(self, symbol: str) -> Dict:
        """
        è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼Œæ”¯æŒå¤šæ•°æ®æºå’Œè‡ªåŠ¨é™çº§
        ä¼˜å…ˆçº§ï¼šMongoDB â†’ Tushare â†’ AKShare â†’ BaoStock
        """
        logger.info(f"ğŸ“Š [æ•°æ®æ¥æº: {self.current_source.value}] å¼€å§‹è·å–è‚¡ç¥¨ä¿¡æ¯: {symbol}")

        # ä¼˜å…ˆä½¿ç”¨ App Mongo ç¼“å­˜ï¼ˆå½“ ta_use_app_cache=Trueï¼‰
        try:
            from tradingagents.config.runtime_settings import use_app_cache_enabled  # type: ignore
            use_cache = use_app_cache_enabled(False)
            logger.info(f"ğŸ”§ [é…ç½®æ£€æŸ¥] use_app_cache_enabled() è¿”å›å€¼: {use_cache}")
        except Exception as e:
            logger.error(f"âŒ [é…ç½®æ£€æŸ¥] use_app_cache_enabled() è°ƒç”¨å¤±è´¥: {e}", exc_info=True)
            use_cache = False

        logger.info(f"ğŸ”§ [é…ç½®] ta_use_app_cache={use_cache}, current_source={self.current_source.value}")

        if use_cache:

            try:
                from .cache.app_adapter import get_basics_from_cache, get_market_quote_dataframe
                doc = get_basics_from_cache(symbol)
                if doc:
                    name = doc.get('name') or doc.get('stock_name') or ''
                    # è§„èŒƒåŒ–è¡Œä¸šä¸æ¿å—ï¼ˆé¿å…æŠŠâ€œä¸­å°æ¿/åˆ›ä¸šæ¿â€ç­‰æ¿å—å€¼è¯¯ä½œè¡Œä¸šï¼‰
                    board_labels = {'ä¸»æ¿', 'ä¸­å°æ¿', 'åˆ›ä¸šæ¿', 'ç§‘åˆ›æ¿'}
                    raw_industry = (doc.get('industry') or doc.get('industry_name') or '').strip()
                    sec_or_cat = (doc.get('sec') or doc.get('category') or '').strip()
                    market_val = (doc.get('market') or '').strip()
                    industry_val = raw_industry or sec_or_cat or 'æœªçŸ¥'
                    changed = False
                    if raw_industry in board_labels:
                        # è‹¥industryæ˜¯æ¿å—åï¼Œåˆ™å°†å…¶ç”¨äºmarketï¼›industryæ”¹ç”¨æ›´ç»†åˆ†ç±»ï¼ˆsec/categoryï¼‰
                        if not market_val:
                            market_val = raw_industry
                            changed = True
                        if sec_or_cat:
                            industry_val = sec_or_cat
                            changed = True
                    if changed:
                        try:
                            logger.debug(f"ğŸ”§ [å­—æ®µå½’ä¸€åŒ–] industryåŸå€¼='{raw_industry}' â†’ è¡Œä¸š='{industry_val}', å¸‚åœº/æ¿å—='{market_val or doc.get('market', 'æœªçŸ¥')}'")
                        except Exception:
                            pass

                    result = {
                        'symbol': symbol,
                        'name': name or f'è‚¡ç¥¨{symbol}',
                        'area': doc.get('area', 'æœªçŸ¥'),
                        'industry': industry_val or 'æœªçŸ¥',
                        'market': market_val or doc.get('market', 'æœªçŸ¥'),
                        'list_date': doc.get('list_date', 'æœªçŸ¥'),
                        'source': 'app_cache'
                    }
                    # è¿½åŠ å¿«ç…§è¡Œæƒ…ï¼ˆè‹¥å­˜åœ¨ï¼‰
                    try:
                        df = get_market_quote_dataframe(symbol)
                        if df is not None and not df.empty:
                            row = df.iloc[-1]
                            result['current_price'] = row.get('close')
                            result['change_pct'] = row.get('pct_chg')
                            result['volume'] = row.get('volume')
                            result['quote_date'] = row.get('date')
                            result['quote_source'] = 'market_quotes'
                            logger.info(f"âœ… [è‚¡ç¥¨ä¿¡æ¯] é™„åŠ è¡Œæƒ… | price={result['current_price']} pct={result['change_pct']} vol={result['volume']} code={symbol}")
                    except Exception as _e:
                        logger.debug(f"é™„åŠ è¡Œæƒ…å¤±è´¥ï¼ˆå¿½ç•¥ï¼‰ï¼š{_e}")

                    if name:
                        logger.info(f"âœ… [æ•°æ®æ¥æº: MongoDB-stock_basic_info] æˆåŠŸè·å–: {symbol}")
                        return result
                    else:
                        logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] æœªæ‰¾åˆ°æœ‰æ•ˆåç§°: {symbol}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº")
            except Exception as e:
                logger.error(f"âŒ [æ•°æ®æ¥æº: MongoDBå¼‚å¸¸] è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)


        # é¦–å…ˆå°è¯•å½“å‰æ•°æ®æº
        try:
            if self.current_source == ChinaDataSource.TUSHARE:
                from .interface import get_china_stock_info_tushare
                info_str = get_china_stock_info_tushare(symbol)
                result = self._parse_stock_info_string(info_str, symbol)

                # æ£€æŸ¥æ˜¯å¦è·å–åˆ°æœ‰æ•ˆä¿¡æ¯
                if result.get('name') and result['name'] != f'è‚¡ç¥¨{symbol}':
                    logger.info(f"âœ… [æ•°æ®æ¥æº: Tushare-è‚¡ç¥¨ä¿¡æ¯] æˆåŠŸè·å–: {symbol}")
                    return result
                else:
                    logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: Tushareå¤±è´¥] è¿”å›æ— æ•ˆä¿¡æ¯ï¼Œå°è¯•é™çº§: {symbol}")
                    return self._try_fallback_stock_info(symbol)
            else:
                adapter = self.get_data_adapter()
                if adapter and hasattr(adapter, 'get_stock_info'):
                    result = adapter.get_stock_info(symbol)
                    if result.get('name') and result['name'] != f'è‚¡ç¥¨{symbol}':
                        logger.info(f"âœ… [æ•°æ®æ¥æº: {self.current_source.value}-è‚¡ç¥¨ä¿¡æ¯] æˆåŠŸè·å–: {symbol}")
                        return result
                    else:
                        logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}å¤±è´¥] è¿”å›æ— æ•ˆä¿¡æ¯ï¼Œå°è¯•é™çº§: {symbol}")
                        return self._try_fallback_stock_info(symbol)
                else:
                    logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: {self.current_source.value}] ä¸æ”¯æŒè‚¡ç¥¨ä¿¡æ¯è·å–ï¼Œå°è¯•é™çº§: {symbol}")
                    return self._try_fallback_stock_info(symbol)

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: {self.current_source.value}å¼‚å¸¸] è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)
            return self._try_fallback_stock_info(symbol)

    def get_stock_basic_info(self, stock_code: str = None) -> Optional[Dict[str, Any]]:
        """
        è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼ˆå…¼å®¹ stock_data_service æ¥å£ï¼‰

        Args:
            stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚æœä¸º None åˆ™è¿”å›æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨

        Returns:
            Dict: è‚¡ç¥¨ä¿¡æ¯å­—å…¸ï¼Œæˆ–åŒ…å« error å­—æ®µçš„é”™è¯¯å­—å…¸
        """
        if stock_code is None:
            # è¿”å›æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨
            logger.info("ğŸ“Š è·å–æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨")
            try:
                # å°è¯•ä» MongoDB è·å–
                from tradingagents.config.database_manager import get_database_manager
                db_manager = get_database_manager()
                if db_manager and db_manager.is_mongodb_available():
                    collection = db_manager.mongodb_db['stock_basic_info']
                    stocks = list(collection.find({}, {'_id': 0}))
                    if stocks:
                        logger.info(f"âœ… ä»MongoDBè·å–æ‰€æœ‰è‚¡ç¥¨: {len(stocks)}æ¡")
                        return stocks
            except Exception as e:
                logger.warning(f"âš ï¸ ä»MongoDBè·å–æ‰€æœ‰è‚¡ç¥¨å¤±è´¥: {e}")

            # é™çº§ï¼šè¿”å›ç©ºåˆ—è¡¨
            return []

        # è·å–å•ä¸ªè‚¡ç¥¨ä¿¡æ¯
        try:
            result = self.get_stock_info(stock_code)
            if result and result.get('name'):
                return result
            else:
                return {'error': f'æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„ä¿¡æ¯'}
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
            return {'error': str(e)}

    def get_stock_data_with_fallback(self, stock_code: str, start_date: str, end_date: str) -> str:
        """
        è·å–è‚¡ç¥¨æ•°æ®ï¼ˆå…¼å®¹ stock_data_service æ¥å£ï¼‰

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            str: æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®æŠ¥å‘Š
        """
        logger.info(f"ğŸ“Š è·å–è‚¡ç¥¨æ•°æ®: {stock_code} ({start_date} åˆ° {end_date})")

        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®è·å–æ¥å£
            return self.get_stock_data(stock_code, start_date, end_date)
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
            return f"âŒ è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {str(e)}\n\nğŸ’¡ å»ºè®®ï¼š\n1. æ£€æŸ¥ç½‘ç»œè¿æ¥\n2. ç¡®è®¤è‚¡ç¥¨ä»£ç æ ¼å¼æ­£ç¡®\n3. æ£€æŸ¥æ•°æ®æºé…ç½®"

    def _try_fallback_stock_info(self, symbol: str) -> Dict:
        """å°è¯•ä½¿ç”¨å¤‡ç”¨æ•°æ®æºè·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        logger.error(f"ğŸ”„ {self.current_source.value}å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æºè·å–è‚¡ç¥¨ä¿¡æ¯...")

        # è·å–æ‰€æœ‰å¯ç”¨æ•°æ®æº
        available_sources = self.available_sources.copy()

        # ç§»é™¤å½“å‰æ•°æ®æº
        if self.current_source.value in available_sources:
            available_sources.remove(self.current_source.value)

        # å°è¯•æ‰€æœ‰å¤‡ç”¨æ•°æ®æº
        for source_name in available_sources:
            try:
                source = ChinaDataSource(source_name)
                logger.info(f"ğŸ”„ å°è¯•å¤‡ç”¨æ•°æ®æºè·å–è‚¡ç¥¨ä¿¡æ¯: {source_name}")

                # æ ¹æ®æ•°æ®æºç±»å‹è·å–è‚¡ç¥¨ä¿¡æ¯
                if source == ChinaDataSource.TUSHARE:
                    # ğŸ”¥ ç›´æ¥è°ƒç”¨ Tushare é€‚é…å™¨ï¼Œé¿å…å¾ªç¯è°ƒç”¨
                    result = self._get_tushare_stock_info(symbol)
                elif source == ChinaDataSource.AKSHARE:
                    result = self._get_akshare_stock_info(symbol)
                elif source == ChinaDataSource.BAOSTOCK:
                    result = self._get_baostock_stock_info(symbol)
                else:
                    # å°è¯•é€šç”¨é€‚é…å™¨
                    original_source = self.current_source
                    self.current_source = source
                    adapter = self.get_data_adapter()
                    self.current_source = original_source

                    if adapter and hasattr(adapter, 'get_stock_info'):
                        result = adapter.get_stock_info(symbol)
                    else:
                        logger.warning(f"âš ï¸ [è‚¡ç¥¨ä¿¡æ¯] {source_name}ä¸æ”¯æŒè‚¡ç¥¨ä¿¡æ¯è·å–")
                        continue

                # æ£€æŸ¥æ˜¯å¦è·å–åˆ°æœ‰æ•ˆä¿¡æ¯
                if result.get('name') and result['name'] != f'è‚¡ç¥¨{symbol}':
                    logger.info(f"âœ… [æ•°æ®æ¥æº: å¤‡ç”¨æ•°æ®æº] é™çº§æˆåŠŸè·å–è‚¡ç¥¨ä¿¡æ¯: {source_name}")
                    return result
                else:
                    logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: {source_name}] è¿”å›æ— æ•ˆä¿¡æ¯")

            except Exception as e:
                logger.error(f"âŒ å¤‡ç”¨æ•°æ®æº{source_name}å¤±è´¥: {e}")
                continue

        # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
        logger.error(f"âŒ æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å–{symbol}çš„è‚¡ç¥¨ä¿¡æ¯")
        return {'symbol': symbol, 'name': f'è‚¡ç¥¨{symbol}', 'source': 'unknown'}

    def _get_akshare_stock_info(self, symbol: str) -> Dict:
        """ä½¿ç”¨AKShareè·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯

        ğŸ”¥ é‡è¦ï¼šAKShare éœ€è¦åŒºåˆ†è‚¡ç¥¨å’ŒæŒ‡æ•°
        - å¯¹äº 000001ï¼Œå¦‚æœä¸åŠ åç¼€ï¼Œä¼šè¢«è¯†åˆ«ä¸º"æ·±åœ³æˆæŒ‡"ï¼ˆæŒ‡æ•°ï¼‰
        - å¯¹äºè‚¡ç¥¨ï¼Œéœ€è¦ä½¿ç”¨å®Œæ•´ä»£ç ï¼ˆå¦‚ sz000001 æˆ– sh600000ï¼‰
        """
        try:
            import akshare as ak

            # ğŸ”¥ è½¬æ¢ä¸º AKShare æ ¼å¼çš„è‚¡ç¥¨ä»£ç 
            # AKShare çš„ stock_individual_info_em éœ€è¦ä½¿ç”¨ "sz000001" æˆ– "sh600000" æ ¼å¼
            if symbol.startswith('6'):
                # ä¸Šæµ·è‚¡ç¥¨ï¼š600000 -> sh600000
                akshare_symbol = f"sh{symbol}"
            elif symbol.startswith(('0', '3', '2')):
                # æ·±åœ³è‚¡ç¥¨ï¼š000001 -> sz000001
                akshare_symbol = f"sz{symbol}"
            elif symbol.startswith(('8', '4')):
                # åŒ—äº¬è‚¡ç¥¨ï¼š830000 -> bj830000
                akshare_symbol = f"bj{symbol}"
            else:
                # å…¶ä»–æƒ…å†µï¼Œç›´æ¥ä½¿ç”¨åŸå§‹ä»£ç 
                akshare_symbol = symbol

            logger.debug(f"ğŸ“Š [AKShareè‚¡ç¥¨ä¿¡æ¯] åŸå§‹ä»£ç : {symbol}, AKShareæ ¼å¼: {akshare_symbol}")

            # å°è¯•è·å–ä¸ªè‚¡ä¿¡æ¯
            stock_info = ak.stock_individual_info_em(symbol=akshare_symbol)

            if stock_info is not None and not stock_info.empty:
                # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                info = {'symbol': symbol, 'source': 'akshare'}

                # æå–è‚¡ç¥¨åç§°
                name_row = stock_info[stock_info['item'] == 'è‚¡ç¥¨ç®€ç§°']
                if not name_row.empty:
                    stock_name = name_row['value'].iloc[0]
                    info['name'] = stock_name
                    logger.info(f"âœ… [AKShareè‚¡ç¥¨ä¿¡æ¯] {symbol} -> {stock_name}")
                else:
                    info['name'] = f'è‚¡ç¥¨{symbol}'
                    logger.warning(f"âš ï¸ [AKShareè‚¡ç¥¨ä¿¡æ¯] æœªæ‰¾åˆ°è‚¡ç¥¨ç®€ç§°: {symbol}")

                # æå–å…¶ä»–ä¿¡æ¯
                info['area'] = 'æœªçŸ¥'  # AKShareæ²¡æœ‰åœ°åŒºä¿¡æ¯
                info['industry'] = 'æœªçŸ¥'  # å¯ä»¥é€šè¿‡å…¶ä»–APIè·å–
                info['market'] = 'æœªçŸ¥'  # å¯ä»¥æ ¹æ®è‚¡ç¥¨ä»£ç æ¨æ–­
                info['list_date'] = 'æœªçŸ¥'  # å¯ä»¥é€šè¿‡å…¶ä»–APIè·å–

                return info
            else:
                logger.warning(f"âš ï¸ [AKShareè‚¡ç¥¨ä¿¡æ¯] è¿”å›ç©ºæ•°æ®: {symbol}")
                return {'symbol': symbol, 'name': f'è‚¡ç¥¨{symbol}', 'source': 'akshare'}

        except Exception as e:
            logger.error(f"âŒ [è‚¡ç¥¨ä¿¡æ¯] AKShareè·å–å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            return {'symbol': symbol, 'name': f'è‚¡ç¥¨{symbol}', 'source': 'akshare', 'error': str(e)}

    def _get_baostock_stock_info(self, symbol: str) -> Dict:
        """ä½¿ç”¨BaoStockè·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        try:
            import baostock as bs

            # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼
            if symbol.startswith('6'):
                bs_code = f"sh.{symbol}"
            else:
                bs_code = f"sz.{symbol}"

            # ç™»å½•BaoStock
            lg = bs.login()
            if lg.error_code != '0':
                logger.error(f"âŒ [è‚¡ç¥¨ä¿¡æ¯] BaoStockç™»å½•å¤±è´¥: {lg.error_msg}")
                return {'symbol': symbol, 'name': f'è‚¡ç¥¨{symbol}', 'source': 'baostock'}

            # æŸ¥è¯¢è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            rs = bs.query_stock_basic(code=bs_code)
            if rs.error_code != '0':
                bs.logout()
                logger.error(f"âŒ [è‚¡ç¥¨ä¿¡æ¯] BaoStockæŸ¥è¯¢å¤±è´¥: {rs.error_msg}")
                return {'symbol': symbol, 'name': f'è‚¡ç¥¨{symbol}', 'source': 'baostock'}

            # è§£æç»“æœ
            data_list = []
            while (rs.error_code == '0') & rs.next():
                data_list.append(rs.get_row_data())

            # ç™»å‡º
            bs.logout()

            if data_list:
                # BaoStockè¿”å›æ ¼å¼: [code, code_name, ipoDate, outDate, type, status]
                info = {'symbol': symbol, 'source': 'baostock'}
                info['name'] = data_list[0][1]  # code_name
                info['area'] = 'æœªçŸ¥'  # BaoStockæ²¡æœ‰åœ°åŒºä¿¡æ¯
                info['industry'] = 'æœªçŸ¥'  # BaoStockæ²¡æœ‰è¡Œä¸šä¿¡æ¯
                info['market'] = 'æœªçŸ¥'  # å¯ä»¥æ ¹æ®è‚¡ç¥¨ä»£ç æ¨æ–­
                info['list_date'] = data_list[0][2]  # ipoDate

                return info
            else:
                return {'symbol': symbol, 'name': f'è‚¡ç¥¨{symbol}', 'source': 'baostock'}

        except Exception as e:
            logger.error(f"âŒ [è‚¡ç¥¨ä¿¡æ¯] BaoStockè·å–å¤±è´¥: {e}")
            return {'symbol': symbol, 'name': f'è‚¡ç¥¨{symbol}', 'source': 'baostock', 'error': str(e)}

    def _parse_stock_info_string(self, info_str: str, symbol: str) -> Dict:
        """è§£æè‚¡ç¥¨ä¿¡æ¯å­—ç¬¦ä¸²ä¸ºå­—å…¸"""
        try:
            info = {'symbol': symbol, 'source': self.current_source.value}
            lines = info_str.split('\n')

            for line in lines:
                if ':' in line:
                    key, value = line.split(':', 1)
                    key = key.strip()
                    value = value.strip()

                    if 'è‚¡ç¥¨åç§°' in key:
                        info['name'] = value
                    elif 'æ‰€å±è¡Œä¸š' in key:
                        info['industry'] = value
                    elif 'æ‰€å±åœ°åŒº' in key:
                        info['area'] = value
                    elif 'ä¸Šå¸‚å¸‚åœº' in key:
                        info['market'] = value
                    elif 'ä¸Šå¸‚æ—¥æœŸ' in key:
                        info['list_date'] = value

            return info

        except Exception as e:
            logger.error(f"âš ï¸ è§£æè‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
            return {'symbol': symbol, 'name': f'è‚¡ç¥¨{symbol}', 'source': self.current_source.value}

    # ==================== åŸºæœ¬é¢æ•°æ®è·å–æ–¹æ³• ====================

    def _get_mongodb_fundamentals(self, symbol: str) -> str:
        """ä» MongoDB è·å–è´¢åŠ¡æ•°æ®"""
        logger.debug(f"ğŸ“Š [MongoDB] è°ƒç”¨å‚æ•°: symbol={symbol}")

        try:
            from tradingagents.dataflows.cache.mongodb_cache_adapter import get_mongodb_cache_adapter
            import pandas as pd
            adapter = get_mongodb_cache_adapter()

            # ä» MongoDB è·å–è´¢åŠ¡æ•°æ®
            financial_data = adapter.get_financial_data(symbol)

            # æ£€æŸ¥æ•°æ®ç±»å‹å’Œå†…å®¹
            if financial_data is not None:
                # å¦‚æœæ˜¯ DataFrameï¼Œè½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                if isinstance(financial_data, pd.DataFrame):
                    if not financial_data.empty:
                        logger.info(f"âœ… [æ•°æ®æ¥æº: MongoDB-è´¢åŠ¡æ•°æ®] æˆåŠŸè·å–: {symbol} ({len(financial_data)}æ¡è®°å½•)")
                        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                        financial_dict_list = financial_data.to_dict('records')
                        # æ ¼å¼åŒ–è´¢åŠ¡æ•°æ®ä¸ºæŠ¥å‘Š
                        return self._format_financial_data(symbol, financial_dict_list)
                    else:
                        logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] è´¢åŠ¡æ•°æ®ä¸ºç©º: {symbol}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº")
                        return self._try_fallback_fundamentals(symbol)
                # å¦‚æœæ˜¯åˆ—è¡¨
                elif isinstance(financial_data, list) and len(financial_data) > 0:
                    logger.info(f"âœ… [æ•°æ®æ¥æº: MongoDB-è´¢åŠ¡æ•°æ®] æˆåŠŸè·å–: {symbol} ({len(financial_data)}æ¡è®°å½•)")
                    return self._format_financial_data(symbol, financial_data)
                # å¦‚æœæ˜¯å•ä¸ªå­—å…¸ï¼ˆè¿™æ˜¯MongoDBå®é™…è¿”å›çš„æ ¼å¼ï¼‰
                elif isinstance(financial_data, dict):
                    logger.info(f"âœ… [æ•°æ®æ¥æº: MongoDB-è´¢åŠ¡æ•°æ®] æˆåŠŸè·å–: {symbol} (å•æ¡è®°å½•)")
                    # å°†å•ä¸ªå­—å…¸åŒ…è£…æˆåˆ—è¡¨
                    financial_dict_list = [financial_data]
                    return self._format_financial_data(symbol, financial_dict_list)
                else:
                    logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] æœªæ‰¾åˆ°è´¢åŠ¡æ•°æ®: {symbol}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº")
                    return self._try_fallback_fundamentals(symbol)
            else:
                logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] æœªæ‰¾åˆ°è´¢åŠ¡æ•°æ®: {symbol}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº")
                # MongoDB æ²¡æœ‰æ•°æ®ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº
                return self._try_fallback_fundamentals(symbol)

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: MongoDBå¼‚å¸¸] è·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}", exc_info=True)
            # MongoDB å¼‚å¸¸ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº
            return self._try_fallback_fundamentals(symbol)

    def _get_tushare_fundamentals(self, symbol: str) -> str:
        """ä» Tushare è·å–åŸºæœ¬é¢æ•°æ® - æš‚æ—¶ä¸å¯ç”¨ï¼Œéœ€è¦å®ç°"""
        logger.warning(f"âš ï¸ TushareåŸºæœ¬é¢æ•°æ®åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨")
        return f"âš ï¸ TushareåŸºæœ¬é¢æ•°æ®åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ä½¿ç”¨å…¶ä»–æ•°æ®æº"

    def _get_akshare_fundamentals(self, symbol: str) -> str:
        """ä» AKShare ç”ŸæˆåŸºæœ¬é¢åˆ†æ"""
        logger.debug(f"ğŸ“Š [AKShare] è°ƒç”¨å‚æ•°: symbol={symbol}")

        try:
            # AKShare æ²¡æœ‰ç›´æ¥çš„åŸºæœ¬é¢æ•°æ®æ¥å£ï¼Œä½¿ç”¨ç”Ÿæˆåˆ†æ
            logger.info(f"ğŸ“Š [æ•°æ®æ¥æº: AKShare-ç”Ÿæˆåˆ†æ] ç”ŸæˆåŸºæœ¬é¢åˆ†æ: {symbol}")
            return self._generate_fundamentals_analysis(symbol)

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: AKShareå¼‚å¸¸] ç”ŸæˆåŸºæœ¬é¢åˆ†æå¤±è´¥: {e}")
            return f"âŒ ç”Ÿæˆ{symbol}åŸºæœ¬é¢åˆ†æå¤±è´¥: {e}"

    def _get_valuation_indicators(self, symbol: str) -> Dict:
        """ä»stock_basic_infoé›†åˆè·å–ä¼°å€¼æŒ‡æ ‡"""
        try:
            db_manager = get_database_manager()
            if not db_manager.is_mongodb_available():
                return {}
                
            client = db_manager.get_mongodb_client()
            db = client[db_manager.config.mongodb_config.database_name]
            
            # ä»stock_basic_infoé›†åˆè·å–ä¼°å€¼æŒ‡æ ‡
            collection = db['stock_basic_info']
            result = collection.find_one({'ts_code': symbol})
            
            if result:
                return {
                    'pe': result.get('pe'),
                    'pb': result.get('pb'),
                    'pe_ttm': result.get('pe_ttm'),
                    'total_mv': result.get('total_mv'),
                    'circ_mv': result.get('circ_mv')
                }
            return {}
            
        except Exception as e:
            logger.error(f"è·å–{symbol}ä¼°å€¼æŒ‡æ ‡å¤±è´¥: {e}")
            return {}

    def _format_financial_data(self, symbol: str, financial_data: List[Dict]) -> str:
        """æ ¼å¼åŒ–è´¢åŠ¡æ•°æ®ä¸ºæŠ¥å‘Š"""
        try:
            if not financial_data or len(financial_data) == 0:
                return f"âŒ æœªæ‰¾åˆ°{symbol}çš„è´¢åŠ¡æ•°æ®"

            # è·å–æœ€æ–°çš„è´¢åŠ¡æ•°æ®
            latest = financial_data[0]

            # æ„å»ºæŠ¥å‘Š
            report = f"ğŸ“Š {symbol} åŸºæœ¬é¢æ•°æ®ï¼ˆæ¥è‡ªMongoDBï¼‰\n\n"

            # åŸºæœ¬ä¿¡æ¯
            report += f"ğŸ“… æŠ¥å‘ŠæœŸ: {latest.get('report_period', latest.get('end_date', 'æœªçŸ¥'))}\n"
            report += f"ğŸ“ˆ æ•°æ®æ¥æº: MongoDBè´¢åŠ¡æ•°æ®åº“\n\n"

            # è´¢åŠ¡æŒ‡æ ‡
            report += "ğŸ’° è´¢åŠ¡æŒ‡æ ‡:\n"
            revenue = latest.get('revenue') or latest.get('total_revenue')
            if revenue is not None:
                report += f"   è¥ä¸šæ€»æ”¶å…¥: {revenue:,.2f}\n"
            
            net_profit = latest.get('net_profit') or latest.get('net_income')
            if net_profit is not None:
                report += f"   å‡€åˆ©æ¶¦: {net_profit:,.2f}\n"
                
            total_assets = latest.get('total_assets')
            if total_assets is not None:
                report += f"   æ€»èµ„äº§: {total_assets:,.2f}\n"
                
            total_liab = latest.get('total_liab')
            if total_liab is not None:
                report += f"   æ€»è´Ÿå€º: {total_liab:,.2f}\n"
                
            total_equity = latest.get('total_equity')
            if total_equity is not None:
                report += f"   è‚¡ä¸œæƒç›Š: {total_equity:,.2f}\n"

            # ä¼°å€¼æŒ‡æ ‡ - ä»stock_basic_infoé›†åˆè·å–
            report += "\nğŸ“Š ä¼°å€¼æŒ‡æ ‡:\n"
            valuation_data = self._get_valuation_indicators(symbol)
            if valuation_data:
                pe = valuation_data.get('pe')
                if pe is not None:
                    report += f"   å¸‚ç›ˆç‡(PE): {pe:.2f}\n"
                    
                pb = valuation_data.get('pb')
                if pb is not None:
                    report += f"   å¸‚å‡€ç‡(PB): {pb:.2f}\n"
                    
                pe_ttm = valuation_data.get('pe_ttm')
                if pe_ttm is not None:
                    report += f"   å¸‚ç›ˆç‡TTM(PE_TTM): {pe_ttm:.2f}\n"
                    
                total_mv = valuation_data.get('total_mv')
                if total_mv is not None:
                    report += f"   æ€»å¸‚å€¼: {total_mv:.2f}äº¿å…ƒ\n"
                    
                circ_mv = valuation_data.get('circ_mv')
                if circ_mv is not None:
                    report += f"   æµé€šå¸‚å€¼: {circ_mv:.2f}äº¿å…ƒ\n"
            else:
                # å¦‚æœæ— æ³•ä»stock_basic_infoè·å–ï¼Œå°è¯•ä»è´¢åŠ¡æ•°æ®è®¡ç®—
                pe = latest.get('pe')
                if pe is not None:
                    report += f"   å¸‚ç›ˆç‡(PE): {pe:.2f}\n"
                    
                pb = latest.get('pb')
                if pb is not None:
                    report += f"   å¸‚å‡€ç‡(PB): {pb:.2f}\n"
                    
                ps = latest.get('ps')
                if ps is not None:
                    report += f"   å¸‚é”€ç‡(PS): {ps:.2f}\n"

            # ç›ˆåˆ©èƒ½åŠ›
            report += "\nğŸ’¹ ç›ˆåˆ©èƒ½åŠ›:\n"
            roe = latest.get('roe')
            if roe is not None:
                report += f"   å‡€èµ„äº§æ”¶ç›Šç‡(ROE): {roe:.2f}%\n"
                
            roa = latest.get('roa')
            if roa is not None:
                report += f"   æ€»èµ„äº§æ”¶ç›Šç‡(ROA): {roa:.2f}%\n"
                
            gross_margin = latest.get('gross_margin')
            if gross_margin is not None:
                report += f"   æ¯›åˆ©ç‡: {gross_margin:.2f}%\n"
                
            netprofit_margin = latest.get('netprofit_margin') or latest.get('net_margin')
            if netprofit_margin is not None:
                report += f"   å‡€åˆ©ç‡: {netprofit_margin:.2f}%\n"

            # ç°é‡‘æµ
            n_cashflow_act = latest.get('n_cashflow_act')
            if n_cashflow_act is not None:
                report += "\nğŸ’° ç°é‡‘æµ:\n"
                report += f"   ç»è¥æ´»åŠ¨ç°é‡‘æµ: {n_cashflow_act:,.2f}\n"
                
                n_cashflow_inv_act = latest.get('n_cashflow_inv_act')
                if n_cashflow_inv_act is not None:
                    report += f"   æŠ•èµ„æ´»åŠ¨ç°é‡‘æµ: {n_cashflow_inv_act:,.2f}\n"
                    
                c_cash_equ_end_period = latest.get('c_cash_equ_end_period')
                if c_cash_equ_end_period is not None:
                    report += f"   æœŸæœ«ç°é‡‘åŠç­‰ä»·ç‰©: {c_cash_equ_end_period:,.2f}\n"

            report += f"\nğŸ“ å…±æœ‰ {len(financial_data)} æœŸè´¢åŠ¡æ•°æ®\n"

            return report

        except Exception as e:
            logger.error(f"âŒ æ ¼å¼åŒ–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
            return f"âŒ æ ¼å¼åŒ–{symbol}è´¢åŠ¡æ•°æ®å¤±è´¥: {e}"

    def _generate_fundamentals_analysis(self, symbol: str) -> str:
        """ç”ŸæˆåŸºæœ¬çš„åŸºæœ¬é¢åˆ†æ"""
        try:
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            stock_info = self.get_stock_info(symbol)

            report = f"ğŸ“Š {symbol} åŸºæœ¬é¢åˆ†æï¼ˆç”Ÿæˆï¼‰\n\n"
            report += f"ğŸ“ˆ è‚¡ç¥¨åç§°: {stock_info.get('name', 'æœªçŸ¥')}\n"
            report += f"ğŸ¢ æ‰€å±è¡Œä¸š: {stock_info.get('industry', 'æœªçŸ¥')}\n"
            report += f"ğŸ“ æ‰€å±åœ°åŒº: {stock_info.get('area', 'æœªçŸ¥')}\n"
            report += f"ğŸ“… ä¸Šå¸‚æ—¥æœŸ: {stock_info.get('list_date', 'æœªçŸ¥')}\n"
            report += f"ğŸ›ï¸ äº¤æ˜“æ‰€: {stock_info.get('exchange', 'æœªçŸ¥')}\n\n"

            report += "âš ï¸ æ³¨æ„: è¯¦ç»†è´¢åŠ¡æ•°æ®éœ€è¦ä»æ•°æ®æºè·å–\n"
            report += "ğŸ’¡ å»ºè®®: å¯ç”¨MongoDBç¼“å­˜ä»¥è·å–å®Œæ•´çš„è´¢åŠ¡æ•°æ®\n"

            return report

        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆåŸºæœ¬é¢åˆ†æå¤±è´¥: {e}")
            return f"âŒ ç”Ÿæˆ{symbol}åŸºæœ¬é¢åˆ†æå¤±è´¥: {e}"

    def _try_fallback_fundamentals(self, symbol: str) -> str:
        """åŸºæœ¬é¢æ•°æ®é™çº§å¤„ç†"""
        logger.error(f"ğŸ”„ {self.current_source.value}å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æºè·å–åŸºæœ¬é¢...")

        # ğŸ”¥ ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆæ ¹æ®è‚¡ç¥¨ä»£ç è¯†åˆ«å¸‚åœºï¼‰
        fallback_order = self._get_data_source_priority_order(symbol)

        for source in fallback_order:
            if source != self.current_source and source in self.available_sources:
                try:
                    logger.info(f"ğŸ”„ å°è¯•å¤‡ç”¨æ•°æ®æºè·å–åŸºæœ¬é¢: {source.value}")

                    # ç›´æ¥è°ƒç”¨å…·ä½“çš„æ•°æ®æºæ–¹æ³•ï¼Œé¿å…é€’å½’
                    if source == ChinaDataSource.TUSHARE:
                        result = self._get_tushare_fundamentals(symbol)
                    elif source == ChinaDataSource.AKSHARE:
                        result = self._get_akshare_fundamentals(symbol)
                    else:
                        continue

                    if result and "âŒ" not in result:
                        logger.info(f"âœ… [æ•°æ®æ¥æº: å¤‡ç”¨æ•°æ®æº] é™çº§æˆåŠŸè·å–åŸºæœ¬é¢: {source.value}")
                        return result
                    else:
                        logger.warning(f"âš ï¸ å¤‡ç”¨æ•°æ®æº{source.value}è¿”å›é”™è¯¯ç»“æœ")

                except Exception as e:
                    logger.error(f"âŒ å¤‡ç”¨æ•°æ®æº{source.value}å¼‚å¸¸: {e}")
                    continue

        # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥ï¼Œç”ŸæˆåŸºæœ¬åˆ†æ
        logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: ç”Ÿæˆåˆ†æ] æ‰€æœ‰æ•°æ®æºå¤±è´¥ï¼Œç”ŸæˆåŸºæœ¬åˆ†æ: {symbol}")
        return self._generate_fundamentals_analysis(symbol)

    def _get_mongodb_news(self, symbol: str, hours_back: int, limit: int) -> List[Dict[str, Any]]:
        """ä»MongoDBè·å–æ–°é—»æ•°æ®"""
        try:
            from tradingagents.dataflows.cache.mongodb_cache_adapter import get_mongodb_cache_adapter
            adapter = get_mongodb_cache_adapter()

            # ä»MongoDBè·å–æ–°é—»æ•°æ®
            news_data = adapter.get_news_data(symbol, hours_back=hours_back, limit=limit)

            if news_data and len(news_data) > 0:
                logger.info(f"âœ… [æ•°æ®æ¥æº: MongoDB-æ–°é—»] æˆåŠŸè·å–: {symbol or 'å¸‚åœºæ–°é—»'} ({len(news_data)}æ¡)")
                return news_data
            else:
                logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: MongoDB] æœªæ‰¾åˆ°æ–°é—»: {symbol or 'å¸‚åœºæ–°é—»'}ï¼Œé™çº§åˆ°å…¶ä»–æ•°æ®æº")
                return self._try_fallback_news(symbol, hours_back, limit)

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: MongoDB] è·å–æ–°é—»å¤±è´¥: {e}")
            return self._try_fallback_news(symbol, hours_back, limit)

    def _get_tushare_news(self, symbol: str, hours_back: int, limit: int) -> List[Dict[str, Any]]:
        """ä»Tushareè·å–æ–°é—»æ•°æ®"""
        try:
            # Tushareæ–°é—»åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
            logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: Tushare] Tushareæ–°é—»åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨")
            return []

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: Tushare] è·å–æ–°é—»å¤±è´¥: {e}")
            return []

    def _get_akshare_news(self, symbol: str, hours_back: int, limit: int) -> List[Dict[str, Any]]:
        """ä»AKShareè·å–æ–°é—»æ•°æ®"""
        try:
            # AKShareæ–°é—»åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
            logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: AKShare] AKShareæ–°é—»åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨")
            return []

        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¥æº: AKShare] è·å–æ–°é—»å¤±è´¥: {e}")
            return []

    def _try_fallback_news(self, symbol: str, hours_back: int, limit: int) -> List[Dict[str, Any]]:
        """æ–°é—»æ•°æ®é™çº§å¤„ç†"""
        logger.error(f"ğŸ”„ {self.current_source.value}å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æºè·å–æ–°é—»...")

        # ğŸ”¥ ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆæ ¹æ®è‚¡ç¥¨ä»£ç è¯†åˆ«å¸‚åœºï¼‰
        fallback_order = self._get_data_source_priority_order(symbol)

        for source in fallback_order:
            if source != self.current_source and source in self.available_sources:
                try:
                    logger.info(f"ğŸ”„ å°è¯•å¤‡ç”¨æ•°æ®æºè·å–æ–°é—»: {source.value}")

                    # ç›´æ¥è°ƒç”¨å…·ä½“çš„æ•°æ®æºæ–¹æ³•ï¼Œé¿å…é€’å½’
                    if source == ChinaDataSource.TUSHARE:
                        result = self._get_tushare_news(symbol, hours_back, limit)
                    elif source == ChinaDataSource.AKSHARE:
                        result = self._get_akshare_news(symbol, hours_back, limit)
                    else:
                        continue

                    if result and len(result) > 0:
                        logger.info(f"âœ… [æ•°æ®æ¥æº: å¤‡ç”¨æ•°æ®æº] é™çº§æˆåŠŸè·å–æ–°é—»: {source.value}")
                        return result
                    else:
                        logger.warning(f"âš ï¸ å¤‡ç”¨æ•°æ®æº{source.value}æœªè¿”å›æ–°é—»")

                except Exception as e:
                    logger.error(f"âŒ å¤‡ç”¨æ•°æ®æº{source.value}å¼‚å¸¸: {e}")
                    continue

        # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥
        logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: æ‰€æœ‰æ•°æ®æºå¤±è´¥] æ— æ³•è·å–æ–°é—»: {symbol or 'å¸‚åœºæ–°é—»'}")
        return []


# å…¨å±€æ•°æ®æºç®¡ç†å™¨å®ä¾‹
_data_source_manager = None

def get_data_source_manager() -> DataSourceManager:
    """è·å–å…¨å±€æ•°æ®æºç®¡ç†å™¨å®ä¾‹"""
    global _data_source_manager
    if _data_source_manager is None:
        _data_source_manager = DataSourceManager()
    return _data_source_manager


def get_china_stock_data_unified(symbol: str, start_date: str, end_date: str) -> str:
    """
    ç»Ÿä¸€çš„ä¸­å›½è‚¡ç¥¨æ•°æ®è·å–æ¥å£
    è‡ªåŠ¨ä½¿ç”¨é…ç½®çš„æ•°æ®æºï¼Œæ”¯æŒå¤‡ç”¨æ•°æ®æº

    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ

    Returns:
        str: æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®
    """
    from tradingagents.utils.logging_init import get_logger


    # æ·»åŠ è¯¦ç»†çš„è‚¡ç¥¨ä»£ç è¿½è¸ªæ—¥å¿—
    logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] data_source_manager.get_china_stock_data_unified æ¥æ”¶åˆ°çš„è‚¡ç¥¨ä»£ç : '{symbol}' (ç±»å‹: {type(symbol)})")
    logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç é•¿åº¦: {len(str(symbol))}")
    logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç å­—ç¬¦: {list(str(symbol))}")

    manager = get_data_source_manager()
    logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è°ƒç”¨ manager.get_stock_dataï¼Œä¼ å…¥å‚æ•°: symbol='{symbol}', start_date='{start_date}', end_date='{end_date}'")
    result = manager.get_stock_data(symbol, start_date, end_date)
    # åˆ†æè¿”å›ç»“æœçš„è¯¦ç»†ä¿¡æ¯
    if result:
        lines = result.split('\n')
        data_lines = [line for line in lines if '2025-' in line and symbol in line]
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è¿”å›ç»“æœç»Ÿè®¡: æ€»è¡Œæ•°={len(lines)}, æ•°æ®è¡Œæ•°={len(data_lines)}, ç»“æœé•¿åº¦={len(result)}å­—ç¬¦")
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è¿”å›ç»“æœå‰500å­—ç¬¦: {result[:500]}")
        if len(data_lines) > 0:
            logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] æ•°æ®è¡Œç¤ºä¾‹: ç¬¬1è¡Œ='{data_lines[0][:100]}', æœ€å1è¡Œ='{data_lines[-1][:100]}'")
    else:
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è¿”å›ç»“æœ: None")
    return result


def get_china_stock_info_unified(symbol: str) -> Dict:
    """
    ç»Ÿä¸€çš„ä¸­å›½è‚¡ç¥¨ä¿¡æ¯è·å–æ¥å£

    Args:
        symbol: è‚¡ç¥¨ä»£ç 

    Returns:
        Dict: è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
    """
    manager = get_data_source_manager()
    return manager.get_stock_info(symbol)


# å…¨å±€æ•°æ®æºç®¡ç†å™¨å®ä¾‹
_data_source_manager = None

def get_data_source_manager() -> DataSourceManager:
    """è·å–å…¨å±€æ•°æ®æºç®¡ç†å™¨å®ä¾‹"""
    global _data_source_manager
    if _data_source_manager is None:
        _data_source_manager = DataSourceManager()
    return _data_source_manager

# ==================== å…¼å®¹æ€§æ¥å£ ====================
# ä¸ºäº†å…¼å®¹ stock_data_serviceï¼Œæä¾›ç›¸åŒçš„æ¥å£

def get_stock_data_service() -> DataSourceManager:
    """
    è·å–è‚¡ç¥¨æ•°æ®æœåŠ¡å®ä¾‹ï¼ˆå…¼å®¹ stock_data_service æ¥å£ï¼‰

    âš ï¸ æ­¤å‡½æ•°ä¸ºå…¼å®¹æ€§æ¥å£ï¼Œå®é™…è¿”å› DataSourceManager å®ä¾‹
    æ¨èç›´æ¥ä½¿ç”¨ get_data_source_manager()
    """
    return get_data_source_manager()


# ==================== ç¾è‚¡æ•°æ®æºç®¡ç†å™¨ ====================

class USDataSourceManager:
    """
    ç¾è‚¡æ•°æ®æºç®¡ç†å™¨

    æ”¯æŒçš„æ•°æ®æºï¼š
    - yfinance: è‚¡ç¥¨ä»·æ ¼å’ŒæŠ€æœ¯æŒ‡æ ‡ï¼ˆå…è´¹ï¼‰
    - alpha_vantage: åŸºæœ¬é¢å’Œæ–°é—»æ•°æ®ï¼ˆéœ€è¦API Keyï¼‰
    - finnhub: å¤‡ç”¨æ•°æ®æºï¼ˆéœ€è¦API Keyï¼‰
    - mongodb: ç¼“å­˜æ•°æ®æºï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    """

    def __init__(self):
        """åˆå§‹åŒ–ç¾è‚¡æ•°æ®æºç®¡ç†å™¨"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨ MongoDB ç¼“å­˜
        self.use_mongodb_cache = self._check_mongodb_enabled()

        # æ£€æŸ¥å¯ç”¨çš„æ•°æ®æº
        self.available_sources = self._check_available_sources()

        # è®¾ç½®é»˜è®¤æ•°æ®æº
        self.default_source = self._get_default_source()
        self.current_source = self.default_source

        logger.info(f"ğŸ“Š ç¾è‚¡æ•°æ®æºç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   MongoDBç¼“å­˜: {'âœ… å·²å¯ç”¨' if self.use_mongodb_cache else 'âŒ æœªå¯ç”¨'}")
        logger.info(f"   é»˜è®¤æ•°æ®æº: {self.default_source.value}")
        logger.info(f"   å¯ç”¨æ•°æ®æº: {[s.value for s in self.available_sources]}")

    def _check_mongodb_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨MongoDBç¼“å­˜"""
        from tradingagents.config.runtime_settings import use_app_cache_enabled
        return use_app_cache_enabled()

    def _get_data_source_priority_order(self, symbol: Optional[str] = None) -> List[USDataSource]:
        """
        ä»æ•°æ®åº“è·å–ç¾è‚¡æ•°æ®æºä¼˜å…ˆçº§é¡ºåºï¼ˆç”¨äºé™çº§ï¼‰

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            æŒ‰ä¼˜å…ˆçº§æ’åºçš„æ•°æ®æºåˆ—è¡¨ï¼ˆä¸åŒ…å«MongoDBï¼‰
        """
        try:
            # ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®
            from app.core.database import get_mongo_db_sync
            db = get_mongo_db_sync()

            # æ–¹æ³•1: ä» datasource_groupings é›†åˆè¯»å–ï¼ˆæ¨èï¼‰
            groupings_collection = db.datasource_groupings
            groupings = list(groupings_collection.find({
                "market_category_id": "us_stocks",
                "enabled": True
            }).sort("priority", -1))  # é™åºæ’åºï¼Œä¼˜å…ˆçº§é«˜çš„åœ¨å‰

            if groupings:
                # è½¬æ¢ä¸º USDataSource æšä¸¾
                # ğŸ”¥ æ•°æ®æºåç§°æ˜ å°„ï¼ˆæ•°æ®åº“åç§° â†’ USDataSource æšä¸¾ï¼‰
                source_mapping = {
                    'yfinance': USDataSource.YFINANCE,
                    'yahoo_finance': USDataSource.YFINANCE,  # åˆ«å
                    'alpha_vantage': USDataSource.ALPHA_VANTAGE,
                    'finnhub': USDataSource.FINNHUB,
                }

                result = []
                for grouping in groupings:
                    ds_name = grouping.get('data_source_name', '').lower()
                    if ds_name in source_mapping:
                        source = source_mapping[ds_name]
                        # æ’é™¤ MongoDBï¼ˆMongoDB æ˜¯æœ€é«˜ä¼˜å…ˆçº§ï¼Œä¸å‚ä¸é™çº§ï¼‰
                        if source != USDataSource.MONGODB and source in self.available_sources:
                            result.append(source)

                if result:
                    logger.info(f"âœ… [ç¾è‚¡æ•°æ®æºä¼˜å…ˆçº§] ä»æ•°æ®åº“è¯»å–: {[s.value for s in result]}")
                    return result

            logger.warning("âš ï¸ [ç¾è‚¡æ•°æ®æºä¼˜å…ˆçº§] æ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
        except Exception as e:
            logger.warning(f"âš ï¸ [ç¾è‚¡æ•°æ®æºä¼˜å…ˆçº§] ä»æ•°æ®åº“è¯»å–å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")

        # å›é€€åˆ°é»˜è®¤é¡ºåº
        # é»˜è®¤é¡ºåºï¼šyfinance > Alpha Vantage > Finnhub
        default_order = [
            USDataSource.YFINANCE,
            USDataSource.ALPHA_VANTAGE,
            USDataSource.FINNHUB,
        ]
        # åªè¿”å›å¯ç”¨çš„æ•°æ®æº
        return [s for s in default_order if s in self.available_sources]

    def _get_default_source(self) -> USDataSource:
        """è·å–é»˜è®¤æ•°æ®æº"""
        # å¦‚æœå¯ç”¨MongoDBç¼“å­˜ï¼ŒMongoDBä½œä¸ºæœ€é«˜ä¼˜å…ˆçº§æ•°æ®æº
        if self.use_mongodb_cache:
            return USDataSource.MONGODB

        # ä»ç¯å¢ƒå˜é‡è·å–ï¼Œé»˜è®¤ä½¿ç”¨ yfinance
        env_source = os.getenv('DEFAULT_US_DATA_SOURCE', DataSourceCode.YFINANCE).lower()

        # æ˜ å°„åˆ°æšä¸¾
        source_mapping = {
            DataSourceCode.YFINANCE: USDataSource.YFINANCE,
            DataSourceCode.ALPHA_VANTAGE: USDataSource.ALPHA_VANTAGE,
            DataSourceCode.FINNHUB: USDataSource.FINNHUB,
        }

        return source_mapping.get(env_source, USDataSource.YFINANCE)

    def _check_available_sources(self) -> List[USDataSource]:
        """
        æ£€æŸ¥å¯ç”¨çš„æ•°æ®æº

        ä»æ•°æ®åº“è¯»å–å¯ç”¨çŠ¶æ€ï¼Œå¹¶æ£€æŸ¥ä¾èµ–æ˜¯å¦æ»¡è¶³
        """
        available = []

        # MongoDB ç¼“å­˜
        if self.use_mongodb_cache:
            available.append(USDataSource.MONGODB)
            logger.info("âœ… MongoDBç¼“å­˜æ•°æ®æºå¯ç”¨")

        # ä»æ•°æ®åº“è¯»å–å¯ç”¨çš„æ•°æ®æºåˆ—è¡¨å’Œé…ç½®
        enabled_sources_in_db = self._get_enabled_sources_from_db()
        datasource_configs = self._get_datasource_configs_from_db()

        # æ£€æŸ¥ yfinance
        if 'yfinance' in enabled_sources_in_db:
            try:
                import yfinance
                available.append(USDataSource.YFINANCE)
                logger.info("âœ… yfinanceæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨")
            except ImportError:
                logger.warning("âš ï¸ yfinanceæ•°æ®æºä¸å¯ç”¨: æœªå®‰è£… yfinance åº“")
        else:
            logger.info("â„¹ï¸ yfinanceæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # æ£€æŸ¥ Alpha Vantage
        if 'alpha_vantage' in enabled_sources_in_db:
            try:
                # ä¼˜å…ˆä»æ•°æ®åº“é…ç½®è¯»å– API Keyï¼Œå…¶æ¬¡ä»ç¯å¢ƒå˜é‡è¯»å–
                api_key = datasource_configs.get('alpha_vantage', {}).get('api_key') or os.getenv("ALPHA_VANTAGE_API_KEY")
                if api_key:
                    available.append(USDataSource.ALPHA_VANTAGE)
                    source = "æ•°æ®åº“é…ç½®" if datasource_configs.get('alpha_vantage', {}).get('api_key') else "ç¯å¢ƒå˜é‡"
                    logger.info(f"âœ… Alpha Vantageæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨ (API Keyæ¥æº: {source})")
                else:
                    logger.warning("âš ï¸ Alpha Vantageæ•°æ®æºä¸å¯ç”¨: API Keyæœªé…ç½®ï¼ˆæ•°æ®åº“å’Œç¯å¢ƒå˜é‡å‡æœªæ‰¾åˆ°ï¼‰")
            except Exception as e:
                logger.warning(f"âš ï¸ Alpha Vantageæ•°æ®æºæ£€æŸ¥å¤±è´¥: {e}")
        else:
            logger.info("â„¹ï¸ Alpha Vantageæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        # æ£€æŸ¥ Finnhub
        if 'finnhub' in enabled_sources_in_db:
            try:
                # ä¼˜å…ˆä»æ•°æ®åº“é…ç½®è¯»å– API Keyï¼Œå…¶æ¬¡ä»ç¯å¢ƒå˜é‡è¯»å–
                api_key = datasource_configs.get('finnhub', {}).get('api_key') or os.getenv("FINNHUB_API_KEY")
                if api_key:
                    available.append(USDataSource.FINNHUB)
                    source = "æ•°æ®åº“é…ç½®" if datasource_configs.get('finnhub', {}).get('api_key') else "ç¯å¢ƒå˜é‡"
                    logger.info(f"âœ… Finnhubæ•°æ®æºå¯ç”¨ä¸”å·²å¯ç”¨ (API Keyæ¥æº: {source})")
                else:
                    logger.warning("âš ï¸ Finnhubæ•°æ®æºä¸å¯ç”¨: API Keyæœªé…ç½®ï¼ˆæ•°æ®åº“å’Œç¯å¢ƒå˜é‡å‡æœªæ‰¾åˆ°ï¼‰")
            except Exception as e:
                logger.warning(f"âš ï¸ Finnhubæ•°æ®æºæ£€æŸ¥å¤±è´¥: {e}")
        else:
            logger.info("â„¹ï¸ Finnhubæ•°æ®æºå·²åœ¨æ•°æ®åº“ä¸­ç¦ç”¨")

        return available

    def _get_enabled_sources_from_db(self) -> List[str]:
        """ä»æ•°æ®åº“è¯»å–å¯ç”¨çš„æ•°æ®æºåˆ—è¡¨"""
        try:
            from app.core.database import get_mongo_db_sync
            db = get_mongo_db_sync()

            # ä» datasource_groupings é›†åˆè¯»å–
            groupings = list(db.datasource_groupings.find({
                "market_category_id": "us_stocks",
                "enabled": True
            }))

            # ğŸ”¥ æ•°æ®æºåç§°æ˜ å°„ï¼ˆæ•°æ®åº“åç§° â†’ ä»£ç ä¸­ä½¿ç”¨çš„åç§°ï¼‰
            name_mapping = {
                'alpha vantage': 'alpha_vantage',
                'yahoo finance': 'yfinance',
                'finnhub': 'finnhub',
            }

            result = []
            for g in groupings:
                db_name = g.get('data_source_name', '').lower()
                # ä½¿ç”¨æ˜ å°„è¡¨è½¬æ¢åç§°
                code_name = name_mapping.get(db_name, db_name)
                result.append(code_name)
                logger.debug(f"ğŸ”„ æ•°æ®æºåç§°æ˜ å°„: '{db_name}' â†’ '{code_name}'")

            return result
        except Exception as e:
            logger.warning(f"âš ï¸ ä»æ•°æ®åº“è¯»å–å¯ç”¨çš„æ•°æ®æºå¤±è´¥: {e}")
            # é»˜è®¤å…¨éƒ¨å¯ç”¨
            return ['yfinance', 'alpha_vantage', 'finnhub']

    def _get_datasource_configs_from_db(self) -> dict:
        """ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®ï¼ˆåŒ…æ‹¬ API Keyï¼‰"""
        try:
            from app.core.database import get_mongo_db_sync
            db = get_mongo_db_sync()

            # ä» system_configs é›†åˆè¯»å–æ¿€æ´»çš„é…ç½®
            config = db.system_configs.find_one({"is_active": True})
            if not config:
                return {}

            # æå–æ•°æ®æºé…ç½®
            datasource_configs = config.get('data_source_configs', [])

            # æ„å»ºé…ç½®å­—å…¸ {æ•°æ®æºåç§°: {api_key, api_secret, ...}}
            result = {}
            for ds_config in datasource_configs:
                name = ds_config.get('name', '').lower()
                result[name] = {
                    'api_key': ds_config.get('api_key', ''),
                    'api_secret': ds_config.get('api_secret', ''),
                    'config_params': ds_config.get('config_params', {})
                }

            return result
        except Exception as e:
            logger.warning(f"âš ï¸ ä»æ•°æ®åº“è¯»å–æ•°æ®æºé…ç½®å¤±è´¥: {e}")
            return {}

    def get_current_source(self) -> USDataSource:
        """è·å–å½“å‰æ•°æ®æº"""
        return self.current_source

    def set_current_source(self, source: USDataSource) -> bool:
        """è®¾ç½®å½“å‰æ•°æ®æº"""
        if source in self.available_sources:
            self.current_source = source
            logger.info(f"âœ… ç¾è‚¡æ•°æ®æºå·²åˆ‡æ¢åˆ°: {source.value}")
            return True
        else:
            logger.error(f"âŒ ç¾è‚¡æ•°æ®æºä¸å¯ç”¨: {source.value}")
            return False


# å…¨å±€ç¾è‚¡æ•°æ®æºç®¡ç†å™¨å®ä¾‹
_us_data_source_manager = None

def get_us_data_source_manager() -> USDataSourceManager:
    """è·å–å…¨å±€ç¾è‚¡æ•°æ®æºç®¡ç†å™¨å®ä¾‹"""
    global _us_data_source_manager
    if _us_data_source_manager is None:
        _us_data_source_manager = USDataSourceManager()
    return _us_data_source_manager
