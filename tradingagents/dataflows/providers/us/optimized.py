#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„ç¾è‚¡æ•°æ®è·å–å·¥å…·
é›†æˆç¼“å­˜ç­–ç•¥ï¼Œå‡å°‘APIè°ƒç”¨ï¼Œæé«˜å“åº”é€Ÿåº¦
"""

import os
import time
import random
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

from typing import Optional, Dict, Any
import yfinance as yf
import pandas as pd

# å¯¼å…¥ç¼“å­˜ç®¡ç†å™¨ï¼ˆæ”¯æŒæ–°æ—§è·¯å¾„ï¼‰
try:
    from ...cache import StockDataCache
    def get_cache():
        return StockDataCache()
except ImportError:
    from ...cache_manager import get_cache

# å¯¼å…¥é…ç½®ï¼ˆæ”¯æŒæ–°æ—§è·¯å¾„ï¼‰
try:
    from ...config import get_config
except ImportError:
    def get_config():
        return {}

from tradingagents.config.runtime_settings import get_float, get_timezone_name
# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('agents')


class OptimizedUSDataProvider:
    """ä¼˜åŒ–çš„ç¾è‚¡æ•°æ®æä¾›å™¨ - é›†æˆç¼“å­˜å’ŒAPIé™åˆ¶å¤„ç†"""

    def __init__(self):
        self.cache = get_cache()
        self.config = get_config()
        self.last_api_call = 0
        self.min_api_interval = get_float("TA_US_MIN_API_INTERVAL_SECONDS", "ta_us_min_api_interval_seconds", 1.0)

        # ğŸ”¥ åˆå§‹åŒ–æ•°æ®æºç®¡ç†å™¨ï¼ˆä»æ•°æ®åº“è¯»å–é…ç½®ï¼‰
        try:
            from tradingagents.dataflows.data_source_manager import USDataSourceManager
            self.us_manager = USDataSourceManager()
            logger.info(f"âœ… ç¾è‚¡æ•°æ®æºç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ ç¾è‚¡æ•°æ®æºç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨é»˜è®¤é¡ºåº")
            self.us_manager = None

        logger.info(f"ğŸ“Š ä¼˜åŒ–ç¾è‚¡æ•°æ®æä¾›å™¨åˆå§‹åŒ–å®Œæˆ")

    def _wait_for_rate_limit(self):
        """ç­‰å¾…APIé™åˆ¶"""
        current_time = time.time()
        time_since_last_call = current_time - self.last_api_call

        if time_since_last_call < self.min_api_interval:
            wait_time = self.min_api_interval - time_since_last_call
            logger.info(f"â³ APIé™åˆ¶ç­‰å¾… {wait_time:.1f}s...")
            time.sleep(wait_time)

        self.last_api_call = time.time()

    def get_stock_data(self, symbol: str, start_date: str, end_date: str,
                      force_refresh: bool = False) -> str:
        """
        è·å–ç¾è‚¡æ•°æ® - ä¼˜å…ˆä½¿ç”¨ç¼“å­˜

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜

        Returns:
            æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®å­—ç¬¦ä¸²
        """
        logger.info(f"ğŸ“ˆ è·å–ç¾è‚¡æ•°æ®: {symbol} ({start_date} åˆ° {end_date})")

        # æ£€æŸ¥ç¼“å­˜ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
        if not force_refresh:
            # ğŸ”¥ æŒ‰ç…§æ•°æ®æºä¼˜å…ˆçº§é¡ºåºæŸ¥æ‰¾ç¼“å­˜
            from ...data_source_manager import get_us_data_source_manager, USDataSource
            us_manager = get_us_data_source_manager()

            # è·å–æ•°æ®æºä¼˜å…ˆçº§é¡ºåº
            priority_order = us_manager._get_data_source_priority_order(symbol)

            # æ•°æ®æºåç§°æ˜ å°„
            source_name_mapping = {
                USDataSource.ALPHA_VANTAGE: "alpha_vantage",
                USDataSource.YFINANCE: "yfinance",
                USDataSource.FINNHUB: "finnhub",
            }

            # æŒ‰ä¼˜å…ˆçº§é¡ºåºæŸ¥æ‰¾ç¼“å­˜
            for source in priority_order:
                if source == USDataSource.MONGODB:
                    continue  # MongoDB ç¼“å­˜å•ç‹¬å¤„ç†

                source_name = source_name_mapping.get(source)
                if source_name:
                    cache_key = self.cache.find_cached_stock_data(
                        symbol=symbol,
                        start_date=start_date,
                        end_date=end_date,
                        data_source=source_name
                    )

                    if cache_key:
                        cached_data = self.cache.load_stock_data(cache_key)
                        if cached_data:
                            logger.info(f"âš¡ [æ•°æ®æ¥æº: ç¼“å­˜-{source_name}] ä»ç¼“å­˜åŠ è½½ç¾è‚¡æ•°æ®: {symbol}")
                            return cached_data

        # ç¼“å­˜æœªå‘½ä¸­ï¼Œä»APIè·å– - ä½¿ç”¨æ•°æ®æºç®¡ç†å™¨çš„ä¼˜å…ˆçº§é¡ºåº
        formatted_data = None
        data_source = None

        # ğŸ”¥ ä»æ•°æ®æºç®¡ç†å™¨è·å–ä¼˜å…ˆçº§é¡ºåº
        if self.us_manager:
            try:
                source_priority = self.us_manager._get_data_source_priority_order(symbol)
                logger.info(f"ğŸ“Š [ç¾è‚¡æ•°æ®æºä¼˜å…ˆçº§] ä»æ•°æ®åº“è¯»å–: {[s.value for s in source_priority]}")
            except Exception as e:
                logger.warning(f"âš ï¸ è·å–æ•°æ®æºä¼˜å…ˆçº§å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
                source_priority = None
        else:
            source_priority = None

        # å¦‚æœæ²¡æœ‰é…ç½®ä¼˜å…ˆçº§ï¼Œä½¿ç”¨é»˜è®¤é¡ºåº
        if not source_priority:
            # é»˜è®¤é¡ºåºï¼šyfinance > alpha_vantage > finnhub
            from tradingagents.dataflows.data_source_manager import USDataSource
            source_priority = [USDataSource.YFINANCE, USDataSource.ALPHA_VANTAGE, USDataSource.FINNHUB]
            logger.info(f"ğŸ“Š [ç¾è‚¡æ•°æ®æºä¼˜å…ˆçº§] ä½¿ç”¨é»˜è®¤é¡ºåº: {[s.value for s in source_priority]}")

        # æŒ‰ä¼˜å…ˆçº§å°è¯•å„ä¸ªæ•°æ®æº
        for source in source_priority:
            try:
                source_name = source.value
                logger.info(f"ğŸŒ [æ•°æ®æ¥æº: APIè°ƒç”¨-{source_name.upper()}] å°è¯•ä» {source_name.upper()} è·å–æ•°æ®: {symbol}")
                self._wait_for_rate_limit()

                # æ ¹æ®æ•°æ®æºç±»å‹è°ƒç”¨ä¸åŒçš„æ–¹æ³•
                if source_name == 'finnhub':
                    formatted_data = self._get_data_from_finnhub(symbol, start_date, end_date)
                elif source_name == 'alpha_vantage':
                    formatted_data = self._get_data_from_alpha_vantage(symbol, start_date, end_date)
                elif source_name == 'yfinance':
                    formatted_data = self._get_data_from_yfinance(symbol, start_date, end_date)
                else:
                    logger.warning(f"âš ï¸ æœªçŸ¥çš„æ•°æ®æºç±»å‹: {source_name}")
                    continue

                if formatted_data and "âŒ" not in formatted_data:
                    data_source = source_name
                    logger.info(f"âœ… [æ•°æ®æ¥æº: APIè°ƒç”¨æˆåŠŸ-{source_name.upper()}] {source_name.upper()} æ•°æ®è·å–æˆåŠŸ: {symbol}")
                    break  # æˆåŠŸè·å–æ•°æ®ï¼Œè·³å‡ºå¾ªç¯
                else:
                    logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: APIå¤±è´¥-{source_name.upper()}] {source_name.upper()} æ•°æ®è·å–å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ•°æ®æº")
                    formatted_data = None

            except Exception as e:
                logger.error(f"âŒ [æ•°æ®æ¥æº: APIå¼‚å¸¸-{source.value.upper()}] {source.value.upper()} APIè°ƒç”¨å¤±è´¥: {e}")
                formatted_data = None
                continue  # å°è¯•ä¸‹ä¸€ä¸ªæ•°æ®æº

        # å¦‚æœæ‰€æœ‰é…ç½®çš„æ•°æ®æºéƒ½å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ
        if not formatted_data:
            try:
                # æ£€æµ‹è‚¡ç¥¨ç±»å‹
                from tradingagents.utils.stock_utils import StockUtils
                market_info = StockUtils.get_market_info(symbol)

                if market_info['is_hk']:
                    # æ¸¯è‚¡ä¼˜å…ˆä½¿ç”¨AKShareæ•°æ®æº
                    logger.info(f"ğŸ‡­ğŸ‡° [æ•°æ®æ¥æº: APIè°ƒç”¨-AKShare] å°è¯•ä½¿ç”¨AKShareè·å–æ¸¯è‚¡æ•°æ®: {symbol}")
                    try:
                        from tradingagents.dataflows.interface import get_hk_stock_data_unified
                        hk_data_text = get_hk_stock_data_unified(symbol, start_date, end_date)

                        if hk_data_text and "âŒ" not in hk_data_text:
                            formatted_data = hk_data_text
                            data_source = "akshare_hk"
                            logger.info(f"âœ… [æ•°æ®æ¥æº: APIè°ƒç”¨æˆåŠŸ-AKShare] AKShareæ¸¯è‚¡æ•°æ®è·å–æˆåŠŸ: {symbol}")
                        else:
                            raise Exception("AKShareæ¸¯è‚¡æ•°æ®è·å–å¤±è´¥")

                    except Exception as e:
                        logger.error(f"âš ï¸ [æ•°æ®æ¥æº: APIå¤±è´¥-AKShare] AKShareæ¸¯è‚¡æ•°æ®è·å–å¤±è´¥: {e}")
                        # å¤‡ç”¨æ–¹æ¡ˆï¼šYahoo Finance
                        logger.info(f"ğŸ”„ [æ•°æ®æ¥æº: APIè°ƒç”¨-Yahoo Financeå¤‡ç”¨] ä½¿ç”¨Yahoo Financeå¤‡ç”¨æ–¹æ¡ˆè·å–æ¸¯è‚¡æ•°æ®: {symbol}")

                        self._wait_for_rate_limit()
                        ticker = yf.Ticker(symbol)  # æ¸¯è‚¡ä»£ç ä¿æŒåŸæ ¼å¼
                        data = ticker.history(start=start_date, end=end_date)

                        if not data.empty:
                            formatted_data = self._format_stock_data(symbol, data, start_date, end_date)
                            data_source = "yfinance_hk"
                            logger.info(f"âœ… [æ•°æ®æ¥æº: APIè°ƒç”¨æˆåŠŸ-Yahoo Finance] Yahoo Financeæ¸¯è‚¡æ•°æ®è·å–æˆåŠŸ: {symbol}")
                        else:
                            logger.error(f"âŒ [æ•°æ®æ¥æº: APIå¤±è´¥-Yahoo Finance] Yahoo Financeæ¸¯è‚¡æ•°æ®ä¸ºç©º: {symbol}")
                else:
                    # ç¾è‚¡ä½¿ç”¨Yahoo Finance
                    logger.info(f"ğŸ‡ºğŸ‡¸ [æ•°æ®æ¥æº: APIè°ƒç”¨-Yahoo Finance] ä»Yahoo Finance APIè·å–ç¾è‚¡æ•°æ®: {symbol}")
                    self._wait_for_rate_limit()

                    # è·å–æ•°æ®
                    ticker = yf.Ticker(symbol.upper())
                    data = ticker.history(start=start_date, end=end_date)

                    if data.empty:
                        error_msg = f"æœªæ‰¾åˆ°è‚¡ç¥¨ '{symbol}' åœ¨ {start_date} åˆ° {end_date} æœŸé—´çš„æ•°æ®"
                        logger.error(f"âŒ [æ•°æ®æ¥æº: APIå¤±è´¥-Yahoo Finance] {error_msg}")
                    else:
                        # æ ¼å¼åŒ–æ•°æ®
                        formatted_data = self._format_stock_data(symbol, data, start_date, end_date)
                        data_source = "yfinance"
                        logger.info(f"âœ… [æ•°æ®æ¥æº: APIè°ƒç”¨æˆåŠŸ-Yahoo Finance] Yahoo Financeç¾è‚¡æ•°æ®è·å–æˆåŠŸ: {symbol}")

            except Exception as e:
                logger.error(f"âŒ [æ•°æ®æ¥æº: APIå¼‚å¸¸] æ•°æ®è·å–å¤±è´¥: {e}")
                formatted_data = None

        # å¦‚æœæ‰€æœ‰APIéƒ½å¤±è´¥ï¼Œç”Ÿæˆå¤‡ç”¨æ•°æ®
        if not formatted_data:
            error_msg = "æ‰€æœ‰ç¾è‚¡æ•°æ®æºéƒ½ä¸å¯ç”¨"
            logger.error(f"âŒ [æ•°æ®æ¥æº: æ‰€æœ‰APIå¤±è´¥] {error_msg}")
            logger.warning(f"âš ï¸ [æ•°æ®æ¥æº: å¤‡ç”¨æ•°æ®] ç”Ÿæˆå¤‡ç”¨æ•°æ®: {symbol}")
            return self._generate_fallback_data(symbol, start_date, end_date, error_msg)

        # ä¿å­˜åˆ°ç¼“å­˜
        self.cache.save_stock_data(
            symbol=symbol,
            data=formatted_data,
            start_date=start_date,
            end_date=end_date,
            data_source=data_source
        )

        logger.info(f"ğŸ’¾ [æ•°æ®æ¥æº: {data_source}] æ•°æ®å·²ç¼“å­˜: {symbol}")
        return formatted_data

    def _format_stock_data(self, symbol: str, data: pd.DataFrame,
                          start_date: str, end_date: str) -> str:
        """æ ¼å¼åŒ–è‚¡ç¥¨æ•°æ®ä¸ºå­—ç¬¦ä¸²"""

        # ç§»é™¤æ—¶åŒºä¿¡æ¯
        if data.index.tz is not None:
            data.index = data.index.tz_localize(None)

        # å››èˆäº”å…¥æ•°å€¼
        numeric_columns = ["Open", "High", "Low", "Close", "Adj Close"]
        for col in numeric_columns:
            if col in data.columns:
                data[col] = data[col].round(2)

        # è·å–æœ€æ–°ä»·æ ¼å’Œç»Ÿè®¡ä¿¡æ¯
        latest_price = data['Close'].iloc[-1]
        price_change = data['Close'].iloc[-1] - data['Close'].iloc[0]
        price_change_pct = (price_change / data['Close'].iloc[0]) * 100

        # ğŸ”¥ ä½¿ç”¨ç»Ÿä¸€çš„æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å‡½æ•°
        # æ³¨æ„ï¼šç¾è‚¡æ•°æ®åˆ—åæ˜¯å¤§å†™çš„ Close, High, Low
        from tradingagents.tools.analysis.indicators import add_all_indicators
        data = add_all_indicators(data, close_col='Close', high_col='High', low_col='Low')

        # è·å–æœ€æ–°æŠ€æœ¯æŒ‡æ ‡
        latest = data.iloc[-1]

        # æ ¼å¼åŒ–è¾“å‡º
        result = f"""# {symbol} ç¾è‚¡æ•°æ®åˆ†æ

## ğŸ“Š åŸºæœ¬ä¿¡æ¯
- è‚¡ç¥¨ä»£ç : {symbol}
- æ•°æ®æœŸé—´: {start_date} è‡³ {end_date}
- æ•°æ®æ¡æ•°: {len(data)}æ¡
- æœ€æ–°ä»·æ ¼: ${latest_price:.2f}
- æœŸé—´æ¶¨è·Œ: ${price_change:+.2f} ({price_change_pct:+.2f}%)

## ğŸ“ˆ ä»·æ ¼ç»Ÿè®¡
- æœŸé—´æœ€é«˜: ${data['High'].max():.2f}
- æœŸé—´æœ€ä½: ${data['Low'].min():.2f}
- å¹³å‡æˆäº¤é‡: {data['Volume'].mean():,.0f}

## ğŸ” æŠ€æœ¯æŒ‡æ ‡ï¼ˆæœ€æ–°å€¼ï¼‰
**ç§»åŠ¨å¹³å‡çº¿**:
- MA5: ${latest['ma5']:.2f}
- MA10: ${latest['ma10']:.2f}
- MA20: ${latest['ma20']:.2f}
- MA60: ${latest['ma60']:.2f}

**MACDæŒ‡æ ‡**:
- DIF: {latest['macd_dif']:.2f}
- DEA: {latest['macd_dea']:.2f}
- MACD: {latest['macd']:.2f}

**RSIæŒ‡æ ‡**:
- RSI(14): {latest['rsi']:.2f}

**å¸ƒæ—å¸¦**:
- ä¸Šè½¨: ${latest['boll_upper']:.2f}
- ä¸­è½¨: ${latest['boll_mid']:.2f}
- ä¸‹è½¨: ${latest['boll_lower']:.2f}

## ğŸ“‹ æœ€è¿‘5æ—¥æ•°æ®
{data[['Open', 'High', 'Low', 'Close', 'Volume']].tail().to_string()}

æ•°æ®æ¥æº: Yahoo Finance API
æ›´æ–°æ—¶é—´: {datetime.now(ZoneInfo(get_timezone_name())).strftime('%Y-%m-%d %H:%M:%S')}
"""

        return result

    def _try_get_old_cache(self, symbol: str, start_date: str, end_date: str) -> Optional[str]:
        """å°è¯•è·å–è¿‡æœŸçš„ç¼“å­˜æ•°æ®ä½œä¸ºå¤‡ç”¨"""
        try:
            # æŸ¥æ‰¾ä»»ä½•ç›¸å…³çš„ç¼“å­˜ï¼Œä¸è€ƒè™‘TTL
            for metadata_file in self.cache.metadata_dir.glob(f"*_meta.json"):
                try:
                    import json
                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)

                    if (metadata.get('symbol') == symbol and
                        metadata.get('data_type') == 'stock_data' and
                        metadata.get('market_type') == 'us'):

                        cache_key = metadata_file.stem.replace('_meta', '')
                        cached_data = self.cache.load_stock_data(cache_key)
                        if cached_data:
                            return cached_data + "\n\nâš ï¸ æ³¨æ„: ä½¿ç”¨çš„æ˜¯è¿‡æœŸç¼“å­˜æ•°æ®"
                except Exception:
                    continue
        except Exception:
            pass

        return None

    def _get_data_from_finnhub(self, symbol: str, start_date: str, end_date: str) -> str:
        """ä»FINNHUB APIè·å–è‚¡ç¥¨æ•°æ®"""
        try:
            import finnhub
            import os
            from datetime import datetime, timedelta


            # è·å–APIå¯†é’¥
            api_key = os.getenv('FINNHUB_API_KEY')
            if not api_key:
                return None

            client = finnhub.Client(api_key=api_key)

            # è·å–å®æ—¶æŠ¥ä»·
            quote = client.quote(symbol.upper())
            if not quote or 'c' not in quote:
                return None

            # è·å–å…¬å¸ä¿¡æ¯
            profile = client.company_profile2(symbol=symbol.upper())
            company_name = profile.get('name', symbol.upper()) if profile else symbol.upper()

            # æ ¼å¼åŒ–æ•°æ®
            current_price = quote.get('c', 0)
            change = quote.get('d', 0)
            change_percent = quote.get('dp', 0)

            formatted_data = f"""# {symbol.upper()} ç¾è‚¡æ•°æ®åˆ†æ

## ğŸ“Š å®æ—¶è¡Œæƒ…
- è‚¡ç¥¨åç§°: {company_name}
- å½“å‰ä»·æ ¼: ${current_price:.2f}
- æ¶¨è·Œé¢: ${change:+.2f}
- æ¶¨è·Œå¹…: {change_percent:+.2f}%
- å¼€ç›˜ä»·: ${quote.get('o', 0):.2f}
- æœ€é«˜ä»·: ${quote.get('h', 0):.2f}
- æœ€ä½ä»·: ${quote.get('l', 0):.2f}
- å‰æ”¶ç›˜: ${quote.get('pc', 0):.2f}
- æ›´æ–°æ—¶é—´: {datetime.now(ZoneInfo(get_timezone_name())).strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“ˆ æ•°æ®æ¦‚è§ˆ
- æ•°æ®æœŸé—´: {start_date} è‡³ {end_date}
- æ•°æ®æ¥æº: FINNHUB API (å®æ—¶æ•°æ®)
- å½“å‰ä»·ä½ç›¸å¯¹ä½ç½®: {((current_price - quote.get('l', current_price)) / max(quote.get('h', current_price) - quote.get('l', current_price), 0.01) * 100):.1f}%
- æ—¥å†…æŒ¯å¹…: {((quote.get('h', 0) - quote.get('l', 0)) / max(quote.get('pc', 1), 0.01) * 100):.2f}%

ç”Ÿæˆæ—¶é—´: {datetime.now(ZoneInfo(get_timezone_name())).strftime('%Y-%m-%d %H:%M:%S')}
"""

            return formatted_data

        except Exception as e:
            logger.error(f"âŒ FINNHUBæ•°æ®è·å–å¤±è´¥: {e}")
            return None

    def _get_data_from_yfinance(self, symbol: str, start_date: str, end_date: str) -> str:
        """ä» Yahoo Finance API è·å–è‚¡ç¥¨æ•°æ®"""
        try:
            # è·å–æ•°æ®
            ticker = yf.Ticker(symbol.upper())
            data = ticker.history(start=start_date, end=end_date)

            if data.empty:
                error_msg = f"æœªæ‰¾åˆ°è‚¡ç¥¨ '{symbol}' åœ¨ {start_date} åˆ° {end_date} æœŸé—´çš„æ•°æ®"
                logger.error(f"âŒ Yahoo Financeæ•°æ®ä¸ºç©º: {error_msg}")
                return None

            # æ ¼å¼åŒ–æ•°æ®
            formatted_data = self._format_stock_data(symbol, data, start_date, end_date)
            return formatted_data

        except Exception as e:
            logger.error(f"âŒ Yahoo Financeæ•°æ®è·å–å¤±è´¥: {e}")
            return None

    def _get_data_from_alpha_vantage(self, symbol: str, start_date: str, end_date: str) -> str:
        """ä» Alpha Vantage API è·å–è‚¡ç¥¨æ•°æ®"""
        try:
            from tradingagents.dataflows.providers.us.alpha_vantage_common import get_api_key
            import requests
            from datetime import datetime

            # è·å– API Key
            api_key = get_api_key()
            if not api_key:
                logger.warning("âš ï¸ Alpha Vantage API Key æœªé…ç½®")
                return None

            # è°ƒç”¨ Alpha Vantage API (TIME_SERIES_DAILY)
            url = f"https://www.alphavantage.co/query"
            params = {
                "function": "TIME_SERIES_DAILY",
                "symbol": symbol.upper(),
                "apikey": api_key,
                "outputsize": "full"  # è·å–å®Œæ•´å†å²æ•°æ®
            }

            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()
            data_json = response.json()

            # æ£€æŸ¥é”™è¯¯
            if "Error Message" in data_json:
                logger.error(f"âŒ Alpha Vantage API é”™è¯¯: {data_json['Error Message']}")
                return None

            if "Note" in data_json:
                logger.warning(f"âš ï¸ Alpha Vantage API é™åˆ¶: {data_json['Note']}")
                return None

            # è§£ææ—¶é—´åºåˆ—æ•°æ®
            time_series = data_json.get("Time Series (Daily)", {})
            if not time_series:
                logger.error("âŒ Alpha Vantage è¿”å›æ•°æ®ä¸ºç©º")
                return None

            # è½¬æ¢ä¸º DataFrame
            df = pd.DataFrame.from_dict(time_series, orient='index')
            df.index = pd.to_datetime(df.index)
            df = df.sort_index()

            # é‡å‘½ååˆ—
            df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']
            df = df.astype(float)

            # è¿‡æ»¤æ—¥æœŸèŒƒå›´
            df = df[(df.index >= start_date) & (df.index <= end_date)]

            if df.empty:
                logger.error(f"âŒ Alpha Vantage æ•°æ®åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…ä¸ºç©º")
                return None

            # æ ¼å¼åŒ–æ•°æ®
            formatted_data = self._format_stock_data(symbol, df, start_date, end_date)
            return formatted_data

        except Exception as e:
            logger.error(f"âŒ Alpha Vantageæ•°æ®è·å–å¤±è´¥: {e}")
            return None

    def _generate_fallback_data(self, symbol: str, start_date: str, end_date: str, error_msg: str) -> str:
        """ç”Ÿæˆå¤‡ç”¨æ•°æ®"""
        return f"""# {symbol} ç¾è‚¡æ•°æ®è·å–å¤±è´¥

## âŒ é”™è¯¯ä¿¡æ¯
{error_msg}

## ğŸ“Š æ¨¡æ‹Ÿæ•°æ®ï¼ˆä»…ä¾›æ¼”ç¤ºï¼‰
- è‚¡ç¥¨ä»£ç : {symbol}
- æ•°æ®æœŸé—´: {start_date} è‡³ {end_date}
- æœ€æ–°ä»·æ ¼: ${random.uniform(100, 300):.2f}
- æ¨¡æ‹Ÿæ¶¨è·Œ: {random.uniform(-5, 5):+.2f}%

## âš ï¸ é‡è¦æç¤º
ç”±äºAPIé™åˆ¶æˆ–ç½‘ç»œé—®é¢˜ï¼Œæ— æ³•è·å–å®æ—¶æ•°æ®ã€‚
å»ºè®®ç¨åé‡è¯•æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚

ç”Ÿæˆæ—¶é—´: {datetime.now(ZoneInfo(get_timezone_name())).strftime('%Y-%m-%d %H:%M:%S')}
"""


# å…¨å±€å®ä¾‹
_us_data_provider = None

def get_optimized_us_data_provider() -> OptimizedUSDataProvider:
    """è·å–å…¨å±€ç¾è‚¡æ•°æ®æä¾›å™¨å®ä¾‹"""
    global _us_data_provider
    if _us_data_provider is None:
        _us_data_provider = OptimizedUSDataProvider()
    return _us_data_provider


def get_us_stock_data_cached(symbol: str, start_date: str, end_date: str,
                           force_refresh: bool = False) -> str:
    """
    è·å–ç¾è‚¡æ•°æ®çš„ä¾¿æ·å‡½æ•°

    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜

    Returns:
        æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®å­—ç¬¦ä¸²
    """
    # ğŸ”§ æ™ºèƒ½æ—¥æœŸèŒƒå›´å¤„ç†ï¼šè‡ªåŠ¨æ‰©å±•åˆ°é…ç½®çš„å›æº¯å¤©æ•°ï¼Œå¤„ç†å‘¨æœ«/èŠ‚å‡æ—¥
    from tradingagents.utils.dataflow_utils import get_trading_date_range
    from app.core.config import get_settings
    from datetime import datetime

    original_start_date = start_date
    original_end_date = end_date

    # ä»é…ç½®è·å–å¸‚åœºåˆ†æå›æº¯å¤©æ•°ï¼ˆé»˜è®¤60å¤©ï¼‰
    try:
        settings = get_settings()
        lookback_days = settings.MARKET_ANALYST_LOOKBACK_DAYS
        logger.info(f"ğŸ“… [ç¾è‚¡é…ç½®éªŒè¯] MARKET_ANALYST_LOOKBACK_DAYS: {lookback_days}å¤©")
    except Exception as e:
        lookback_days = 60  # é»˜è®¤60å¤©
        logger.warning(f"âš ï¸ [ç¾è‚¡é…ç½®éªŒè¯] æ— æ³•è·å–é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼: {lookback_days}å¤©")
        logger.warning(f"âš ï¸ [ç¾è‚¡é…ç½®éªŒè¯] é”™è¯¯è¯¦æƒ…: {e}")

    # ä½¿ç”¨ end_date ä½œä¸ºç›®æ ‡æ—¥æœŸï¼Œå‘å‰å›æº¯æŒ‡å®šå¤©æ•°
    start_date, end_date = get_trading_date_range(end_date, lookback_days=lookback_days)

    logger.info(f"ğŸ“… [ç¾è‚¡æ™ºèƒ½æ—¥æœŸ] åŸå§‹è¾“å…¥: {original_start_date} è‡³ {original_end_date}")
    logger.info(f"ğŸ“… [ç¾è‚¡æ™ºèƒ½æ—¥æœŸ] å›æº¯å¤©æ•°: {lookback_days}å¤©")
    logger.info(f"ğŸ“… [ç¾è‚¡æ™ºèƒ½æ—¥æœŸ] è®¡ç®—ç»“æœ: {start_date} è‡³ {end_date}")
    logger.info(f"ğŸ“… [ç¾è‚¡æ™ºèƒ½æ—¥æœŸ] å®é™…å¤©æ•°: {(datetime.strptime(end_date, '%Y-%m-%d') - datetime.strptime(start_date, '%Y-%m-%d')).days}å¤©")

    provider = get_optimized_us_data_provider()
    return provider.get_stock_data(symbol, start_date, end_date, force_refresh)
