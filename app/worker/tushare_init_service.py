"""
Tushareæ•°æ®åˆå§‹åŒ–æœåŠ¡
ç”¨äºé¦–æ¬¡éƒ¨ç½²æ—¶çš„å®Œæ•´æ•°æ®åˆå§‹åŒ–ï¼ŒåŒ…æ‹¬åŸºç¡€æ•°æ®ã€å†å²æ•°æ®ã€è´¢åŠ¡æ•°æ®ç­‰
"""
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
from dataclasses import dataclass

from app.core.database import get_mongo_db
from app.worker.tushare_sync_service import get_tushare_sync_service

logger = logging.getLogger(__name__)


@dataclass
class InitializationStats:
    """åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯"""
    started_at: datetime
    finished_at: Optional[datetime] = None
    total_steps: int = 0
    completed_steps: int = 0
    current_step: str = ""
    basic_info_count: int = 0
    historical_records: int = 0
    weekly_records: int = 0
    monthly_records: int = 0
    financial_records: int = 0
    quotes_count: int = 0
    news_count: int = 0
    errors: List[Dict[str, Any]] = None

    def __post_init__(self):
        if self.errors is None:
            self.errors = []


class TushareInitService:
    """
    Tushareæ•°æ®åˆå§‹åŒ–æœåŠ¡
    
    è´Ÿè´£é¦–æ¬¡éƒ¨ç½²æ—¶çš„å®Œæ•´æ•°æ®åˆå§‹åŒ–ï¼š
    1. æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
    2. åˆå§‹åŒ–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
    3. åŒæ­¥å†å²æ•°æ®ï¼ˆå¯é…ç½®æ—¶é—´èŒƒå›´ï¼‰
    4. åŒæ­¥è´¢åŠ¡æ•°æ®
    5. åŒæ­¥æœ€æ–°è¡Œæƒ…æ•°æ®
    6. éªŒè¯æ•°æ®å®Œæ•´æ€§
    """
    
    def __init__(self):
        self.db = None
        self.sync_service = None
        self.stats = None
    
    async def initialize(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        self.db = get_mongo_db()
        self.sync_service = await get_tushare_sync_service()
        logger.info("âœ… Tushareåˆå§‹åŒ–æœåŠ¡å‡†å¤‡å®Œæˆ")
    
    async def run_full_initialization(
        self,
        historical_days: int = 365,
        skip_if_exists: bool = True,
        batch_size: int = 100,
        enable_multi_period: bool = False,
        sync_items: List[str] = None
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„æ•°æ®åˆå§‹åŒ–

        Args:
            historical_days: å†å²æ•°æ®å¤©æ•°ï¼ˆé»˜è®¤1å¹´ï¼‰
            skip_if_exists: å¦‚æœæ•°æ®å·²å­˜åœ¨æ˜¯å¦è·³è¿‡
            batch_size: æ‰¹å¤„ç†å¤§å°
            enable_multi_period: æ˜¯å¦å¯ç”¨å¤šå‘¨æœŸæ•°æ®åŒæ­¥ï¼ˆæ—¥çº¿ã€å‘¨çº¿ã€æœˆçº¿ï¼‰
            sync_items: è¦åŒæ­¥çš„æ•°æ®ç±»å‹åˆ—è¡¨ï¼Œå¯é€‰å€¼ï¼š
                - 'basic_info': è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
                - 'historical': å†å²è¡Œæƒ…æ•°æ®ï¼ˆæ—¥çº¿ï¼‰
                - 'weekly': å‘¨çº¿æ•°æ®
                - 'monthly': æœˆçº¿æ•°æ®
                - 'financial': è´¢åŠ¡æ•°æ®
                - 'quotes': æœ€æ–°è¡Œæƒ…
                - 'news': æ–°é—»æ•°æ®
                - None: åŒæ­¥æ‰€æœ‰æ•°æ®ï¼ˆé»˜è®¤ï¼‰

        Returns:
            åˆå§‹åŒ–ç»“æœç»Ÿè®¡
        """
        # å¦‚æœæœªæŒ‡å®šsync_itemsï¼Œåˆ™åŒæ­¥æ‰€æœ‰æ•°æ®
        if sync_items is None:
            sync_items = ['basic_info', 'historical', 'financial', 'quotes']
            if enable_multi_period:
                sync_items.extend(['weekly', 'monthly'])

        logger.info(f"ğŸš€ å¼€å§‹Tushareæ•°æ®åˆå§‹åŒ–...")
        logger.info(f"ğŸ“‹ åŒæ­¥é¡¹ç›®: {', '.join(sync_items)}")

        # è®¡ç®—æ€»æ­¥éª¤æ•°ï¼ˆæ£€æŸ¥çŠ¶æ€ + åŒæ­¥é¡¹ç›®æ•° + éªŒè¯ï¼‰
        total_steps = 1 + len(sync_items) + 1

        self.stats = InitializationStats(
            started_at=datetime.utcnow(),
            total_steps=total_steps
        )

        try:
            # æ­¥éª¤1: æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
            await self._step_check_database_status(skip_if_exists)

            # æ­¥éª¤2: åˆå§‹åŒ–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
            if 'basic_info' in sync_items:
                await self._step_initialize_basic_info()
            else:
                logger.info("â­ï¸ è·³è¿‡è‚¡ç¥¨åŸºç¡€ä¿¡æ¯åŒæ­¥")

            # æ­¥éª¤3: åŒæ­¥å†å²æ•°æ®ï¼ˆæ—¥çº¿ï¼‰
            if 'historical' in sync_items:
                await self._step_initialize_historical_data(historical_days)
            else:
                logger.info("â­ï¸ è·³è¿‡å†å²æ•°æ®ï¼ˆæ—¥çº¿ï¼‰åŒæ­¥")

            # æ­¥éª¤4: åŒæ­¥å‘¨çº¿æ•°æ®
            if 'weekly' in sync_items:
                await self._step_initialize_weekly_data(historical_days)
            else:
                logger.info("â­ï¸ è·³è¿‡å‘¨çº¿æ•°æ®åŒæ­¥")

            # æ­¥éª¤5: åŒæ­¥æœˆçº¿æ•°æ®
            if 'monthly' in sync_items:
                await self._step_initialize_monthly_data(historical_days)
            else:
                logger.info("â­ï¸ è·³è¿‡æœˆçº¿æ•°æ®åŒæ­¥")

            # æ­¥éª¤6: åŒæ­¥è´¢åŠ¡æ•°æ®
            if 'financial' in sync_items:
                await self._step_initialize_financial_data()
            else:
                logger.info("â­ï¸ è·³è¿‡è´¢åŠ¡æ•°æ®åŒæ­¥")

            # æ­¥éª¤7: åŒæ­¥æœ€æ–°è¡Œæƒ…
            if 'quotes' in sync_items:
                await self._step_initialize_quotes()
            else:
                logger.info("â­ï¸ è·³è¿‡æœ€æ–°è¡Œæƒ…åŒæ­¥")

            # æ­¥éª¤8: åŒæ­¥æ–°é—»æ•°æ®
            if 'news' in sync_items:
                await self._step_initialize_news_data(historical_days)
            else:
                logger.info("â­ï¸ è·³è¿‡æ–°é—»æ•°æ®åŒæ­¥")

            # æœ€å: éªŒè¯æ•°æ®å®Œæ•´æ€§
            await self._step_verify_data_integrity()
            
            self.stats.finished_at = datetime.utcnow()
            duration = (self.stats.finished_at - self.stats.started_at).total_seconds()
            
            logger.info(f"ğŸ‰ Tushareæ•°æ®åˆå§‹åŒ–å®Œæˆï¼è€—æ—¶: {duration:.2f}ç§’")
            
            return self._get_initialization_summary()
            
        except Exception as e:
            logger.error(f"âŒ Tushareæ•°æ®åˆå§‹åŒ–å¤±è´¥: {e}")
            self.stats.errors.append({
                "step": self.stats.current_step,
                "error": str(e),
                "timestamp": datetime.utcnow()
            })
            return self._get_initialization_summary()
    
    async def _step_check_database_status(self, skip_if_exists: bool):
        """æ­¥éª¤1: æ£€æŸ¥æ•°æ®åº“çŠ¶æ€"""
        self.stats.current_step = "æ£€æŸ¥æ•°æ®åº“çŠ¶æ€"
        logger.info(f"ğŸ“Š {self.stats.current_step}...")
        
        # æ£€æŸ¥å„é›†åˆçš„æ•°æ®é‡
        basic_count = await self.db.stock_basic_info.count_documents({})
        quotes_count = await self.db.market_quotes.count_documents({})
        
        logger.info(f"  å½“å‰æ•°æ®çŠ¶æ€:")
        logger.info(f"    è‚¡ç¥¨åŸºç¡€ä¿¡æ¯: {basic_count}æ¡")
        logger.info(f"    è¡Œæƒ…æ•°æ®: {quotes_count}æ¡")
        
        if skip_if_exists and basic_count > 0:
            logger.info("âš ï¸ æ£€æµ‹åˆ°å·²æœ‰æ•°æ®ï¼Œè·³è¿‡åˆå§‹åŒ–ï¼ˆå¯é€šè¿‡skip_if_exists=Falseå¼ºåˆ¶åˆå§‹åŒ–ï¼‰")
            raise Exception("æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
        
        self.stats.completed_steps += 1
        logger.info(f"âœ… {self.stats.current_step}å®Œæˆ")
    
    async def _step_initialize_basic_info(self):
        """æ­¥éª¤2: åˆå§‹åŒ–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯"""
        self.stats.current_step = "åˆå§‹åŒ–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯"
        logger.info(f"ğŸ“‹ {self.stats.current_step}...")
        
        # å¼ºåˆ¶æ›´æ–°æ‰€æœ‰åŸºç¡€ä¿¡æ¯
        result = await self.sync_service.sync_stock_basic_info(force_update=True)
        
        if result:
            self.stats.basic_info_count = result.get("success_count", 0)
            logger.info(f"âœ… åŸºç¡€ä¿¡æ¯åˆå§‹åŒ–å®Œæˆ: {self.stats.basic_info_count}åªè‚¡ç¥¨")
        else:
            raise Exception("åŸºç¡€ä¿¡æ¯åˆå§‹åŒ–å¤±è´¥")
        
        self.stats.completed_steps += 1
    
    async def _step_initialize_historical_data(self, historical_days: int):
        """æ­¥éª¤3: åŒæ­¥å†å²æ•°æ®"""
        self.stats.current_step = f"åŒæ­¥å†å²æ•°æ®({historical_days}å¤©)"
        logger.info(f"ğŸ“Š {self.stats.current_step}...")

        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now().strftime('%Y-%m-%d')

        # å¦‚æœ historical_days å¤§äºç­‰äº10å¹´ï¼ˆ3650å¤©ï¼‰ï¼Œåˆ™åŒæ­¥å…¨å†å²
        if historical_days >= 3650:
            start_date = "1990-01-01"  # å…¨å†å²åŒæ­¥
            logger.info(f"  å†å²æ•°æ®èŒƒå›´: å…¨å†å²ï¼ˆä»1990-01-01åˆ°{end_date}ï¼‰")
        else:
            start_date = (datetime.now() - timedelta(days=historical_days)).strftime('%Y-%m-%d')
            logger.info(f"  å†å²æ•°æ®èŒƒå›´: {start_date} åˆ° {end_date}")

        # åŒæ­¥å†å²æ•°æ®
        result = await self.sync_service.sync_historical_data(
            start_date=start_date,
            end_date=end_date,
            incremental=False  # å…¨é‡åŒæ­¥
        )
        
        if result:
            self.stats.historical_records = result.get("total_records", 0)
            logger.info(f"âœ… å†å²æ•°æ®åˆå§‹åŒ–å®Œæˆ: {self.stats.historical_records}æ¡è®°å½•")
        else:
            logger.warning("âš ï¸ å†å²æ•°æ®åˆå§‹åŒ–éƒ¨åˆ†å¤±è´¥ï¼Œç»§ç»­åç»­æ­¥éª¤")
        
        self.stats.completed_steps += 1

    async def _step_initialize_weekly_data(self, historical_days: int):
        """æ­¥éª¤4a: åŒæ­¥å‘¨çº¿æ•°æ®"""
        self.stats.current_step = f"åŒæ­¥å‘¨çº¿æ•°æ®({historical_days}å¤©)"
        logger.info(f"ğŸ“Š {self.stats.current_step}...")

        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now().strftime('%Y-%m-%d')

        # å¦‚æœ historical_days å¤§äºç­‰äº10å¹´ï¼ˆ3650å¤©ï¼‰ï¼Œåˆ™åŒæ­¥å…¨å†å²
        if historical_days >= 3650:
            start_date = "1990-01-01"  # å…¨å†å²åŒæ­¥
            logger.info(f"  å‘¨çº¿æ•°æ®èŒƒå›´: å…¨å†å²ï¼ˆä»1990-01-01åˆ°{end_date}ï¼‰")
        else:
            start_date = (datetime.now() - timedelta(days=historical_days)).strftime('%Y-%m-%d')
            logger.info(f"  å‘¨çº¿æ•°æ®èŒƒå›´: {start_date} åˆ° {end_date}")

        try:
            # åŒæ­¥å‘¨çº¿æ•°æ®
            result = await self.sync_service.sync_historical_data(
                start_date=start_date,
                end_date=end_date,
                incremental=False,
                period="weekly"  # æŒ‡å®šå‘¨çº¿
            )

            if result:
                weekly_records = result.get("total_records", 0)
                self.stats.weekly_records = weekly_records
                logger.info(f"âœ… å‘¨çº¿æ•°æ®åˆå§‹åŒ–å®Œæˆ: {weekly_records}æ¡è®°å½•")
            else:
                logger.warning("âš ï¸ å‘¨çº¿æ•°æ®åˆå§‹åŒ–éƒ¨åˆ†å¤±è´¥ï¼Œç»§ç»­åç»­æ­¥éª¤")
        except Exception as e:
            logger.warning(f"âš ï¸ å‘¨çº¿æ•°æ®åˆå§‹åŒ–å¤±è´¥: {e}ï¼ˆç»§ç»­åç»­æ­¥éª¤ï¼‰")

        self.stats.completed_steps += 1

    async def _step_initialize_monthly_data(self, historical_days: int):
        """æ­¥éª¤4b: åŒæ­¥æœˆçº¿æ•°æ®"""
        self.stats.current_step = f"åŒæ­¥æœˆçº¿æ•°æ®({historical_days}å¤©)"
        logger.info(f"ğŸ“Š {self.stats.current_step}...")

        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now().strftime('%Y-%m-%d')

        # å¦‚æœ historical_days å¤§äºç­‰äº10å¹´ï¼ˆ3650å¤©ï¼‰ï¼Œåˆ™åŒæ­¥å…¨å†å²
        if historical_days >= 3650:
            start_date = "1990-01-01"  # å…¨å†å²åŒæ­¥
            logger.info(f"  æœˆçº¿æ•°æ®èŒƒå›´: å…¨å†å²ï¼ˆä»1990-01-01åˆ°{end_date}ï¼‰")
        else:
            start_date = (datetime.now() - timedelta(days=historical_days)).strftime('%Y-%m-%d')
            logger.info(f"  æœˆçº¿æ•°æ®èŒƒå›´: {start_date} åˆ° {end_date}")

        try:
            # åŒæ­¥æœˆçº¿æ•°æ®
            result = await self.sync_service.sync_historical_data(
                start_date=start_date,
                end_date=end_date,
                incremental=False,
                period="monthly"  # æŒ‡å®šæœˆçº¿
            )

            if result:
                monthly_records = result.get("total_records", 0)
                self.stats.monthly_records = monthly_records
                logger.info(f"âœ… æœˆçº¿æ•°æ®åˆå§‹åŒ–å®Œæˆ: {monthly_records}æ¡è®°å½•")
            else:
                logger.warning("âš ï¸ æœˆçº¿æ•°æ®åˆå§‹åŒ–éƒ¨åˆ†å¤±è´¥ï¼Œç»§ç»­åç»­æ­¥éª¤")
        except Exception as e:
            logger.warning(f"âš ï¸ æœˆçº¿æ•°æ®åˆå§‹åŒ–å¤±è´¥: {e}ï¼ˆç»§ç»­åç»­æ­¥éª¤ï¼‰")

        self.stats.completed_steps += 1

    async def _step_initialize_financial_data(self):
        """æ­¥éª¤4: åŒæ­¥è´¢åŠ¡æ•°æ®"""
        self.stats.current_step = "åŒæ­¥è´¢åŠ¡æ•°æ®"
        logger.info(f"ğŸ’° {self.stats.current_step}...")
        
        try:
            result = await self.sync_service.sync_financial_data()
            
            if result:
                self.stats.financial_records = result.get("success_count", 0)
                logger.info(f"âœ… è´¢åŠ¡æ•°æ®åˆå§‹åŒ–å®Œæˆ: {self.stats.financial_records}æ¡è®°å½•")
            else:
                logger.warning("âš ï¸ è´¢åŠ¡æ•°æ®åˆå§‹åŒ–å¤±è´¥ï¼ˆå¯èƒ½éœ€è¦æ›´é«˜æƒé™ï¼‰")
        except Exception as e:
            logger.warning(f"âš ï¸ è´¢åŠ¡æ•°æ®åˆå§‹åŒ–å¤±è´¥: {e}ï¼ˆç»§ç»­åç»­æ­¥éª¤ï¼‰")
        
        self.stats.completed_steps += 1
    
    async def _step_initialize_quotes(self):
        """æ­¥éª¤5: åŒæ­¥æœ€æ–°è¡Œæƒ…"""
        self.stats.current_step = "åŒæ­¥æœ€æ–°è¡Œæƒ…"
        logger.info(f"ğŸ“ˆ {self.stats.current_step}...")

        try:
            result = await self.sync_service.sync_realtime_quotes()

            if result:
                self.stats.quotes_count = result.get("success_count", 0)
                logger.info(f"âœ… æœ€æ–°è¡Œæƒ…åˆå§‹åŒ–å®Œæˆ: {self.stats.quotes_count}åªè‚¡ç¥¨")
            else:
                logger.warning("âš ï¸ æœ€æ–°è¡Œæƒ…åˆå§‹åŒ–å¤±è´¥")
        except Exception as e:
            logger.warning(f"âš ï¸ æœ€æ–°è¡Œæƒ…åˆå§‹åŒ–å¤±è´¥: {e}ï¼ˆç»§ç»­åç»­æ­¥éª¤ï¼‰")

        self.stats.completed_steps += 1

    async def _step_initialize_news_data(self, historical_days: int):
        """æ­¥éª¤6: åŒæ­¥æ–°é—»æ•°æ®"""
        self.stats.current_step = "åŒæ­¥æ–°é—»æ•°æ®"
        logger.info(f"ğŸ“° {self.stats.current_step}...")

        try:
            # è®¡ç®—å›æº¯å°æ—¶æ•°
            hours_back = min(historical_days * 24, 24 * 7)  # æœ€å¤šå›æº¯7å¤©æ–°é—»

            result = await self.sync_service.sync_news_data(
                hours_back=hours_back,
                max_news_per_stock=20
            )

            if result:
                self.stats.news_count = result.get("news_count", 0)
                logger.info(f"âœ… æ–°é—»æ•°æ®åˆå§‹åŒ–å®Œæˆ: {self.stats.news_count}æ¡æ–°é—»")
            else:
                logger.warning("âš ï¸ æ–°é—»æ•°æ®åˆå§‹åŒ–å¤±è´¥ï¼ˆå¯èƒ½éœ€è¦Tushareæ–°é—»æƒé™ï¼‰")
        except Exception as e:
            logger.warning(f"âš ï¸ æ–°é—»æ•°æ®åˆå§‹åŒ–å¤±è´¥: {e}ï¼ˆç»§ç»­åç»­æ­¥éª¤ï¼‰")

        self.stats.completed_steps += 1

    async def _step_verify_data_integrity(self):
        """æ­¥éª¤6: éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        self.stats.current_step = "éªŒè¯æ•°æ®å®Œæ•´æ€§"
        logger.info(f"ğŸ” {self.stats.current_step}...")
        
        # æ£€æŸ¥æœ€ç»ˆæ•°æ®çŠ¶æ€
        basic_count = await self.db.stock_basic_info.count_documents({})
        quotes_count = await self.db.market_quotes.count_documents({})
        
        # æ£€æŸ¥æ•°æ®è´¨é‡
        extended_count = await self.db.stock_basic_info.count_documents({
            "full_symbol": {"$exists": True},
            "market_info": {"$exists": True}
        })
        
        logger.info(f"  æ•°æ®å®Œæ•´æ€§éªŒè¯:")
        logger.info(f"    è‚¡ç¥¨åŸºç¡€ä¿¡æ¯: {basic_count}æ¡")
        logger.info(f"    æ‰©å±•å­—æ®µè¦†ç›–: {extended_count}æ¡ ({extended_count/basic_count*100:.1f}%)")
        logger.info(f"    è¡Œæƒ…æ•°æ®: {quotes_count}æ¡")
        
        if basic_count == 0:
            raise Exception("æ•°æ®åˆå§‹åŒ–å¤±è´¥ï¼šæ— åŸºç¡€æ•°æ®")
        
        if extended_count / basic_count < 0.9:  # 90%ä»¥ä¸Šåº”è¯¥æœ‰æ‰©å±•å­—æ®µ
            logger.warning("âš ï¸ æ‰©å±•å­—æ®µè¦†ç›–ç‡è¾ƒä½ï¼Œå¯èƒ½å­˜åœ¨æ•°æ®è´¨é‡é—®é¢˜")
        
        self.stats.completed_steps += 1
        logger.info(f"âœ… {self.stats.current_step}å®Œæˆ")
    
    def _get_initialization_summary(self) -> Dict[str, Any]:
        """è·å–åˆå§‹åŒ–æ€»ç»“"""
        duration = 0
        if self.stats.finished_at:
            duration = (self.stats.finished_at - self.stats.started_at).total_seconds()
        
        return {
            "success": self.stats.completed_steps == self.stats.total_steps,
            "started_at": self.stats.started_at,
            "finished_at": self.stats.finished_at,
            "duration": duration,
            "completed_steps": self.stats.completed_steps,
            "total_steps": self.stats.total_steps,
            "progress": f"{self.stats.completed_steps}/{self.stats.total_steps}",
            "data_summary": {
                "basic_info_count": self.stats.basic_info_count,
                "historical_records": self.stats.historical_records,
                "daily_records": self.stats.historical_records,  # æ—¥çº¿æ•°æ®
                "weekly_records": self.stats.weekly_records,     # å‘¨çº¿æ•°æ®
                "monthly_records": self.stats.monthly_records,   # æœˆçº¿æ•°æ®
                "financial_records": self.stats.financial_records,
                "quotes_count": self.stats.quotes_count,
                "news_count": self.stats.news_count
            },
            "errors": self.stats.errors,
            "current_step": self.stats.current_step
        }


# å…¨å±€åˆå§‹åŒ–æœåŠ¡å®ä¾‹
_tushare_init_service = None

async def get_tushare_init_service() -> TushareInitService:
    """è·å–Tushareåˆå§‹åŒ–æœåŠ¡å®ä¾‹"""
    global _tushare_init_service
    if _tushare_init_service is None:
        _tushare_init_service = TushareInitService()
        await _tushare_init_service.initialize()
    return _tushare_init_service


# APSchedulerå…¼å®¹çš„åˆå§‹åŒ–ä»»åŠ¡å‡½æ•°
async def run_tushare_full_initialization(
    historical_days: int = 365,
    skip_if_exists: bool = True
):
    """APSchedulerä»»åŠ¡ï¼šè¿è¡Œå®Œæ•´çš„Tushareæ•°æ®åˆå§‹åŒ–"""
    try:
        service = await get_tushare_init_service()
        result = await service.run_full_initialization(
            historical_days=historical_days,
            skip_if_exists=skip_if_exists
        )
        logger.info(f"âœ… Tushareå®Œæ•´åˆå§‹åŒ–å®Œæˆ: {result}")
        return result
    except Exception as e:
        logger.error(f"âŒ Tushareå®Œæ•´åˆå§‹åŒ–å¤±è´¥: {e}")
        raise
