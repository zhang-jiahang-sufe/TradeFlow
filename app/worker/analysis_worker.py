"""
åˆ†æä»»åŠ¡Workerè¿›ç¨‹
æ¶ˆè´¹é˜Ÿåˆ—ä¸­çš„åˆ†æä»»åŠ¡ï¼Œè°ƒç”¨TradingAgentsè¿›è¡Œè‚¡ç¥¨åˆ†æ
"""

import asyncio
import logging
import signal
import sys
import uuid
import traceback
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from app.services.queue_service import get_queue_service
from app.services.analysis_service import get_analysis_service
from app.core.database import init_database, close_database
from app.core.redis_client import init_redis, close_redis
from app.core.config import settings
from app.models.analysis import AnalysisTask, AnalysisParameters
from app.services.config_provider import provider as config_provider
from app.services.queue import DEFAULT_USER_CONCURRENT_LIMIT, GLOBAL_CONCURRENT_LIMIT, VISIBILITY_TIMEOUT_SECONDS

logger = logging.getLogger(__name__)


class AnalysisWorker:
    """åˆ†æä»»åŠ¡Workerç±»"""

    def __init__(self, worker_id: Optional[str] = None):
        self.worker_id = worker_id or f"worker-{uuid.uuid4().hex[:8]}"
        self.queue_service = None
        self.running = False
        self.current_task = None

        # é…ç½®å‚æ•°ï¼ˆå¯ç”±ç³»ç»Ÿè®¾ç½®è¦†ç›–ï¼‰
        self.heartbeat_interval = int(getattr(settings, 'WORKER_HEARTBEAT_INTERVAL', 30))
        self.max_retries = int(getattr(settings, 'QUEUE_MAX_RETRIES', 3))
        self.poll_interval = float(getattr(settings, 'QUEUE_POLL_INTERVAL_SECONDS', 1))  # é˜Ÿåˆ—è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
        self.cleanup_interval = float(getattr(settings, 'QUEUE_CLEANUP_INTERVAL_SECONDS', 60))

        # æ³¨å†Œä¿¡å·å¤„ç†å™¨
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)

    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨ï¼Œä¼˜é›…å…³é—­"""
        logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œå‡†å¤‡å…³é—­Worker...")
        self.running = False

    async def start(self):
        """å¯åŠ¨Worker"""
        try:
            logger.info(f"ğŸš€ å¯åŠ¨åˆ†æWorker: {self.worker_id}")

            # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
            await init_database()
            await init_redis()

            # è¯»å–ç³»ç»Ÿè®¾ç½®ï¼ˆENV ä¼˜å…ˆ â†’ DBï¼‰
            try:
                effective_settings = await config_provider.get_effective_system_settings()
            except Exception:
                effective_settings = {}

            # è·å–é˜Ÿåˆ—æœåŠ¡
            self.queue_service = get_queue_service()

            self.running = True

            # åº”ç”¨é˜Ÿåˆ—å¹¶å‘/è¶…æ—¶é…ç½® + Worker/è½®è¯¢å‚æ•°
            try:
                self.queue_service.user_concurrent_limit = int(effective_settings.get("max_concurrent_tasks", DEFAULT_USER_CONCURRENT_LIMIT))
                self.queue_service.global_concurrent_limit = int(effective_settings.get("max_concurrent_tasks", GLOBAL_CONCURRENT_LIMIT))
                self.queue_service.visibility_timeout = int(effective_settings.get("default_analysis_timeout", VISIBILITY_TIMEOUT_SECONDS))
                # Worker intervals
                self.heartbeat_interval = int(effective_settings.get("worker_heartbeat_interval_seconds", self.heartbeat_interval))
                self.poll_interval = float(effective_settings.get("queue_poll_interval_seconds", self.poll_interval))
                self.cleanup_interval = float(effective_settings.get("queue_cleanup_interval_seconds", self.cleanup_interval))
            except Exception:
                pass
            # å¯åŠ¨å¿ƒè·³ä»»åŠ¡
            heartbeat_task = asyncio.create_task(self._heartbeat_loop())

            # å¯åŠ¨æ¸…ç†ä»»åŠ¡
            cleanup_task = asyncio.create_task(self._cleanup_loop())

            # ä¸»å·¥ä½œå¾ªç¯
            await self._work_loop()

            # å–æ¶ˆåå°ä»»åŠ¡
            heartbeat_task.cancel()
            cleanup_task.cancel()

            try:
                await heartbeat_task
                await cleanup_task
            except asyncio.CancelledError:
                pass

        except Exception as e:
            logger.error(f"Workerå¯åŠ¨å¤±è´¥: {e}")
            raise
        finally:
            await self._cleanup()

    async def _work_loop(self):
        """ä¸»å·¥ä½œå¾ªç¯"""
        logger.info(f"âœ… Worker {self.worker_id} å¼€å§‹å·¥ä½œ")

        while self.running:
            try:
                # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡
                task_data = await self.queue_service.dequeue_task(self.worker_id)

                if task_data:
                    await self._process_task(task_data)
                else:
                    # æ²¡æœ‰ä»»åŠ¡ï¼ŒçŸ­æš‚ä¼‘çœ 
                    await asyncio.sleep(self.poll_interval)

            except Exception as e:
                logger.error(f"å·¥ä½œå¾ªç¯å¼‚å¸¸: {e}")
                await asyncio.sleep(5)  # å¼‚å¸¸åç­‰å¾…5ç§’å†ç»§ç»­

        logger.info(f"ğŸ”„ Worker {self.worker_id} å·¥ä½œå¾ªç¯ç»“æŸ")

    async def _process_task(self, task_data: Dict[str, Any]):
        """å¤„ç†å•ä¸ªä»»åŠ¡"""
        task_id = task_data.get("id")
        stock_code = task_data.get("symbol")
        user_id = task_data.get("user")

        logger.info(f"ğŸ“Š å¼€å§‹å¤„ç†ä»»åŠ¡: {task_id} - {stock_code}")

        self.current_task = task_id
        success = False

        try:
            # æ„å»ºåˆ†æä»»åŠ¡å¯¹è±¡
            parameters_dict = task_data.get("parameters", {})
            if isinstance(parameters_dict, str):
                import json
                parameters_dict = json.loads(parameters_dict)

            parameters = AnalysisParameters(**parameters_dict)

            task = AnalysisTask(
                task_id=task_id,
                user_id=user_id,
                stock_code=stock_code,
                batch_id=task_data.get("batch_id"),
                parameters=parameters
            )

            # æ‰§è¡Œåˆ†æ
            result = await get_analysis_service().execute_analysis_task(
                task,
                progress_callback=self._progress_callback
            )

            success = True
            logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {task_id} - è€—æ—¶: {result.execution_time:.2f}ç§’")

        except Exception as e:
            logger.error(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {task_id} - {e}")
            logger.error(traceback.format_exc())

        finally:
            # ç¡®è®¤ä»»åŠ¡å®Œæˆ
            try:
                await self.queue_service.ack_task(task_id, success)
            except Exception as e:
                logger.error(f"ç¡®è®¤ä»»åŠ¡å¤±è´¥: {task_id} - {e}")

            self.current_task = None

    def _progress_callback(self, progress: int, message: str):
        """è¿›åº¦å›è°ƒå‡½æ•°"""
        logger.debug(f"ä»»åŠ¡è¿›åº¦ {self.current_task}: {progress}% - {message}")

    async def _heartbeat_loop(self):
        """å¿ƒè·³å¾ªç¯"""
        while self.running:
            try:
                await self._send_heartbeat()
                await asyncio.sleep(self.heartbeat_interval)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"å¿ƒè·³å¼‚å¸¸: {e}")
                await asyncio.sleep(5)

    async def _send_heartbeat(self):
        """å‘é€å¿ƒè·³"""
        try:
            from app.core.redis_client import get_redis_service
            redis_service = get_redis_service()

            heartbeat_data = {
                "worker_id": self.worker_id,
                "timestamp": datetime.utcnow().isoformat(),
                "current_task": self.current_task,
                "status": "active" if self.running else "stopping"
            }

            heartbeat_key = f"worker:{self.worker_id}:heartbeat"
            await redis_service.set_json(heartbeat_key, heartbeat_data, ttl=self.heartbeat_interval * 2)

        except Exception as e:
            logger.error(f"å‘é€å¿ƒè·³å¤±è´¥: {e}")

    async def _cleanup_loop(self):
        """æ¸…ç†å¾ªç¯ï¼Œå®šæœŸæ¸…ç†è¿‡æœŸä»»åŠ¡"""
        while self.running:
            try:
                await asyncio.sleep(self.cleanup_interval)  # æ¸…ç†é—´éš”ï¼ˆç§’ï¼‰ï¼Œå¯é…
                if self.queue_service:
                    await self.queue_service.cleanup_expired_tasks()
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"æ¸…ç†ä»»åŠ¡å¼‚å¸¸: {e}")

    async def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info(f"ğŸ§¹ æ¸…ç†Workerèµ„æº: {self.worker_id}")

        try:
            # æ¸…ç†å¿ƒè·³è®°å½•
            from app.core.redis_client import get_redis_service
            redis_service = get_redis_service()
            heartbeat_key = f"worker:{self.worker_id}:heartbeat"
            await redis_service.redis.delete(heartbeat_key)
        except Exception as e:
            logger.error(f"æ¸…ç†å¿ƒè·³è®°å½•å¤±è´¥: {e}")

        try:
            # å…³é—­æ•°æ®åº“è¿æ¥
            await close_database()
            await close_redis()
        except Exception as e:
            logger.error(f"å…³é—­æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # åˆ›å»ºå¹¶å¯åŠ¨Worker
    worker = AnalysisWorker()

    try:
        await worker.start()
    except KeyboardInterrupt:
        logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
    except Exception as e:
        logger.error(f"Workerå¼‚å¸¸é€€å‡º: {e}")
        sys.exit(1)

    logger.info("Workerå·²å®‰å…¨é€€å‡º")


if __name__ == "__main__":
    asyncio.run(main())
