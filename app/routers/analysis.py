"""
è‚¡ç¥¨åˆ†æžAPIè·¯ç”±
å¢žå¼ºç‰ˆæœ¬ï¼Œæ”¯æŒä¼˜å…ˆçº§ã€è¿›åº¦è·Ÿè¸ªã€ä»»åŠ¡ç®¡ç†ç­‰åŠŸèƒ½
"""

from fastapi import APIRouter, HTTPException, Depends, Query, BackgroundTasks, WebSocket, WebSocketDisconnect
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import datetime
import logging
import time
import uuid
import asyncio

from app.routers.auth_db import get_current_user
from app.services.queue_service import get_queue_service, QueueService
from app.services.analysis_service import get_analysis_service
from app.services.simple_analysis_service import get_simple_analysis_service
from app.services.websocket_manager import get_websocket_manager
from app.models.analysis import (
    SingleAnalysisRequest, BatchAnalysisRequest, AnalysisParameters,
    AnalysisTaskResponse, AnalysisBatchResponse, AnalysisHistoryQuery
)

router = APIRouter()
logger = logging.getLogger("webapi")

# å…¼å®¹æ€§ï¼šä¿ç•™åŽŸæœ‰çš„è¯·æ±‚æ¨¡åž‹
class SingleAnalyzeRequest(BaseModel):
    symbol: str
    parameters: dict = Field(default_factory=dict)

class BatchAnalyzeRequest(BaseModel):
    symbols: List[str]
    parameters: dict = Field(default_factory=dict)
    title: str = Field(default="æ‰¹é‡åˆ†æž", description="æ‰¹æ¬¡æ ‡é¢˜")
    description: Optional[str] = Field(None, description="æ‰¹æ¬¡æè¿°")

# æ–°ç‰ˆAPIç«¯ç‚¹
@router.post("/single", response_model=Dict[str, Any])
async def submit_single_analysis(
    request: SingleAnalysisRequest,
    background_tasks: BackgroundTasks,
    user: dict = Depends(get_current_user)
):
    """æäº¤å•è‚¡åˆ†æžä»»åŠ¡ - ä½¿ç”¨ BackgroundTasks å¼‚æ­¥æ‰§è¡Œ"""
    try:
        logger.info(f"ðŸŽ¯ æ”¶åˆ°å•è‚¡åˆ†æžè¯·æ±‚")
        logger.info(f"ðŸ‘¤ ç”¨æˆ·ä¿¡æ¯: {user}")
        logger.info(f"ðŸ“Š è¯·æ±‚æ•°æ®: {request}")

        # ç«‹å³åˆ›å»ºä»»åŠ¡è®°å½•å¹¶è¿”å›žï¼Œä¸ç­‰å¾…æ‰§è¡Œå®Œæˆ
        analysis_service = get_simple_analysis_service()
        result = await analysis_service.create_analysis_task(user["id"], request)

        # æå–å˜é‡ï¼Œé¿å…é—­åŒ…é—®é¢˜
        task_id = result["task_id"]
        user_id = user["id"]

        # å®šä¹‰ä¸€ä¸ªåŒ…è£…å‡½æ•°æ¥è¿è¡Œå¼‚æ­¥ä»»åŠ¡
        async def run_analysis_task():
            """åŒ…è£…å‡½æ•°ï¼šåœ¨åŽå°è¿è¡Œåˆ†æžä»»åŠ¡"""
            try:
                logger.info(f"ðŸš€ [BackgroundTask] å¼€å§‹æ‰§è¡Œåˆ†æžä»»åŠ¡: {task_id}")
                logger.info(f"ðŸ“ [BackgroundTask] task_id={task_id}, user_id={user_id}")
                logger.info(f"ðŸ“ [BackgroundTask] request={request}")

                # é‡æ–°èŽ·å–æœåŠ¡å®žä¾‹ï¼Œç¡®ä¿åœ¨æ­£ç¡®çš„ä¸Šä¸‹æ–‡ä¸­
                logger.info(f"ðŸ”§ [BackgroundTask] æ­£åœ¨èŽ·å–æœåŠ¡å®žä¾‹...")
                service = get_simple_analysis_service()
                logger.info(f"âœ… [BackgroundTask] æœåŠ¡å®žä¾‹èŽ·å–æˆåŠŸ: {id(service)}")

                logger.info(f"ðŸš€ [BackgroundTask] å‡†å¤‡è°ƒç”¨ execute_analysis_background...")
                await service.execute_analysis_background(
                    task_id,
                    user_id,
                    request
                )
                logger.info(f"âœ… [BackgroundTask] åˆ†æžä»»åŠ¡å®Œæˆ: {task_id}")
            except Exception as e:
                logger.error(f"âŒ [BackgroundTask] åˆ†æžä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {e}", exc_info=True)

        # ä½¿ç”¨ BackgroundTasks æ‰§è¡Œå¼‚æ­¥ä»»åŠ¡
        background_tasks.add_task(run_analysis_task)

        logger.info(f"âœ… åˆ†æžä»»åŠ¡å·²åœ¨åŽå°å¯åŠ¨: {result}")

        return {
            "success": True,
            "data": result,
            "message": "åˆ†æžä»»åŠ¡å·²åœ¨åŽå°å¯åŠ¨"
        }
    except Exception as e:
        logger.error(f"âŒ æäº¤å•è‚¡åˆ†æžä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=400, detail=str(e))


# æµ‹è¯•è·¯ç”± - éªŒè¯è·¯ç”±æ˜¯å¦è¢«æ­£ç¡®æ³¨å†Œ
@router.get("/test-route")
async def test_route():
    """æµ‹è¯•è·¯ç”±æ˜¯å¦å·¥ä½œ"""
    logger.info("ðŸ§ª æµ‹è¯•è·¯ç”±è¢«è°ƒç”¨äº†ï¼")
    return {"message": "æµ‹è¯•è·¯ç”±å·¥ä½œæ­£å¸¸", "timestamp": time.time()}

@router.get("/tasks/{task_id}/status", response_model=Dict[str, Any])
async def get_task_status_new(
    task_id: str,
    user: dict = Depends(get_current_user)
):
    """èŽ·å–åˆ†æžä»»åŠ¡çŠ¶æ€ï¼ˆæ–°ç‰ˆå¼‚æ­¥å®žçŽ°ï¼‰"""
    try:
        logger.info(f"ðŸ” [NEW ROUTE] è¿›å…¥æ–°ç‰ˆçŠ¶æ€æŸ¥è¯¢è·¯ç”±: {task_id}")
        logger.info(f"ðŸ‘¤ [NEW ROUTE] ç”¨æˆ·: {user}")

        analysis_service = get_simple_analysis_service()
        logger.info(f"ðŸ”§ [NEW ROUTE] èŽ·å–åˆ†æžæœåŠ¡å®žä¾‹: {id(analysis_service)}")

        result = await analysis_service.get_task_status(task_id)
        logger.info(f"ðŸ“Š [NEW ROUTE] æŸ¥è¯¢ç»“æžœ: {result is not None}")

        if result:
            return {
                "success": True,
                "data": result,
                "message": "ä»»åŠ¡çŠ¶æ€èŽ·å–æˆåŠŸ"
            }
        else:
            # å†…å­˜ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»ŽMongoDBä¸­æŸ¥æ‰¾
            logger.info(f"ðŸ“Š [STATUS] å†…å­˜ä¸­æœªæ‰¾åˆ°ï¼Œå°è¯•ä»ŽMongoDBæŸ¥æ‰¾: {task_id}")

            from app.core.database import get_mongo_db
            db = get_mongo_db()

            # é¦–å…ˆä»Žanalysis_tasksé›†åˆä¸­æŸ¥æ‰¾ï¼ˆæ­£åœ¨è¿›è¡Œçš„ä»»åŠ¡ï¼‰
            task_result = await db.analysis_tasks.find_one({"task_id": task_id})

            if task_result:
                logger.info(f"âœ… [STATUS] ä»Žanalysis_tasksæ‰¾åˆ°ä»»åŠ¡: {task_id}")

                # æž„é€ çŠ¶æ€å“åº”ï¼ˆæ­£åœ¨è¿›è¡Œçš„ä»»åŠ¡ï¼‰
                status = task_result.get("status", "pending")
                progress = task_result.get("progress", 0)

                # è®¡ç®—æ—¶é—´ä¿¡æ¯
                start_time = task_result.get("started_at") or task_result.get("created_at")
                current_time = datetime.utcnow()
                elapsed_time = 0
                if start_time:
                    elapsed_time = (current_time - start_time).total_seconds()

                status_data = {
                    "task_id": task_id,
                    "status": status,
                    "progress": progress,
                    "message": f"ä»»åŠ¡{status}ä¸­...",
                    "current_step": status,
                    "start_time": start_time,
                    "end_time": task_result.get("completed_at"),
                    "elapsed_time": elapsed_time,
                    "remaining_time": 0,  # æ— æ³•å‡†ç¡®ä¼°ç®—
                    "estimated_total_time": 0,
                    "symbol": task_result.get("symbol") or task_result.get("stock_code"),
                    "stock_code": task_result.get("symbol") or task_result.get("stock_code"),  # å…¼å®¹å­—æ®µ
                    "stock_symbol": task_result.get("symbol") or task_result.get("stock_code"),
                    "source": "mongodb_tasks"  # æ ‡è®°æ•°æ®æ¥æº
                }

                return {
                    "success": True,
                    "data": status_data,
                    "message": "ä»»åŠ¡çŠ¶æ€èŽ·å–æˆåŠŸï¼ˆä»Žä»»åŠ¡è®°å½•æ¢å¤ï¼‰"
                }

            # å¦‚æžœanalysis_tasksä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œå†ä»Žanalysis_reportsé›†åˆä¸­æŸ¥æ‰¾ï¼ˆå·²å®Œæˆçš„ä»»åŠ¡ï¼‰
            mongo_result = await db.analysis_reports.find_one({"task_id": task_id})

            if mongo_result:
                logger.info(f"âœ… [STATUS] ä»Žanalysis_reportsæ‰¾åˆ°ä»»åŠ¡: {task_id}")

                # æž„é€ çŠ¶æ€å“åº”ï¼ˆæ¨¡æ‹Ÿå·²å®Œæˆçš„ä»»åŠ¡ï¼‰
                # è®¡ç®—å·²å®Œæˆä»»åŠ¡çš„æ—¶é—´ä¿¡æ¯
                start_time = mongo_result.get("created_at")
                end_time = mongo_result.get("updated_at")
                elapsed_time = 0
                if start_time and end_time:
                    elapsed_time = (end_time - start_time).total_seconds()

                status_data = {
                    "task_id": task_id,
                    "status": "completed",
                    "progress": 100,
                    "message": "åˆ†æžå®Œæˆï¼ˆä»ŽåŽ†å²è®°å½•æ¢å¤ï¼‰",
                    "current_step": "completed",
                    "start_time": start_time,
                    "end_time": end_time,
                    "elapsed_time": elapsed_time,
                    "remaining_time": 0,
                    "estimated_total_time": elapsed_time,  # å·²å®Œæˆä»»åŠ¡çš„æ€»æ—¶é•¿å°±æ˜¯å·²ç”¨æ—¶é—´
                    "stock_code": mongo_result.get("stock_symbol"),
                    "stock_symbol": mongo_result.get("stock_symbol"),
                    "analysts": mongo_result.get("analysts", []),
                    "research_depth": mongo_result.get("research_depth", "å¿«é€Ÿ"),
                    "source": "mongodb_reports"  # æ ‡è®°æ•°æ®æ¥æº
                }

                return {
                    "success": True,
                    "data": status_data,
                    "message": "ä»»åŠ¡çŠ¶æ€èŽ·å–æˆåŠŸï¼ˆä»ŽåŽ†å²è®°å½•æ¢å¤ï¼‰"
                }
            else:
                logger.warning(f"âŒ [STATUS] MongoDBä¸­ä¹Ÿæœªæ‰¾åˆ°: {task_id} trace={task_id}")
                raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ èŽ·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/tasks/{task_id}/result", response_model=Dict[str, Any])
async def get_task_result(
    task_id: str,
    user: dict = Depends(get_current_user)
):
    """èŽ·å–åˆ†æžä»»åŠ¡ç»“æžœ"""
    try:
        logger.info(f"ðŸ” [RESULT] èŽ·å–ä»»åŠ¡ç»“æžœ: {task_id}")
        logger.info(f"ðŸ‘¤ [RESULT] ç”¨æˆ·: {user}")

        analysis_service = get_simple_analysis_service()
        task_status = await analysis_service.get_task_status(task_id)

        result_data = None

        if task_status and task_status.get('status') == 'completed':
            # ä»Žå†…å­˜ä¸­èŽ·å–ç»“æžœæ•°æ®
            result_data = task_status.get('result_data')
            logger.info(f"ðŸ“Š [RESULT] ä»Žå†…å­˜ä¸­èŽ·å–åˆ°ç»“æžœæ•°æ®")

            # ðŸ” è°ƒè¯•ï¼šæ£€æŸ¥å†…å­˜ä¸­çš„æ•°æ®ç»“æž„
            if result_data:
                logger.info(f"ðŸ“Š [RESULT] å†…å­˜æ•°æ®é”®: {list(result_data.keys())}")
                logger.info(f"ðŸ“Š [RESULT] å†…å­˜ä¸­æœ‰decisionå­—æ®µ: {bool(result_data.get('decision'))}")
                logger.info(f"ðŸ“Š [RESULT] å†…å­˜ä¸­summaryé•¿åº¦: {len(result_data.get('summary', ''))}")
                logger.info(f"ðŸ“Š [RESULT] å†…å­˜ä¸­recommendationé•¿åº¦: {len(result_data.get('recommendation', ''))}")
                if result_data.get('decision'):
                    decision = result_data['decision']
                    logger.info(f"ðŸ“Š [RESULT] å†…å­˜decisionå†…å®¹: action={decision.get('action')}, target_price={decision.get('target_price')}")
            else:
                logger.warning(f"âš ï¸ [RESULT] å†…å­˜ä¸­result_dataä¸ºç©º")

        if not result_data:
            # å†…å­˜ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»ŽMongoDBä¸­æŸ¥æ‰¾
            logger.info(f"ðŸ“Š [RESULT] å†…å­˜ä¸­æœªæ‰¾åˆ°ï¼Œå°è¯•ä»ŽMongoDBæŸ¥æ‰¾: {task_id}")

            from app.core.database import get_mongo_db
            db = get_mongo_db()

            # ä»Žanalysis_reportsé›†åˆä¸­æŸ¥æ‰¾ï¼ˆä¼˜å…ˆä½¿ç”¨ task_id åŒ¹é…ï¼‰
            mongo_result = await db.analysis_reports.find_one({"task_id": task_id})

            if not mongo_result:
                # å…¼å®¹æ—§æ•°æ®ï¼šæ—§è®°å½•å¯èƒ½æ²¡æœ‰ task_idï¼Œä½† analysis_id å­˜åœ¨äºŽ analysis_tasks.result
                tasks_doc_for_id = await db.analysis_tasks.find_one({"task_id": task_id}, {"result.analysis_id": 1})
                analysis_id = tasks_doc_for_id.get("result", {}).get("analysis_id") if tasks_doc_for_id else None
                if analysis_id:
                    logger.info(f"ðŸ”Ž [RESULT] æŒ‰analysis_idå…œåº•æŸ¥è¯¢ analysis_reports: {analysis_id}")
                    mongo_result = await db.analysis_reports.find_one({"analysis_id": analysis_id})

            if mongo_result:
                logger.info(f"âœ… [RESULT] ä»ŽMongoDBæ‰¾åˆ°ç»“æžœ: {task_id}")

                # ç›´æŽ¥ä½¿ç”¨MongoDBä¸­çš„æ•°æ®ç»“æž„ï¼ˆä¸Žwebç›®å½•ä¿æŒä¸€è‡´ï¼‰
                result_data = {
                    "analysis_id": mongo_result.get("analysis_id"),
                    "stock_symbol": mongo_result.get("stock_symbol"),
                    "stock_code": mongo_result.get("stock_symbol"),  # å…¼å®¹æ€§
                    "analysis_date": mongo_result.get("analysis_date"),
                    "summary": mongo_result.get("summary", ""),
                    "recommendation": mongo_result.get("recommendation", ""),
                    "confidence_score": mongo_result.get("confidence_score", 0.0),
                    "risk_level": mongo_result.get("risk_level", "ä¸­ç­‰"),
                    "key_points": mongo_result.get("key_points", []),
                    "execution_time": mongo_result.get("execution_time", 0),
                    "tokens_used": mongo_result.get("tokens_used", 0),
                    "analysts": mongo_result.get("analysts", []),
                    "research_depth": mongo_result.get("research_depth", "å¿«é€Ÿ"),
                    "reports": mongo_result.get("reports", {}),
                    "created_at": mongo_result.get("created_at"),
                    "updated_at": mongo_result.get("updated_at"),
                    "status": mongo_result.get("status", "completed"),
                    "decision": mongo_result.get("decision", {}),
                    "source": "mongodb"  # æ ‡è®°æ•°æ®æ¥æº
                }

                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                logger.info(f"ðŸ“Š [RESULT] MongoDBæ•°æ®ç»“æž„: {list(result_data.keys())}")
                logger.info(f"ðŸ“Š [RESULT] MongoDB summaryé•¿åº¦: {len(result_data['summary'])}")
                logger.info(f"ðŸ“Š [RESULT] MongoDB recommendationé•¿åº¦: {len(result_data['recommendation'])}")
                logger.info(f"ðŸ“Š [RESULT] MongoDB decisionå­—æ®µ: {bool(result_data.get('decision'))}")
                if result_data.get('decision'):
                    decision = result_data['decision']
                    logger.info(f"ðŸ“Š [RESULT] MongoDB decisionå†…å®¹: action={decision.get('action')}, target_price={decision.get('target_price')}, confidence={decision.get('confidence')}")
            else:
                # å…œåº•ï¼šanalysis_tasks é›†åˆä¸­çš„ result å­—æ®µ
                tasks_doc = await db.analysis_tasks.find_one(
                    {"task_id": task_id},
                    {"result": 1, "symbol": 1, "stock_code": 1, "created_at": 1, "completed_at": 1}
                )
                if tasks_doc and tasks_doc.get("result"):
                    r = tasks_doc["result"] or {}
                    logger.info("âœ… [RESULT] ä»Žanalysis_tasks.result æ‰¾åˆ°ç»“æžœ")
                    # èŽ·å–è‚¡ç¥¨ä»£ç  (ä¼˜å…ˆä½¿ç”¨symbol)
                    symbol = (tasks_doc.get("symbol") or tasks_doc.get("stock_code") or
                             r.get("stock_symbol") or r.get("stock_code"))
                    result_data = {
                        "analysis_id": r.get("analysis_id"),
                        "stock_symbol": symbol,
                        "stock_code": symbol,  # å…¼å®¹å­—æ®µ
                        "analysis_date": r.get("analysis_date"),
                        "summary": r.get("summary", ""),
                        "recommendation": r.get("recommendation", ""),
                        "confidence_score": r.get("confidence_score", 0.0),
                        "risk_level": r.get("risk_level", "ä¸­ç­‰"),
                        "key_points": r.get("key_points", []),
                        "execution_time": r.get("execution_time", 0),
                        "tokens_used": r.get("tokens_used", 0),
                        "analysts": r.get("analysts", []),
                        "research_depth": r.get("research_depth", "å¿«é€Ÿ"),
                        "reports": r.get("reports", {}),
                        "state": r.get("state", {}),
                        "detailed_analysis": r.get("detailed_analysis", {}),
                        "created_at": tasks_doc.get("created_at"),
                        "updated_at": tasks_doc.get("completed_at"),
                        "status": r.get("status", "completed"),
                        "decision": r.get("decision", {}),
                        "source": "analysis_tasks"  # æ•°æ®æ¥æºæ ‡è®°
                    }

        if not result_data:
            logger.warning(f"âŒ [RESULT] æ‰€æœ‰æ•°æ®æºéƒ½æœªæ‰¾åˆ°ç»“æžœ: {task_id}")
            raise HTTPException(status_code=404, detail="åˆ†æžç»“æžœä¸å­˜åœ¨")

        if not result_data:
            raise HTTPException(status_code=404, detail="åˆ†æžç»“æžœä¸å­˜åœ¨")

        # å¤„ç†reportså­—æ®µ - å¦‚æžœæ²¡æœ‰reportså­—æ®µï¼Œä¼˜å…ˆå°è¯•ä»Žæ–‡ä»¶ç³»ç»ŸåŠ è½½ï¼Œå…¶æ¬¡ä»Žstateä¸­æå–
        if 'reports' not in result_data or not result_data['reports']:
            import os
            from pathlib import Path

            stock_symbol = result_data.get('stock_symbol') or result_data.get('stock_code')
            # analysis_date å¯èƒ½æ˜¯æ—¥æœŸæˆ–æ—¶é—´æˆ³å­—ç¬¦ä¸²ï¼Œè¿™é‡Œåªå–æ—¥æœŸéƒ¨åˆ†
            analysis_date_raw = result_data.get('analysis_date')
            analysis_date = str(analysis_date_raw)[:10] if analysis_date_raw else None

            loaded_reports = {}
            try:
                # 1) å°è¯•ä»ŽçŽ¯å¢ƒå˜é‡ TRADINGAGENTS_RESULTS_DIR æŒ‡å®šçš„ä½ç½®è¯»å–
                base_env = os.getenv('TRADINGAGENTS_RESULTS_DIR')
                project_root = Path.cwd()
                if base_env:
                    base_path = Path(base_env)
                    if not base_path.is_absolute():
                        base_path = project_root / base_env
                else:
                    base_path = project_root / 'results'

                candidate_dirs = []
                if stock_symbol and analysis_date:
                    candidate_dirs.append(base_path / stock_symbol / analysis_date / 'reports')
                # 2) å…¼å®¹å…¶ä»–ä¿å­˜è·¯å¾„
                if stock_symbol and analysis_date:
                    candidate_dirs.append(project_root / 'data' / 'analysis_results' / stock_symbol / analysis_date / 'reports')
                    candidate_dirs.append(project_root / 'data' / 'analysis_results' / 'detailed' / stock_symbol / analysis_date / 'reports')

                for d in candidate_dirs:
                    if d.exists() and d.is_dir():
                        for f in d.glob('*.md'):
                            try:
                                content = f.read_text(encoding='utf-8')
                                if content and content.strip():
                                    loaded_reports[f.stem] = content.strip()
                            except Exception:
                                pass
                if loaded_reports:
                    result_data['reports'] = loaded_reports
                    # è‹¥ summary / recommendation ç¼ºå¤±ï¼Œå°è¯•ä»ŽåŒåæŠ¥å‘Šè¡¥å…¨
                    if not result_data.get('summary') and loaded_reports.get('summary'):
                        result_data['summary'] = loaded_reports.get('summary')
                    if not result_data.get('recommendation') and loaded_reports.get('recommendation'):
                        result_data['recommendation'] = loaded_reports.get('recommendation')
                    logger.info(f"ðŸ“ [RESULT] ä»Žæ–‡ä»¶ç³»ç»ŸåŠ è½½åˆ° {len(loaded_reports)} ä¸ªæŠ¥å‘Š: {list(loaded_reports.keys())}")
            except Exception as fs_err:
                logger.warning(f"âš ï¸ [RESULT] ä»Žæ–‡ä»¶ç³»ç»ŸåŠ è½½æŠ¥å‘Šå¤±è´¥: {fs_err}")

            if 'reports' not in result_data or not result_data['reports']:
                logger.info(f"ðŸ“Š [RESULT] reportså­—æ®µç¼ºå¤±ï¼Œå°è¯•ä»Žstateä¸­æå–")

                # ä»Žstateä¸­æå–æŠ¥å‘Šå†…å®¹
                reports = {}
                state = result_data.get('state', {})

                if isinstance(state, dict):
                    # å®šä¹‰æ‰€æœ‰å¯èƒ½çš„æŠ¥å‘Šå­—æ®µ
                    report_fields = [
                        'market_report',
                        'sentiment_report',
                        'news_report',
                        'fundamentals_report',
                        'investment_plan',
                        'trader_investment_plan',
                        'final_trade_decision'
                    ]

                    # ä»Žstateä¸­æå–æŠ¥å‘Šå†…å®¹
                    for field in report_fields:
                        value = state.get(field, "")
                        if isinstance(value, str) and len(value.strip()) > 10:
                            reports[field] = value.strip()

                    # å¤„ç†ç ”ç©¶å›¢é˜Ÿè¾©è®ºçŠ¶æ€æŠ¥å‘Š
                    investment_debate_state = state.get('investment_debate_state', {})
                    if isinstance(investment_debate_state, dict):
                        # æå–å¤šå¤´ç ”ç©¶å‘˜åŽ†å²
                        bull_content = investment_debate_state.get('bull_history', "")
                        if isinstance(bull_content, str) and len(bull_content.strip()) > 10:
                            reports['bull_researcher'] = bull_content.strip()

                        # æå–ç©ºå¤´ç ”ç©¶å‘˜åŽ†å²
                        bear_content = investment_debate_state.get('bear_history', "")
                        if isinstance(bear_content, str) and len(bear_content.strip()) > 10:
                            reports['bear_researcher'] = bear_content.strip()

                        # æå–ç ”ç©¶ç»ç†å†³ç­–
                        judge_decision = investment_debate_state.get('judge_decision', "")
                        if isinstance(judge_decision, str) and len(judge_decision.strip()) > 10:
                            reports['research_team_decision'] = judge_decision.strip()

                    # å¤„ç†é£Žé™©ç®¡ç†å›¢é˜Ÿè¾©è®ºçŠ¶æ€æŠ¥å‘Š
                    risk_debate_state = state.get('risk_debate_state', {})
                    if isinstance(risk_debate_state, dict):
                        # æå–æ¿€è¿›åˆ†æžå¸ˆåŽ†å²
                        risky_content = risk_debate_state.get('risky_history', "")
                        if isinstance(risky_content, str) and len(risky_content.strip()) > 10:
                            reports['risky_analyst'] = risky_content.strip()

                        # æå–ä¿å®ˆåˆ†æžå¸ˆåŽ†å²
                        safe_content = risk_debate_state.get('safe_history', "")
                        if isinstance(safe_content, str) and len(safe_content.strip()) > 10:
                            reports['safe_analyst'] = safe_content.strip()

                        # æå–ä¸­æ€§åˆ†æžå¸ˆåŽ†å²
                        neutral_content = risk_debate_state.get('neutral_history', "")
                        if isinstance(neutral_content, str) and len(neutral_content.strip()) > 10:
                            reports['neutral_analyst'] = neutral_content.strip()

                        # æå–æŠ•èµ„ç»„åˆç»ç†å†³ç­–
                        risk_decision = risk_debate_state.get('judge_decision', "")
                        if isinstance(risk_decision, str) and len(risk_decision.strip()) > 10:
                            reports['risk_management_decision'] = risk_decision.strip()

                    logger.info(f"ðŸ“Š [RESULT] ä»Žstateä¸­æå–åˆ° {len(reports)} ä¸ªæŠ¥å‘Š: {list(reports.keys())}")
                    result_data['reports'] = reports
                else:
                    logger.warning(f"âš ï¸ [RESULT] stateå­—æ®µä¸æ˜¯å­—å…¸ç±»åž‹: {type(state)}")

        # ç¡®ä¿reportså­—æ®µä¸­çš„æ‰€æœ‰å†…å®¹éƒ½æ˜¯å­—ç¬¦ä¸²ç±»åž‹
        if 'reports' in result_data and result_data['reports']:
            reports = result_data['reports']
            if isinstance(reports, dict):
                # ç¡®ä¿æ¯ä¸ªæŠ¥å‘Šå†…å®¹éƒ½æ˜¯å­—ç¬¦ä¸²ä¸”ä¸ä¸ºç©º
                cleaned_reports = {}
                for key, value in reports.items():
                    if isinstance(value, str) and value.strip():
                        # ç¡®ä¿å­—ç¬¦ä¸²ä¸ä¸ºç©º
                        cleaned_reports[key] = value.strip()
                    elif value is not None:
                        # å¦‚æžœä¸æ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                        str_value = str(value).strip()
                        if str_value:  # åªä¿å­˜éžç©ºå­—ç¬¦ä¸²
                            cleaned_reports[key] = str_value
                    # å¦‚æžœvalueä¸ºNoneæˆ–ç©ºå­—ç¬¦ä¸²ï¼Œåˆ™è·³è¿‡è¯¥æŠ¥å‘Š

                result_data['reports'] = cleaned_reports
                logger.info(f"ðŸ“Š [RESULT] æ¸…ç†reportså­—æ®µï¼ŒåŒ…å« {len(cleaned_reports)} ä¸ªæœ‰æ•ˆæŠ¥å‘Š")

                # å¦‚æžœæ¸…ç†åŽæ²¡æœ‰æœ‰æ•ˆæŠ¥å‘Šï¼Œè®¾ç½®ä¸ºç©ºå­—å…¸
                if not cleaned_reports:
                    logger.warning(f"âš ï¸ [RESULT] æ¸…ç†åŽæ²¡æœ‰æœ‰æ•ˆæŠ¥å‘Š")
                    result_data['reports'] = {}
            else:
                logger.warning(f"âš ï¸ [RESULT] reportså­—æ®µä¸æ˜¯å­—å…¸ç±»åž‹: {type(reports)}")
                result_data['reports'] = {}

        # è¡¥å…¨å…³é”®å­—æ®µï¼šrecommendation/summary/key_points
        try:
            reports = result_data.get('reports', {}) or {}
            decision = result_data.get('decision', {}) or {}

            # recommendation ä¼˜å…ˆä½¿ç”¨å†³ç­–æ‘˜è¦æˆ–æŠ¥å‘Šä¸­çš„å†³ç­–
            if not result_data.get('recommendation'):
                rec_candidates = []
                if isinstance(decision, dict) and decision.get('action'):
                    parts = [
                        f"æ“ä½œ: {decision.get('action')}",
                        f"ç›®æ ‡ä»·: {decision.get('target_price')}" if decision.get('target_price') else None,
                        f"ç½®ä¿¡åº¦: {decision.get('confidence')}" if decision.get('confidence') is not None else None
                    ]
                    rec_candidates.append("ï¼›".join([p for p in parts if p]))
                # ä»ŽæŠ¥å‘Šä¸­å…œåº•
                for k in ['final_trade_decision', 'investment_plan']:
                    v = reports.get(k)
                    if isinstance(v, str) and len(v.strip()) > 10:
                        rec_candidates.append(v.strip())
                if rec_candidates:
                    # å–æœ€æœ‰ä¿¡æ¯é‡çš„ä¸€æ¡ï¼ˆæœ€é•¿ï¼‰
                    result_data['recommendation'] = max(rec_candidates, key=len)[:2000]

            # summary ä»Žè‹¥å¹²æŠ¥å‘Šæ‹¼æŽ¥ç”Ÿæˆ
            if not result_data.get('summary'):
                sum_candidates = []
                for k in ['market_report', 'fundamentals_report', 'sentiment_report', 'news_report']:
                    v = reports.get(k)
                    if isinstance(v, str) and len(v.strip()) > 50:
                        sum_candidates.append(v.strip())
                if sum_candidates:
                    result_data['summary'] = ("\n\n".join(sum_candidates))[:3000]

            # key_points å…œåº•
            if not result_data.get('key_points'):
                kp = []
                if isinstance(decision, dict):
                    if decision.get('action'):
                        kp.append(f"æ“ä½œå»ºè®®: {decision.get('action')}")
                    if decision.get('target_price'):
                        kp.append(f"ç›®æ ‡ä»·: {decision.get('target_price')}")
                    if decision.get('confidence') is not None:
                        kp.append(f"ç½®ä¿¡åº¦: {decision.get('confidence')}")
                # ä»Žreportsä¸­æˆªå–å‰å‡ å¥ä½œä¸ºè¦ç‚¹
                for k in ['investment_plan', 'final_trade_decision']:
                    v = reports.get(k)
                    if isinstance(v, str) and len(v.strip()) > 10:
                        kp.append(v.strip()[:120])
                if kp:
                    result_data['key_points'] = kp[:5]
        except Exception as fill_err:
            logger.warning(f"âš ï¸ [RESULT] è¡¥å…¨å…³é”®å­—æ®µæ—¶å‡ºé”™: {fill_err}")


        # è¿›ä¸€æ­¥å…œåº•ï¼šä»Ž detailed_analysis æŽ¨æ–­å¹¶è¡¥å…¨
        try:
            if not result_data.get('summary') or not result_data.get('recommendation') or not result_data.get('reports'):
                da = result_data.get('detailed_analysis')
                # è‹¥reportsä»ä¸ºç©ºï¼Œæ”¾å…¥ä¸€ä»½åŽŸå§‹è¯¦ç»†åˆ†æžï¼Œä¾¿äºŽå‰ç«¯â€œæŸ¥çœ‹æŠ¥å‘Šè¯¦æƒ…â€
                if (not result_data.get('reports')) and isinstance(da, str) and len(da.strip()) > 20:
                    result_data['reports'] = {'detailed_analysis': da.strip()}
                elif (not result_data.get('reports')) and isinstance(da, dict) and da:
                    # å°†å­—å…¸çš„é•¿æ–‡æœ¬é¡¹æ”¾å…¥reports
                    extracted = {}
                    for k, v in da.items():
                        if isinstance(v, str) and len(v.strip()) > 20:
                            extracted[k] = v.strip()
                    if extracted:
                        result_data['reports'] = extracted

                # è¡¥ summary
                if not result_data.get('summary'):
                    if isinstance(da, str) and da.strip():
                        result_data['summary'] = da.strip()[:3000]
                    elif isinstance(da, dict) and da:
                        # å–æœ€é•¿çš„æ–‡æœ¬ä½œä¸ºæ‘˜è¦
                        texts = [v.strip() for v in da.values() if isinstance(v, str) and v.strip()]
                        if texts:
                            result_data['summary'] = max(texts, key=len)[:3000]

                # è¡¥ recommendation
                if not result_data.get('recommendation'):
                    rec = None
                    if isinstance(da, str):
                        # ç®€å•åŸºäºŽå…³é”®å­—æå–åŒ…å«â€œå»ºè®®â€çš„æ®µè½
                        import re
                        m = re.search(r'(æŠ•èµ„å»ºè®®|å»ºè®®|ç»“è®º)[:ï¼š]?\s*(.+)', da)
                        if m:
                            rec = m.group(0)
                    elif isinstance(da, dict):
                        for key in ['final_trade_decision', 'investment_plan', 'ç»“è®º', 'å»ºè®®']:
                            v = da.get(key)
                            if isinstance(v, str) and len(v.strip()) > 10:
                                rec = v.strip()
                                break
                    if rec:
                        result_data['recommendation'] = rec[:2000]
        except Exception as da_err:
            logger.warning(f"âš ï¸ [RESULT] ä»Ždetailed_analysisè¡¥å…¨å¤±è´¥: {da_err}")

        # ä¸¥æ ¼çš„æ•°æ®æ ¼å¼åŒ–å’ŒéªŒè¯
        def safe_string(value, default=""):
            """å®‰å…¨åœ°è½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
            if value is None:
                return default
            if isinstance(value, str):
                return value
            return str(value)

        def safe_number(value, default=0):
            """å®‰å…¨åœ°è½¬æ¢ä¸ºæ•°å­—"""
            if value is None:
                return default
            if isinstance(value, (int, float)):
                return value
            try:
                return float(value)
            except (ValueError, TypeError):
                return default

        def safe_list(value, default=None):
            """å®‰å…¨åœ°è½¬æ¢ä¸ºåˆ—è¡¨"""
            if default is None:
                default = []
            if value is None:
                return default
            if isinstance(value, list):
                return value
            return default

        def safe_dict(value, default=None):
            """å®‰å…¨åœ°è½¬æ¢ä¸ºå­—å…¸"""
            if default is None:
                default = {}
            if value is None:
                return default
            if isinstance(value, dict):
                return value
            return default

        # ðŸ” è°ƒè¯•ï¼šæ£€æŸ¥æœ€ç»ˆæž„å»ºå‰çš„result_data
        logger.info(f"ðŸ” [FINAL] æž„å»ºæœ€ç»ˆç»“æžœå‰ï¼Œresult_dataé”®: {list(result_data.keys())}")
        logger.info(f"ðŸ” [FINAL] result_dataä¸­æœ‰decision: {bool(result_data.get('decision'))}")
        if result_data.get('decision'):
            logger.info(f"ðŸ” [FINAL] decisionå†…å®¹: {result_data['decision']}")

        # æž„å»ºä¸¥æ ¼éªŒè¯çš„ç»“æžœæ•°æ®
        final_result_data = {
            "analysis_id": safe_string(result_data.get("analysis_id"), "unknown"),
            "stock_symbol": safe_string(result_data.get("stock_symbol"), "UNKNOWN"),
            "stock_code": safe_string(result_data.get("stock_code"), "UNKNOWN"),
            "analysis_date": safe_string(result_data.get("analysis_date"), "2025-08-20"),
            "summary": safe_string(result_data.get("summary"), "åˆ†æžæ‘˜è¦æš‚æ— "),
            "recommendation": safe_string(result_data.get("recommendation"), "æŠ•èµ„å»ºè®®æš‚æ— "),
            "confidence_score": safe_number(result_data.get("confidence_score"), 0.0),
            "risk_level": safe_string(result_data.get("risk_level"), "ä¸­ç­‰"),
            "key_points": safe_list(result_data.get("key_points")),
            "execution_time": safe_number(result_data.get("execution_time"), 0),
            "tokens_used": safe_number(result_data.get("tokens_used"), 0),
            "analysts": safe_list(result_data.get("analysts")),
            "research_depth": safe_string(result_data.get("research_depth"), "å¿«é€Ÿ"),
            "detailed_analysis": safe_dict(result_data.get("detailed_analysis")),
            "state": safe_dict(result_data.get("state")),
            # ðŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ decisionå­—æ®µï¼
            "decision": safe_dict(result_data.get("decision"))
        }

        # ç‰¹åˆ«å¤„ç†reportså­—æ®µ - ç¡®ä¿æ¯ä¸ªæŠ¥å‘Šéƒ½æ˜¯æœ‰æ•ˆå­—ç¬¦ä¸²
        reports_data = safe_dict(result_data.get("reports"))
        validated_reports = {}

        for report_key, report_content in reports_data.items():
            # ç¡®ä¿æŠ¥å‘Šé”®æ˜¯å­—ç¬¦ä¸²
            safe_key = safe_string(report_key, "unknown_report")

            # ç¡®ä¿æŠ¥å‘Šå†…å®¹æ˜¯éžç©ºå­—ç¬¦ä¸²
            if report_content is None:
                validated_content = "æŠ¥å‘Šå†…å®¹æš‚æ— "
            elif isinstance(report_content, str):
                validated_content = report_content.strip() if report_content.strip() else "æŠ¥å‘Šå†…å®¹ä¸ºç©º"
            else:
                validated_content = str(report_content).strip() if str(report_content).strip() else "æŠ¥å‘Šå†…å®¹æ ¼å¼é”™è¯¯"

            validated_reports[safe_key] = validated_content

        final_result_data["reports"] = validated_reports

        logger.info(f"âœ… [RESULT] æˆåŠŸèŽ·å–ä»»åŠ¡ç»“æžœ: {task_id}")
        logger.info(f"ðŸ“Š [RESULT] æœ€ç»ˆè¿”å›ž {len(final_result_data.get('reports', {}))} ä¸ªæŠ¥å‘Š")

        # ðŸ” è°ƒè¯•ï¼šæ£€æŸ¥æœ€ç»ˆè¿”å›žçš„æ•°æ®
        logger.info(f"ðŸ” [FINAL] æœ€ç»ˆè¿”å›žæ•°æ®é”®: {list(final_result_data.keys())}")
        logger.info(f"ðŸ” [FINAL] æœ€ç»ˆè¿”å›žä¸­æœ‰decision: {bool(final_result_data.get('decision'))}")
        if final_result_data.get('decision'):
            logger.info(f"ðŸ” [FINAL] æœ€ç»ˆdecisionå†…å®¹: {final_result_data['decision']}")

        return {
            "success": True,
            "data": final_result_data,
            "message": "åˆ†æžç»“æžœèŽ·å–æˆåŠŸ"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [RESULT] èŽ·å–ä»»åŠ¡ç»“æžœå¤±è´¥: {e}")
        raise HTTPException(status_code=400, detail=str(e))

@router.get("/tasks/all", response_model=Dict[str, Any])
async def list_all_tasks(
    user: dict = Depends(get_current_user),
    status: Optional[str] = Query(None, description="ä»»åŠ¡çŠ¶æ€è¿‡æ»¤"),
    limit: int = Query(20, ge=1, le=100, description="è¿”å›žæ•°é‡é™åˆ¶"),
    offset: int = Query(0, ge=0, description="åç§»é‡")
):
    """èŽ·å–æ‰€æœ‰ä»»åŠ¡åˆ—è¡¨ï¼ˆä¸é™ç”¨æˆ·ï¼‰"""
    try:
        logger.info(f"ðŸ“‹ æŸ¥è¯¢æ‰€æœ‰ä»»åŠ¡åˆ—è¡¨")

        tasks = await get_simple_analysis_service().list_all_tasks(
            status=status,
            limit=limit,
            offset=offset
        )

        return {
            "success": True,
            "data": {
                "tasks": tasks,
                "total": len(tasks),
                "limit": limit,
                "offset": offset
            },
            "message": "ä»»åŠ¡åˆ—è¡¨èŽ·å–æˆåŠŸ"
        }

    except Exception as e:
        logger.error(f"âŒ èŽ·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/tasks", response_model=Dict[str, Any])
async def list_user_tasks(
    user: dict = Depends(get_current_user),
    status: Optional[str] = Query(None, description="ä»»åŠ¡çŠ¶æ€è¿‡æ»¤"),
    limit: int = Query(20, ge=1, le=100, description="è¿”å›žæ•°é‡é™åˆ¶"),
    offset: int = Query(0, ge=0, description="åç§»é‡")
):
    """èŽ·å–ç”¨æˆ·çš„ä»»åŠ¡åˆ—è¡¨"""
    try:
        logger.info(f"ðŸ“‹ æŸ¥è¯¢ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨: {user['id']}")

        tasks = await get_simple_analysis_service().list_user_tasks(
            user_id=user["id"],
            status=status,
            limit=limit,
            offset=offset
        )

        return {
            "success": True,
            "data": {
                "tasks": tasks,
                "total": len(tasks),
                "limit": limit,
                "offset": offset
            },
            "message": "ä»»åŠ¡åˆ—è¡¨èŽ·å–æˆåŠŸ"
        }

    except Exception as e:
        logger.error(f"âŒ èŽ·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/batch", response_model=Dict[str, Any])
async def submit_batch_analysis(
    request: BatchAnalysisRequest,
    user: dict = Depends(get_current_user)
):
    """æäº¤æ‰¹é‡åˆ†æžä»»åŠ¡ï¼ˆçœŸæ­£çš„å¹¶å‘æ‰§è¡Œï¼‰

    âš ï¸ æ³¨æ„ï¼šä¸ä½¿ç”¨ BackgroundTasksï¼Œå› ä¸ºå®ƒæ˜¯ä¸²è¡Œæ‰§è¡Œçš„ï¼
    æ”¹ç”¨ asyncio.create_task å®žçŽ°çœŸæ­£çš„å¹¶å‘æ‰§è¡Œã€‚
    """
    try:
        logger.info(f"ðŸŽ¯ [æ‰¹é‡åˆ†æž] æ”¶åˆ°æ‰¹é‡åˆ†æžè¯·æ±‚: title={request.title}")

        simple_service = get_simple_analysis_service()
        batch_id = str(uuid.uuid4())
        task_ids: List[str] = []
        mapping: List[Dict[str, str]] = []

        # èŽ·å–è‚¡ç¥¨ä»£ç åˆ—è¡¨ (å…¼å®¹æ—§å­—æ®µ)
        stock_symbols = request.get_symbols()
        logger.info(f"ðŸ“Š [æ‰¹é‡åˆ†æž] è‚¡ç¥¨ä»£ç åˆ—è¡¨: {stock_symbols}")

        # éªŒè¯è‚¡ç¥¨ä»£ç åˆ—è¡¨
        if not stock_symbols:
            raise ValueError("è‚¡ç¥¨ä»£ç åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        # ðŸ”§ é™åˆ¶æ‰¹é‡åˆ†æžçš„è‚¡ç¥¨æ•°é‡ï¼ˆæœ€å¤š10ä¸ªï¼‰
        MAX_BATCH_SIZE = 10
        if len(stock_symbols) > MAX_BATCH_SIZE:
            raise ValueError(f"æ‰¹é‡åˆ†æžæœ€å¤šæ”¯æŒ {MAX_BATCH_SIZE} ä¸ªè‚¡ç¥¨ï¼Œå½“å‰æäº¤äº† {len(stock_symbols)} ä¸ª")

        # ä¸ºæ¯åªè‚¡ç¥¨åˆ›å»ºå•è‚¡åˆ†æžä»»åŠ¡
        for i, symbol in enumerate(stock_symbols):
            logger.info(f"ðŸ“ [æ‰¹é‡åˆ†æž] æ­£åœ¨åˆ›å»ºç¬¬ {i+1}/{len(stock_symbols)} ä¸ªä»»åŠ¡: {symbol}")

            single_req = SingleAnalysisRequest(
                symbol=symbol,
                stock_code=symbol,  # å…¼å®¹å­—æ®µ
                parameters=request.parameters
            )

            try:
                create_res = await simple_service.create_analysis_task(user["id"], single_req)
                task_id = create_res.get("task_id")
                if not task_id:
                    raise RuntimeError(f"åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼šæœªè¿”å›žtask_id (symbol={symbol})")
                task_ids.append(task_id)
                mapping.append({"symbol": symbol, "stock_code": symbol, "task_id": task_id})
                logger.info(f"âœ… [æ‰¹é‡åˆ†æž] å·²åˆ›å»ºä»»åŠ¡: {task_id} - {symbol}")
            except Exception as create_error:
                logger.error(f"âŒ [æ‰¹é‡åˆ†æž] åˆ›å»ºä»»åŠ¡å¤±è´¥: {symbol}, é”™è¯¯: {create_error}", exc_info=True)
                raise

        # ðŸ”§ ä½¿ç”¨ asyncio.create_task å®žçŽ°çœŸæ­£çš„å¹¶å‘æ‰§è¡Œ
        # ä¸ä½¿ç”¨ BackgroundTasksï¼Œå› ä¸ºå®ƒæ˜¯ä¸²è¡Œæ‰§è¡Œçš„
        async def run_concurrent_analysis():
            """å¹¶å‘æ‰§è¡Œæ‰€æœ‰åˆ†æžä»»åŠ¡"""
            tasks = []
            for i, symbol in enumerate(stock_symbols):
                task_id = task_ids[i]
                single_req = SingleAnalysisRequest(
                    symbol=symbol,
                    stock_code=symbol,
                    parameters=request.parameters
                )

                # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
                async def run_single_analysis(tid: str, req: SingleAnalysisRequest, uid: str):
                    try:
                        logger.info(f"ðŸš€ [å¹¶å‘ä»»åŠ¡] å¼€å§‹æ‰§è¡Œ: {tid} - {req.stock_code}")
                        await simple_service.execute_analysis_background(tid, uid, req)
                        logger.info(f"âœ… [å¹¶å‘ä»»åŠ¡] æ‰§è¡Œå®Œæˆ: {tid}")
                    except Exception as e:
                        logger.error(f"âŒ [å¹¶å‘ä»»åŠ¡] æ‰§è¡Œå¤±è´¥: {tid}, é”™è¯¯: {e}", exc_info=True)

                # æ·»åŠ åˆ°ä»»åŠ¡åˆ—è¡¨
                task = asyncio.create_task(run_single_analysis(task_id, single_req, user["id"]))
                tasks.append(task)
                logger.info(f"âœ… [æ‰¹é‡åˆ†æž] å·²åˆ›å»ºå¹¶å‘ä»»åŠ¡: {task_id} - {symbol}")

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼ˆä¸é˜»å¡žå“åº”ï¼‰
            await asyncio.gather(*tasks, return_exceptions=True)
            logger.info(f"ðŸŽ‰ [æ‰¹é‡åˆ†æž] æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆ: batch_id={batch_id}")

        # åœ¨åŽå°å¯åŠ¨å¹¶å‘ä»»åŠ¡ï¼ˆä¸ç­‰å¾…å®Œæˆï¼‰
        asyncio.create_task(run_concurrent_analysis())
        logger.info(f"ðŸš€ [æ‰¹é‡åˆ†æž] å·²å¯åŠ¨ {len(task_ids)} ä¸ªå¹¶å‘ä»»åŠ¡")

        return {
            "success": True,
            "data": {
                "batch_id": batch_id,
                "total_tasks": len(task_ids),
                "task_ids": task_ids,
                "mapping": mapping,
                "status": "submitted"
            },
            "message": f"æ‰¹é‡åˆ†æžä»»åŠ¡å·²æäº¤ï¼Œå…±{len(task_ids)}ä¸ªè‚¡ç¥¨ï¼Œæ­£åœ¨å¹¶å‘æ‰§è¡Œ"
        }
    except Exception as e:
        logger.error(f"âŒ [æ‰¹é‡åˆ†æž] æäº¤å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=400, detail=str(e))

# å…¼å®¹æ€§ï¼šä¿ç•™åŽŸæœ‰ç«¯ç‚¹
@router.post("/analyze")
async def analyze_single(
    req: SingleAnalyzeRequest,
    user: dict = Depends(get_current_user),
    svc: QueueService = Depends(get_queue_service)
):
    """å•è‚¡åˆ†æžï¼ˆå…¼å®¹æ€§ç«¯ç‚¹ï¼‰"""
    try:
        task_id = await svc.enqueue_task(
            user_id=user["id"],
            symbol=req.symbol,
            params=req.parameters
        )
        return {"task_id": task_id, "status": "queued"}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.post("/analyze/batch")
async def analyze_batch(
    req: BatchAnalyzeRequest,
    user: dict = Depends(get_current_user),
    svc: QueueService = Depends(get_queue_service)
):
    """æ‰¹é‡åˆ†æžï¼ˆå…¼å®¹æ€§ç«¯ç‚¹ï¼‰"""
    try:
        batch_id, submitted = await svc.create_batch(
            user_id=user["id"],
            symbols=req.symbols,
            params=req.parameters
        )
        return {"batch_id": batch_id, "submitted": submitted}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.get("/batches/{batch_id}")
async def get_batch(batch_id: str, user: dict = Depends(get_current_user), svc: QueueService = Depends(get_queue_service)):
    b = await svc.get_batch(batch_id)
    if not b or b.get("user") != user["id"]:
        raise HTTPException(status_code=404, detail="batch not found")
    return b

# ä»»åŠ¡å’Œæ‰¹æ¬¡æŸ¥è¯¢ç«¯ç‚¹
# æ³¨æ„ï¼šè¿™ä¸ªè·¯ç”±è¢«ç§»åˆ°äº† /tasks/{task_id}/status ä¹‹åŽï¼Œé¿å…è·¯ç”±å†²çª
# @router.get("/tasks/{task_id}")
# async def get_task(
#     task_id: str,
#     user: dict = Depends(get_current_user),
#     svc: QueueService = Depends(get_queue_service)
# ):
#     """èŽ·å–ä»»åŠ¡è¯¦æƒ…"""
#     t = await svc.get_task(task_id)
#     if not t or t.get("user") != user["id"]:
#         raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
#     return t

# åŽŸæœ‰çš„è·¯ç”±å·²è¢«æ–°çš„å¼‚æ­¥å®žçŽ°æ›¿ä»£
# @router.get("/tasks/{task_id}/status")
# async def get_task_status_old(
#     task_id: str,
#     user: dict = Depends(get_current_user)
# ):
#     """èŽ·å–ä»»åŠ¡çŠ¶æ€å’Œè¿›åº¦ï¼ˆæ—§ç‰ˆå®žçŽ°ï¼‰"""
#     try:
#         status = await get_analysis_service().get_task_status(task_id)
#         if not status:
#             raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
#         return {
#             "success": True,
#             "data": status
#         }
#     except Exception as e:
#         raise HTTPException(status_code=400, detail=str(e))

@router.post("/tasks/{task_id}/cancel")
async def cancel_task(
    task_id: str,
    user: dict = Depends(get_current_user),
    svc: QueueService = Depends(get_queue_service)
):
    """å–æ¶ˆä»»åŠ¡"""
    try:
        # éªŒè¯ä»»åŠ¡æ‰€æœ‰æƒ
        task = await svc.get_task(task_id)
        if not task or task.get("user") != user["id"]:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

        success = await svc.cancel_task(task_id)
        if success:
            return {"success": True, "message": "ä»»åŠ¡å·²å–æ¶ˆ"}
        else:
            raise HTTPException(status_code=400, detail="å–æ¶ˆä»»åŠ¡å¤±è´¥")
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.get("/user/queue-status")
async def get_user_queue_status(
    user: dict = Depends(get_current_user),
    svc: QueueService = Depends(get_queue_service)
):
    """èŽ·å–ç”¨æˆ·é˜Ÿåˆ—çŠ¶æ€"""
    try:
        status = await svc.get_user_queue_status(user["id"])
        return {
            "success": True,
            "data": status
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.get("/user/history")
async def get_user_analysis_history(
    user: dict = Depends(get_current_user),
    status: Optional[str] = Query(None, description="ä»»åŠ¡çŠ¶æ€è¿‡æ»¤"),
    start_date: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸï¼ŒYYYY-MM-DD"),
    end_date: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸï¼ŒYYYY-MM-DD"),
    symbol: Optional[str] = Query(None, description="è‚¡ç¥¨ä»£ç "),
    stock_code: Optional[str] = Query(None, description="è‚¡ç¥¨ä»£ç (å·²åºŸå¼ƒ,ä½¿ç”¨symbol)"),
    market_type: Optional[str] = Query(None, description="å¸‚åœºç±»åž‹"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µå¤§å°")
):
    """èŽ·å–ç”¨æˆ·åˆ†æžåŽ†å²ï¼ˆæ”¯æŒåŸºç¡€ç­›é€‰ä¸Žåˆ†é¡µï¼‰"""
    try:
        # å…ˆèŽ·å–ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨ï¼ˆå†…å­˜ä¼˜å…ˆï¼ŒMongoDBå…œåº•ï¼‰
        raw_tasks = await get_simple_analysis_service().list_user_tasks(
            user_id=user["id"],
            status=status,
            limit=page_size,
            offset=(page - 1) * page_size
        )

        # è¿›è¡ŒåŸºç¡€ç­›é€‰
        from datetime import datetime
        def in_date_range(t: Optional[str]) -> bool:
            if not t:
                return True
            try:
                dt = datetime.fromisoformat(t.replace('Z', '+00:00')) if 'Z' in t else datetime.fromisoformat(t)
            except Exception:
                return True
            ok = True
            if start_date:
                try:
                    ok = ok and (dt.date() >= datetime.fromisoformat(start_date).date())
                except Exception:
                    pass
            if end_date:
                try:
                    ok = ok and (dt.date() <= datetime.fromisoformat(end_date).date())
                except Exception:
                    pass
            return ok

        # èŽ·å–æŸ¥è¯¢çš„è‚¡ç¥¨ä»£ç  (å…¼å®¹æ—§å­—æ®µ)
        query_symbol = symbol or stock_code

        filtered = []
        for x in raw_tasks:
            if query_symbol:
                task_symbol = x.get("symbol") or x.get("stock_code") or x.get("stock_symbol")
                if task_symbol not in [query_symbol]:
                    continue
            # å¸‚åœºç±»åž‹æš‚æ—¶ä»Žå‚æ•°å†…åˆ¤æ–­ï¼ˆå¦‚æœ‰ï¼‰
            if market_type:
                params = x.get("parameters") or {}
                if params.get("market_type") != market_type:
                    continue
            # æ—¶é—´èŒƒå›´ï¼ˆä½¿ç”¨ start_time æˆ– created_atï¼‰
            t = x.get("start_time") or x.get("created_at")
            if not in_date_range(t):
                continue
            filtered.append(x)

        return {
            "success": True,
            "data": {
                "tasks": filtered,
                "total": len(filtered),
                "page": page,
                "page_size": page_size
            },
            "message": "åŽ†å²æŸ¥è¯¢æˆåŠŸ"
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

# WebSocket ç«¯ç‚¹
@router.websocket("/ws/task/{task_id}")
async def websocket_task_progress(websocket: WebSocket, task_id: str):
    """WebSocket ç«¯ç‚¹ï¼šå®žæ—¶èŽ·å–ä»»åŠ¡è¿›åº¦"""
    import json
    websocket_manager = get_websocket_manager()

    try:
        await websocket_manager.connect(websocket, task_id)

        # å‘é€è¿žæŽ¥ç¡®è®¤æ¶ˆæ¯
        await websocket.send_text(json.dumps({
            "type": "connection_established",
            "task_id": task_id,
            "message": "WebSocket è¿žæŽ¥å·²å»ºç«‹"
        }))

        # ä¿æŒè¿žæŽ¥æ´»è·ƒ
        while True:
            try:
                # æŽ¥æ”¶å®¢æˆ·ç«¯çš„å¿ƒè·³æ¶ˆæ¯
                data = await websocket.receive_text()
                # å¯ä»¥å¤„ç†å®¢æˆ·ç«¯å‘é€çš„æ¶ˆæ¯
                logger.debug(f"ðŸ“¡ æ”¶åˆ° WebSocket æ¶ˆæ¯: {data}")
            except WebSocketDisconnect:
                break
            except Exception as e:
                logger.warning(f"âš ï¸ WebSocket æ¶ˆæ¯å¤„ç†é”™è¯¯: {e}")
                break

    except WebSocketDisconnect:
        logger.info(f"ðŸ”Œ WebSocket å®¢æˆ·ç«¯æ–­å¼€è¿žæŽ¥: {task_id}")
    except Exception as e:
        logger.error(f"âŒ WebSocket è¿žæŽ¥é”™è¯¯: {e}")
    finally:
        await websocket_manager.disconnect(websocket, task_id)

# ä»»åŠ¡è¯¦æƒ…æŸ¥è¯¢è·¯ç”±ï¼ˆæ”¾åœ¨æœ€åŽé¿å…ä¸Ž /tasks/{task_id}/status å†²çªï¼‰
@router.get("/tasks/{task_id}/details")
async def get_task_details(
    task_id: str,
    user: dict = Depends(get_current_user),
    svc: QueueService = Depends(get_queue_service)
):
    """èŽ·å–ä»»åŠ¡è¯¦æƒ…ï¼ˆä½¿ç”¨ä¸åŒçš„è·¯å¾„é¿å…å†²çªï¼‰"""
    t = await svc.get_task(task_id)
    if not t or t.get("user") != user["id"]:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return t


# ==================== åƒµå°¸ä»»åŠ¡ç®¡ç† ====================

@router.get("/admin/zombie-tasks")
async def get_zombie_tasks(
    max_running_hours: int = Query(default=2, ge=1, le=72, description="æœ€å¤§è¿è¡Œæ—¶é•¿ï¼ˆå°æ—¶ï¼‰"),
    user: dict = Depends(get_current_user)
):
    """èŽ·å–åƒµå°¸ä»»åŠ¡åˆ—è¡¨ï¼ˆä»…ç®¡ç†å‘˜ï¼‰

    åƒµå°¸ä»»åŠ¡ï¼šé•¿æ—¶é—´å¤„äºŽ processing/running/pending çŠ¶æ€çš„ä»»åŠ¡
    """
    # æ£€æŸ¥ç®¡ç†å‘˜æƒé™
    if user.get("username") != "admin":
        raise HTTPException(status_code=403, detail="ä»…ç®¡ç†å‘˜å¯è®¿é—®")

    try:
        svc = get_simple_analysis_service()
        zombie_tasks = await svc.get_zombie_tasks(max_running_hours)

        return {
            "success": True,
            "data": zombie_tasks,
            "total": len(zombie_tasks),
            "max_running_hours": max_running_hours
        }
    except Exception as e:
        logger.error(f"âŒ èŽ·å–åƒµå°¸ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"èŽ·å–åƒµå°¸ä»»åŠ¡å¤±è´¥: {str(e)}")


@router.post("/admin/cleanup-zombie-tasks")
async def cleanup_zombie_tasks(
    max_running_hours: int = Query(default=2, ge=1, le=72, description="æœ€å¤§è¿è¡Œæ—¶é•¿ï¼ˆå°æ—¶ï¼‰"),
    user: dict = Depends(get_current_user)
):
    """æ¸…ç†åƒµå°¸ä»»åŠ¡ï¼ˆä»…ç®¡ç†å‘˜ï¼‰

    å°†é•¿æ—¶é—´å¤„äºŽ processing/running/pending çŠ¶æ€çš„ä»»åŠ¡æ ‡è®°ä¸ºå¤±è´¥
    """
    # æ£€æŸ¥ç®¡ç†å‘˜æƒé™
    if user.get("username") != "admin":
        raise HTTPException(status_code=403, detail="ä»…ç®¡ç†å‘˜å¯è®¿é—®")

    try:
        svc = get_simple_analysis_service()
        result = await svc.cleanup_zombie_tasks(max_running_hours)

        return {
            "success": True,
            "data": result,
            "message": f"å·²æ¸…ç† {result.get('total_cleaned', 0)} ä¸ªåƒµå°¸ä»»åŠ¡"
        }
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†åƒµå°¸ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†åƒµå°¸ä»»åŠ¡å¤±è´¥: {str(e)}")


@router.post("/tasks/{task_id}/mark-failed")
async def mark_task_as_failed(
    task_id: str,
    user: dict = Depends(get_current_user)
):
    """å°†æŒ‡å®šä»»åŠ¡æ ‡è®°ä¸ºå¤±è´¥

    ç”¨äºŽæ‰‹åŠ¨æ¸…ç†å¡ä½çš„ä»»åŠ¡
    """
    try:
        svc = get_simple_analysis_service()

        # æ›´æ–°å†…å­˜ä¸­çš„ä»»åŠ¡çŠ¶æ€
        from app.services.memory_state_manager import TaskStatus
        await svc.memory_manager.update_task_status(
            task_id=task_id,
            status=TaskStatus.FAILED,
            message="æ‰‹åŠ¨æ ‡è®°ä¸ºå¤±è´¥",
            error_message="ç”¨æˆ·æ‰‹åŠ¨æ ‡è®°ä¸ºå¤±è´¥"
        )

        # æ›´æ–° MongoDB ä¸­çš„ä»»åŠ¡çŠ¶æ€
        from app.core.database import get_mongo_db
        from datetime import datetime
        db = get_mongo_db()

        result = await db.analysis_tasks.update_one(
            {"task_id": task_id},
            {
                "$set": {
                    "status": "failed",
                    "last_error": "ç”¨æˆ·æ‰‹åŠ¨æ ‡è®°ä¸ºå¤±è´¥",
                    "completed_at": datetime.utcnow(),
                    "updated_at": datetime.utcnow()
                }
            }
        )

        if result.modified_count > 0:
            logger.info(f"âœ… ä»»åŠ¡ {task_id} å·²æ ‡è®°ä¸ºå¤±è´¥")
            return {
                "success": True,
                "message": "ä»»åŠ¡å·²æ ‡è®°ä¸ºå¤±è´¥"
            }
        else:
            logger.warning(f"âš ï¸ ä»»åŠ¡ {task_id} æœªæ‰¾åˆ°æˆ–å·²æ˜¯å¤±è´¥çŠ¶æ€")
            return {
                "success": True,
                "message": "ä»»åŠ¡æœªæ‰¾åˆ°æˆ–å·²æ˜¯å¤±è´¥çŠ¶æ€"
            }
    except Exception as e:
        logger.error(f"âŒ æ ‡è®°ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ ‡è®°ä»»åŠ¡å¤±è´¥: {str(e)}")


@router.delete("/tasks/{task_id}")
async def delete_task(
    task_id: str,
    user: dict = Depends(get_current_user)
):
    """åˆ é™¤æŒ‡å®šä»»åŠ¡

    ä»Žå†…å­˜å’Œæ•°æ®åº“ä¸­åˆ é™¤ä»»åŠ¡è®°å½•
    """
    try:
        svc = get_simple_analysis_service()

        # ä»Žå†…å­˜ä¸­åˆ é™¤ä»»åŠ¡
        await svc.memory_manager.remove_task(task_id)

        # ä»Ž MongoDB ä¸­åˆ é™¤ä»»åŠ¡
        from app.core.database import get_mongo_db
        db = get_mongo_db()

        result = await db.analysis_tasks.delete_one({"task_id": task_id})

        if result.deleted_count > 0:
            logger.info(f"âœ… ä»»åŠ¡ {task_id} å·²åˆ é™¤")
            return {
                "success": True,
                "message": "ä»»åŠ¡å·²åˆ é™¤"
            }
        else:
            logger.warning(f"âš ï¸ ä»»åŠ¡ {task_id} æœªæ‰¾åˆ°")
            return {
                "success": True,
                "message": "ä»»åŠ¡æœªæ‰¾åˆ°"
            }
    except Exception as e:
        logger.error(f"âŒ åˆ é™¤ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤ä»»åŠ¡å¤±è´¥: {str(e)}")