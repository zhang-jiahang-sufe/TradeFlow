"""
æ–°é—»æ•°æ®APIè·¯ç”±
æä¾›æ–°é—»æ•°æ®æŸ¥è¯¢ã€åŒæ­¥å’Œç®¡ç†æ¥å£
"""
from fastapi import APIRouter, HTTPException, BackgroundTasks, Depends, Query, status
from typing import Optional, List, Dict, Any
from datetime import datetime, timedelta
from pydantic import BaseModel, Field
import logging

from app.routers.auth_db import get_current_user
from app.core.response import ok
from app.services.news_data_service import get_news_data_service, NewsQueryParams
from app.worker.news_data_sync_service import get_news_data_sync_service

router = APIRouter(prefix="/api/news-data", tags=["æ–°é—»æ•°æ®"])
logger = logging.getLogger("webapi")


class NewsQueryRequest(BaseModel):
    """æ–°é—»æŸ¥è¯¢è¯·æ±‚"""
    symbol: Optional[str] = Field(None, description="è‚¡ç¥¨ä»£ç ")
    symbols: Optional[List[str]] = Field(None, description="å¤šä¸ªè‚¡ç¥¨ä»£ç ")
    start_time: Optional[datetime] = Field(None, description="å¼€å§‹æ—¶é—´")
    end_time: Optional[datetime] = Field(None, description="ç»“æŸæ—¶é—´")
    category: Optional[str] = Field(None, description="æ–°é—»ç±»åˆ«")
    sentiment: Optional[str] = Field(None, description="æƒ…ç»ªåˆ†æ")
    importance: Optional[str] = Field(None, description="é‡è¦æ€§")
    data_source: Optional[str] = Field(None, description="æ•°æ®æº")
    keywords: Optional[List[str]] = Field(None, description="å…³é”®è¯")
    limit: int = Field(50, description="è¿”å›æ•°é‡é™åˆ¶")
    skip: int = Field(0, description="è·³è¿‡æ•°é‡")


class NewsSyncRequest(BaseModel):
    """æ–°é—»åŒæ­¥è¯·æ±‚"""
    symbol: Optional[str] = Field(None, description="è‚¡ç¥¨ä»£ç ï¼Œä¸ºç©ºåˆ™åŒæ­¥å¸‚åœºæ–°é—»")
    data_sources: Optional[List[str]] = Field(None, description="æ•°æ®æºåˆ—è¡¨")
    hours_back: int = Field(24, description="å›æº¯å°æ—¶æ•°")
    max_news_per_source: int = Field(50, description="æ¯ä¸ªæ•°æ®æºæœ€å¤§æ–°é—»æ•°é‡")


@router.get("/query/{symbol}", response_model=dict)
async def query_stock_news(
    symbol: str,
    hours_back: int = Query(24, description="å›æº¯å°æ—¶æ•°"),
    limit: int = Query(20, description="è¿”å›æ•°é‡é™åˆ¶"),
    category: Optional[str] = Query(None, description="æ–°é—»ç±»åˆ«"),
    sentiment: Optional[str] = Query(None, description="æƒ…ç»ªåˆ†æ"),
    current_user: dict = Depends(get_current_user)
):
    """
    æŸ¥è¯¢è‚¡ç¥¨æ–°é—»ï¼ˆæ™ºèƒ½è·å–ï¼šä¼˜å…ˆæ•°æ®åº“ï¼Œæ— æ•°æ®æ—¶å®æ—¶è·å–ï¼‰

    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        hours_back: å›æº¯å°æ—¶æ•°
        limit: è¿”å›æ•°é‡é™åˆ¶
        category: æ–°é—»ç±»åˆ«è¿‡æ»¤
        sentiment: æƒ…ç»ªåˆ†æè¿‡æ»¤

    Returns:
        dict: æ–°é—»æ•°æ®åˆ—è¡¨
    """
    try:
        service = await get_news_data_service()

        # æ„å»ºæŸ¥è¯¢å‚æ•°
        start_time = datetime.utcnow() - timedelta(hours=hours_back)

        params = NewsQueryParams(
            symbol=symbol,
            start_time=start_time,
            category=category,
            sentiment=sentiment,
            limit=limit,
            sort_by="publish_time",
            sort_order=-1
        )

        # 1. å…ˆä»æ•°æ®åº“æŸ¥è¯¢
        news_list = await service.query_news(params)
        data_source = "database"

        # 2. å¦‚æœæ•°æ®åº“æ²¡æœ‰æ•°æ®ï¼Œå®æ—¶è·å–
        if not news_list:
            logger.info(f"ğŸ“° æ•°æ®åº“æ— æ–°é—»æ•°æ®ï¼Œå®æ—¶è·å–: {symbol}")
            try:
                from app.worker.akshare_sync_service import get_akshare_sync_service
                sync_service = await get_akshare_sync_service()

                # å®æ—¶è·å–æ–°é—»
                news_data = await sync_service.provider.get_stock_news(
                    symbol=symbol,
                    limit=limit
                )

                if news_data:
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    saved_count = await service.save_news_data(
                        news_data=news_data,
                        data_source="akshare",
                        market="CN"
                    )
                    logger.info(f"âœ… å®æ—¶è·å–å¹¶ä¿å­˜ {saved_count} æ¡æ–°é—»")

                    # é‡æ–°æŸ¥è¯¢
                    news_list = await service.query_news(params)
                    data_source = "realtime"
                else:
                    logger.warning(f"âš ï¸ å®æ—¶è·å–æ–°é—»å¤±è´¥: {symbol}")

            except Exception as e:
                logger.error(f"âŒ å®æ—¶è·å–æ–°é—»å¼‚å¸¸: {e}")

        return ok(data={
                "symbol": symbol,
                "hours_back": hours_back,
                "total_count": len(news_list),
                "news": news_list,
                "data_source": data_source
            },
            message=f"æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {len(news_list)} æ¡æ–°é—»ï¼ˆæ¥æºï¼š{data_source}ï¼‰"
        )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æŸ¥è¯¢è‚¡ç¥¨æ–°é—»å¤±è´¥: {str(e)}"
        )


@router.post("/query", response_model=dict)
async def query_news_advanced(
    request: NewsQueryRequest,
    current_user: dict = Depends(get_current_user)
):
    """
    é«˜çº§æ–°é—»æŸ¥è¯¢
    
    Args:
        request: æŸ¥è¯¢è¯·æ±‚å‚æ•°
        
    Returns:
        dict: æ–°é—»æ•°æ®åˆ—è¡¨
    """
    try:
        service = await get_news_data_service()
        
        # æ„å»ºæŸ¥è¯¢å‚æ•°
        params = NewsQueryParams(
            symbol=request.symbol,
            symbols=request.symbols,
            start_time=request.start_time,
            end_time=request.end_time,
            category=request.category,
            sentiment=request.sentiment,
            importance=request.importance,
            data_source=request.data_source,
            keywords=request.keywords,
            limit=request.limit,
            skip=request.skip
        )
        
        # æŸ¥è¯¢æ–°é—»
        news_list = await service.query_news(params)
        
        return ok(data={
                "query_params": request.dict(),
                "total_count": len(news_list),
                "news": news_list
            },
            message=f"é«˜çº§æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {len(news_list)} æ¡æ–°é—»"
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"é«˜çº§æ–°é—»æŸ¥è¯¢å¤±è´¥: {str(e)}"
        )


@router.get("/latest", response_model=dict)
async def get_latest_news(
    symbol: Optional[str] = Query(None, description="è‚¡ç¥¨ä»£ç ï¼Œä¸ºç©ºåˆ™è·å–æ‰€æœ‰æ–°é—»"),
    limit: int = Query(10, description="è¿”å›æ•°é‡é™åˆ¶"),
    hours_back: int = Query(24, description="å›æº¯å°æ—¶æ•°"),
    current_user: dict = Depends(get_current_user)
):
    """
    è·å–æœ€æ–°æ–°é—»
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç ï¼Œä¸ºç©ºåˆ™è·å–æ‰€æœ‰æ–°é—»
        limit: è¿”å›æ•°é‡é™åˆ¶
        hours_back: å›æº¯å°æ—¶æ•°
        
    Returns:
        dict: æœ€æ–°æ–°é—»åˆ—è¡¨
    """
    try:
        service = await get_news_data_service()
        
        # è·å–æœ€æ–°æ–°é—»
        news_list = await service.get_latest_news(
            symbol=symbol,
            limit=limit,
            hours_back=hours_back
        )
        
        return ok(data={
                "symbol": symbol,
                "limit": limit,
                "hours_back": hours_back,
                "total_count": len(news_list),
                "news": news_list
            },
            message=f"è·å–æœ€æ–°æ–°é—»æˆåŠŸï¼Œè¿”å› {len(news_list)} æ¡"
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–æœ€æ–°æ–°é—»å¤±è´¥: {str(e)}"
        )


@router.get("/search", response_model=dict)
async def search_news(
    query: str = Query(..., description="æœç´¢å…³é”®è¯"),
    symbol: Optional[str] = Query(None, description="è‚¡ç¥¨ä»£ç è¿‡æ»¤"),
    limit: int = Query(20, description="è¿”å›æ•°é‡é™åˆ¶"),
    current_user: dict = Depends(get_current_user)
):
    """
    å…¨æ–‡æœç´¢æ–°é—»
    
    Args:
        query: æœç´¢å…³é”®è¯
        symbol: è‚¡ç¥¨ä»£ç è¿‡æ»¤
        limit: è¿”å›æ•°é‡é™åˆ¶
        
    Returns:
        dict: æœç´¢ç»“æœåˆ—è¡¨
    """
    try:
        service = await get_news_data_service()
        
        # å…¨æ–‡æœç´¢
        news_list = await service.search_news(
            query_text=query,
            symbol=symbol,
            limit=limit
        )
        
        return ok(data={
                "query": query,
                "symbol": symbol,
                "total_count": len(news_list),
                "news": news_list
            },
            message=f"æœç´¢æˆåŠŸï¼Œè¿”å› {len(news_list)} æ¡ç»“æœ"
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ–°é—»æœç´¢å¤±è´¥: {str(e)}"
        )


@router.get("/statistics", response_model=dict)
async def get_news_statistics(
    symbol: Optional[str] = Query(None, description="è‚¡ç¥¨ä»£ç "),
    days_back: int = Query(7, description="å›æº¯å¤©æ•°"),
    current_user: dict = Depends(get_current_user)
):
    """
    è·å–æ–°é—»ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        days_back: å›æº¯å¤©æ•°
        
    Returns:
        dict: æ–°é—»ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        service = await get_news_data_service()
        
        # è®¡ç®—æ—¶é—´èŒƒå›´
        start_time = datetime.utcnow() - timedelta(days=days_back)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = await service.get_news_statistics(
            symbol=symbol,
            start_time=start_time
        )
        
        return ok(data={
                "symbol": symbol,
                "days_back": days_back,
                "statistics": {
                    "total_count": stats.total_count,
                    "sentiment_distribution": {
                        "positive": stats.positive_count,
                        "negative": stats.negative_count,
                        "neutral": stats.neutral_count
                    },
                    "importance_distribution": {
                        "high": stats.high_importance_count,
                        "medium": stats.medium_importance_count,
                        "low": stats.low_importance_count
                    },
                    "categories": stats.categories,
                    "sources": stats.sources
                }
            },
            message="è·å–æ–°é—»ç»Ÿè®¡æˆåŠŸ"
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–æ–°é—»ç»Ÿè®¡å¤±è´¥: {str(e)}"
        )


@router.post("/sync/start", response_model=dict)
async def start_news_sync(
    request: NewsSyncRequest,
    background_tasks: BackgroundTasks,
    current_user: dict = Depends(get_current_user)
):
    """
    å¯åŠ¨æ–°é—»åŒæ­¥ä»»åŠ¡
    
    Args:
        request: åŒæ­¥è¯·æ±‚å‚æ•°
        background_tasks: åå°ä»»åŠ¡
        
    Returns:
        dict: ä»»åŠ¡å¯åŠ¨ç»“æœ
    """
    try:
        sync_service = await get_news_data_sync_service()
        
        # æ·»åŠ åå°åŒæ­¥ä»»åŠ¡
        if request.symbol:
            background_tasks.add_task(
                _execute_stock_news_sync,
                sync_service,
                request
            )
            message = f"è‚¡ç¥¨ {request.symbol} æ–°é—»åŒæ­¥ä»»åŠ¡å·²å¯åŠ¨"
        else:
            background_tasks.add_task(
                _execute_market_news_sync,
                sync_service,
                request
            )
            message = "å¸‚åœºæ–°é—»åŒæ­¥ä»»åŠ¡å·²å¯åŠ¨"
        
        return ok(data={
                "sync_type": "stock" if request.symbol else "market",
                "symbol": request.symbol,
                "data_sources": request.data_sources,
                "hours_back": request.hours_back,
                "max_news_per_source": request.max_news_per_source
            },
            message=message
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¯åŠ¨æ–°é—»åŒæ­¥å¤±è´¥: {str(e)}"
        )


@router.post("/sync/single", response_model=dict)
async def sync_single_stock_news(
    symbol: str,
    data_sources: Optional[List[str]] = None,
    hours_back: int = 24,
    max_news_per_source: int = 50,
    current_user: dict = Depends(get_current_user)
):
    """
    åŒæ­¥å•åªè‚¡ç¥¨æ–°é—»ï¼ˆåŒæ­¥æ‰§è¡Œï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        data_sources: æ•°æ®æºåˆ—è¡¨
        hours_back: å›æº¯å°æ—¶æ•°
        max_news_per_source: æ¯ä¸ªæ•°æ®æºæœ€å¤§æ–°é—»æ•°é‡
        
    Returns:
        dict: åŒæ­¥ç»“æœ
    """
    try:
        sync_service = await get_news_data_sync_service()
        
        # æ‰§è¡ŒåŒæ­¥
        stats = await sync_service.sync_stock_news(
            symbol=symbol,
            data_sources=data_sources,
            hours_back=hours_back,
            max_news_per_source=max_news_per_source
        )
        
        return ok(data={
                "symbol": symbol,
                "sync_stats": {
                    "total_processed": stats.total_processed,
                    "successful_saves": stats.successful_saves,
                    "failed_saves": stats.failed_saves,
                    "duplicate_skipped": stats.duplicate_skipped,
                    "sources_used": stats.sources_used,
                    "duration_seconds": stats.duration_seconds,
                    "success_rate": stats.success_rate
                }
            },
            message=f"è‚¡ç¥¨ {symbol} æ–°é—»åŒæ­¥å®Œæˆï¼ŒæˆåŠŸä¿å­˜ {stats.successful_saves} æ¡"
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åŒæ­¥è‚¡ç¥¨æ–°é—»å¤±è´¥: {str(e)}"
        )


@router.delete("/cleanup", response_model=dict)
async def cleanup_old_news(
    days_to_keep: int = Query(90, description="ä¿ç•™å¤©æ•°"),
    current_user: dict = Depends(get_current_user)
):
    """
    æ¸…ç†è¿‡æœŸæ–°é—»
    
    Args:
        days_to_keep: ä¿ç•™å¤©æ•°
        
    Returns:
        dict: æ¸…ç†ç»“æœ
    """
    try:
        service = await get_news_data_service()
        
        # åˆ é™¤è¿‡æœŸæ–°é—»
        deleted_count = await service.delete_old_news(days_to_keep)
        
        return ok(data={
                "days_to_keep": days_to_keep,
                "deleted_count": deleted_count
            },
            message=f"æ¸…ç†å®Œæˆï¼Œåˆ é™¤ {deleted_count} æ¡è¿‡æœŸæ–°é—»"
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ¸…ç†è¿‡æœŸæ–°é—»å¤±è´¥: {str(e)}"
        )


@router.get("/health", response_model=dict)
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        service = await get_news_data_service()
        sync_service = await get_news_data_sync_service()
        
        return ok(data={
                "service_status": "healthy",
                "timestamp": datetime.utcnow().isoformat()
            },
            message="æ–°é—»æ•°æ®æœåŠ¡è¿è¡Œæ­£å¸¸"
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}"
        )


# åå°ä»»åŠ¡æ‰§è¡Œå‡½æ•°
async def _execute_stock_news_sync(sync_service, request: NewsSyncRequest):
    """æ‰§è¡Œè‚¡ç¥¨æ–°é—»åŒæ­¥"""
    try:
        await sync_service.sync_stock_news(
            symbol=request.symbol,
            data_sources=request.data_sources,
            hours_back=request.hours_back,
            max_news_per_source=request.max_news_per_source
        )
    except Exception as e:
        logger.error(f"âŒ åå°è‚¡ç¥¨æ–°é—»åŒæ­¥å¤±è´¥: {e}")


async def _execute_market_news_sync(sync_service, request: NewsSyncRequest):
    """æ‰§è¡Œå¸‚åœºæ–°é—»åŒæ­¥"""
    try:
        await sync_service.sync_market_news(
            data_sources=request.data_sources,
            hours_back=request.hours_back,
            max_news_per_source=request.max_news_per_source
        )
    except Exception as e:
        logger.error(f"âŒ åå°å¸‚åœºæ–°é—»åŒæ­¥å¤±è´¥: {e}")
