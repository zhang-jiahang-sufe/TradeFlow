"""
æ—¥å¿—å¯¼å‡ºæœåŠ¡
æä¾›æ—¥å¿—æ–‡ä»¶çš„æŸ¥è¯¢ã€è¿‡æ»¤å’Œå¯¼å‡ºåŠŸèƒ½
"""

import logging
import os
import zipfile
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Optional, Dict, Any
import re
import json

logger = logging.getLogger("webapi")


class LogExportService:
    """æ—¥å¿—å¯¼å‡ºæœåŠ¡"""

    def __init__(self, log_dir: str = "./logs"):
        """
        åˆå§‹åŒ–æ—¥å¿—å¯¼å‡ºæœåŠ¡

        Args:
            log_dir: æ—¥å¿—æ–‡ä»¶ç›®å½•
        """
        self.log_dir = Path(log_dir)
        logger.info(f"ğŸ” [LogExportService] åˆå§‹åŒ–æ—¥å¿—å¯¼å‡ºæœåŠ¡")
        logger.info(f"ğŸ” [LogExportService] é…ç½®çš„æ—¥å¿—ç›®å½•: {log_dir}")
        logger.info(f"ğŸ” [LogExportService] è§£æåçš„æ—¥å¿—ç›®å½•: {self.log_dir}")
        logger.info(f"ğŸ” [LogExportService] ç»å¯¹è·¯å¾„: {self.log_dir.absolute()}")
        logger.info(f"ğŸ” [LogExportService] ç›®å½•æ˜¯å¦å­˜åœ¨: {self.log_dir.exists()}")

        if not self.log_dir.exists():
            logger.warning(f"âš ï¸ [LogExportService] æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {self.log_dir}")
            try:
                self.log_dir.mkdir(parents=True, exist_ok=True)
                logger.info(f"âœ… [LogExportService] å·²åˆ›å»ºæ—¥å¿—ç›®å½•: {self.log_dir}")
            except Exception as e:
                logger.error(f"âŒ [LogExportService] åˆ›å»ºæ—¥å¿—ç›®å½•å¤±è´¥: {e}")
        else:
            logger.info(f"âœ… [LogExportService] æ—¥å¿—ç›®å½•å­˜åœ¨")

    def list_log_files(self) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºæ‰€æœ‰æ—¥å¿—æ–‡ä»¶

        Returns:
            æ—¥å¿—æ–‡ä»¶åˆ—è¡¨ï¼ŒåŒ…å«æ–‡ä»¶åã€å¤§å°ã€ä¿®æ”¹æ—¶é—´ç­‰ä¿¡æ¯
        """
        log_files = []

        try:
            logger.info(f"ğŸ” [list_log_files] å¼€å§‹åˆ—å‡ºæ—¥å¿—æ–‡ä»¶")
            logger.info(f"ğŸ” [list_log_files] æœç´¢ç›®å½•: {self.log_dir}")
            logger.info(f"ğŸ” [list_log_files] ç»å¯¹è·¯å¾„: {self.log_dir.absolute()}")
            logger.info(f"ğŸ” [list_log_files] ç›®å½•æ˜¯å¦å­˜åœ¨: {self.log_dir.exists()}")
            logger.info(f"ğŸ” [list_log_files] æ˜¯å¦ä¸ºç›®å½•: {self.log_dir.is_dir()}")

            if not self.log_dir.exists():
                logger.error(f"âŒ [list_log_files] æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {self.log_dir}")
                return []

            if not self.log_dir.is_dir():
                logger.error(f"âŒ [list_log_files] è·¯å¾„ä¸æ˜¯ç›®å½•: {self.log_dir}")
                return []

            # åˆ—å‡ºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆè°ƒè¯•ç”¨ï¼‰
            try:
                all_items = list(self.log_dir.iterdir())
                logger.info(f"ğŸ” [list_log_files] ç›®å½•ä¸­å…±æœ‰ {len(all_items)} ä¸ªé¡¹ç›®")
                for item in all_items[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    logger.info(f"ğŸ” [list_log_files]   - {item.name} (is_file: {item.is_file()})")
            except Exception as e:
                logger.error(f"âŒ [list_log_files] åˆ—å‡ºç›®å½•å†…å®¹å¤±è´¥: {e}")

            # æœç´¢æ—¥å¿—æ–‡ä»¶
            logger.info(f"ğŸ” [list_log_files] æœç´¢æ¨¡å¼: *.log*")
            for file_path in self.log_dir.glob("*.log*"):
                logger.info(f"ğŸ” [list_log_files] æ‰¾åˆ°æ–‡ä»¶: {file_path.name}")
                if file_path.is_file():
                    stat = file_path.stat()
                    log_file_info = {
                        "name": file_path.name,
                        "path": str(file_path),
                        "size": stat.st_size,
                        "size_mb": round(stat.st_size / (1024 * 1024), 2),
                        "modified_at": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        "type": self._get_log_type(file_path.name)
                    }
                    log_files.append(log_file_info)
                    logger.info(f"âœ… [list_log_files] æ·»åŠ æ—¥å¿—æ–‡ä»¶: {file_path.name} ({log_file_info['size_mb']} MB)")
                else:
                    logger.warning(f"âš ï¸ [list_log_files] è·³è¿‡éæ–‡ä»¶é¡¹: {file_path.name}")

            # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åº
            log_files.sort(key=lambda x: x["modified_at"], reverse=True)

            logger.info(f"ğŸ“‹ [list_log_files] æœ€ç»ˆæ‰¾åˆ° {len(log_files)} ä¸ªæ—¥å¿—æ–‡ä»¶")
            return log_files

        except Exception as e:
            logger.error(f"âŒ [list_log_files] åˆ—å‡ºæ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
            return []

    def _get_log_type(self, filename: str) -> str:
        """
        æ ¹æ®æ–‡ä»¶ååˆ¤æ–­æ—¥å¿—ç±»å‹
        
        Args:
            filename: æ–‡ä»¶å
            
        Returns:
            æ—¥å¿—ç±»å‹
        """
        if "error" in filename.lower():
            return "error"
        elif "webapi" in filename.lower():
            return "webapi"
        elif "worker" in filename.lower():
            return "worker"
        elif "access" in filename.lower():
            return "access"
        else:
            return "other"

    def read_log_file(
        self,
        filename: str,
        lines: int = 1000,
        level: Optional[str] = None,
        keyword: Optional[str] = None,
        start_time: Optional[str] = None,
        end_time: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        è¯»å–æ—¥å¿—æ–‡ä»¶å†…å®¹ï¼ˆæ”¯æŒè¿‡æ»¤ï¼‰
        
        Args:
            filename: æ—¥å¿—æ–‡ä»¶å
            lines: è¯»å–çš„è¡Œæ•°ï¼ˆä»æœ«å°¾å¼€å§‹ï¼‰
            level: æ—¥å¿—çº§åˆ«è¿‡æ»¤ï¼ˆERROR, WARNING, INFO, DEBUGï¼‰
            keyword: å…³é”®è¯è¿‡æ»¤
            start_time: å¼€å§‹æ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
            end_time: ç»“æŸæ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
            
        Returns:
            æ—¥å¿—å†…å®¹å’Œç»Ÿè®¡ä¿¡æ¯
        """
        file_path = self.log_dir / filename
        
        if not file_path.exists():
            raise FileNotFoundError(f"æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                all_lines = f.readlines()
            
            # ä»æœ«å°¾å¼€å§‹è¯»å–æŒ‡å®šè¡Œæ•°
            recent_lines = all_lines[-lines:] if len(all_lines) > lines else all_lines
            
            # åº”ç”¨è¿‡æ»¤å™¨
            filtered_lines = []
            stats = {
                "total_lines": len(all_lines),
                "filtered_lines": 0,
                "error_count": 0,
                "warning_count": 0,
                "info_count": 0,
                "debug_count": 0
            }
            
            for line in recent_lines:
                # ç»Ÿè®¡æ—¥å¿—çº§åˆ«
                if "ERROR" in line:
                    stats["error_count"] += 1
                elif "WARNING" in line:
                    stats["warning_count"] += 1
                elif "INFO" in line:
                    stats["info_count"] += 1
                elif "DEBUG" in line:
                    stats["debug_count"] += 1
                
                # åº”ç”¨è¿‡æ»¤æ¡ä»¶
                if level and level.upper() not in line:
                    continue
                
                if keyword and keyword.lower() not in line.lower():
                    continue
                
                # æ—¶é—´è¿‡æ»¤ï¼ˆç®€å•å®ç°ï¼Œå‡è®¾æ—¥å¿—æ ¼å¼ä¸º YYYY-MM-DD HH:MM:SSï¼‰
                if start_time or end_time:
                    time_match = re.search(r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}', line)
                    if time_match:
                        log_time = time_match.group()
                        if start_time and log_time < start_time:
                            continue
                        if end_time and log_time > end_time:
                            continue
                
                filtered_lines.append(line.rstrip())
            
            stats["filtered_lines"] = len(filtered_lines)
            
            return {
                "filename": filename,
                "lines": filtered_lines,
                "stats": stats
            }
            
        except Exception as e:
            logger.error(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
            raise

    def export_logs(
        self,
        filenames: Optional[List[str]] = None,
        level: Optional[str] = None,
        start_time: Optional[str] = None,
        end_time: Optional[str] = None,
        format: str = "zip"
    ) -> str:
        """
        å¯¼å‡ºæ—¥å¿—æ–‡ä»¶
        
        Args:
            filenames: è¦å¯¼å‡ºçš„æ—¥å¿—æ–‡ä»¶ååˆ—è¡¨ï¼ˆNoneè¡¨ç¤ºå¯¼å‡ºæ‰€æœ‰ï¼‰
            level: æ—¥å¿—çº§åˆ«è¿‡æ»¤
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            format: å¯¼å‡ºæ ¼å¼ï¼ˆzip, txtï¼‰
            
        Returns:
            å¯¼å‡ºæ–‡ä»¶çš„è·¯å¾„
        """
        try:
            # ç¡®å®šè¦å¯¼å‡ºçš„æ–‡ä»¶
            if filenames:
                files_to_export = [self.log_dir / f for f in filenames if (self.log_dir / f).exists()]
            else:
                files_to_export = list(self.log_dir.glob("*.log*"))
            
            if not files_to_export:
                raise ValueError("æ²¡æœ‰æ‰¾åˆ°è¦å¯¼å‡ºçš„æ—¥å¿—æ–‡ä»¶")
            
            # åˆ›å»ºå¯¼å‡ºç›®å½•
            export_dir = Path("./exports/logs")
            export_dir.mkdir(parents=True, exist_ok=True)
            
            # ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            if format == "zip":
                export_path = export_dir / f"logs_export_{timestamp}.zip"
                
                # åˆ›å»ºZIPæ–‡ä»¶
                with zipfile.ZipFile(export_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for file_path in files_to_export:
                        # å¦‚æœæœ‰è¿‡æ»¤æ¡ä»¶ï¼Œå…ˆè¿‡æ»¤å†æ·»åŠ 
                        if level or start_time or end_time:
                            filtered_data = self.read_log_file(
                                file_path.name,
                                lines=999999,  # è¯»å–æ‰€æœ‰è¡Œ
                                level=level,
                                start_time=start_time,
                                end_time=end_time
                            )
                            # å°†è¿‡æ»¤åçš„å†…å®¹å†™å…¥ä¸´æ—¶æ–‡ä»¶
                            temp_file = export_dir / f"temp_{file_path.name}"
                            with open(temp_file, 'w', encoding='utf-8') as f:
                                f.write('\n'.join(filtered_data['lines']))
                            zipf.write(temp_file, file_path.name)
                            temp_file.unlink()  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                        else:
                            zipf.write(file_path, file_path.name)
                
                logger.info(f"âœ… æ—¥å¿—å¯¼å‡ºæˆåŠŸ: {export_path}")
                return str(export_path)
            
            elif format == "txt":
                export_path = export_dir / f"logs_export_{timestamp}.txt"
                
                # åˆå¹¶æ‰€æœ‰æ—¥å¿—åˆ°ä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶
                with open(export_path, 'w', encoding='utf-8') as outf:
                    for file_path in files_to_export:
                        outf.write(f"\n{'='*80}\n")
                        outf.write(f"æ–‡ä»¶: {file_path.name}\n")
                        outf.write(f"{'='*80}\n\n")
                        
                        if level or start_time or end_time:
                            filtered_data = self.read_log_file(
                                file_path.name,
                                lines=999999,
                                level=level,
                                start_time=start_time,
                                end_time=end_time
                            )
                            outf.write('\n'.join(filtered_data['lines']))
                        else:
                            with open(file_path, 'r', encoding='utf-8', errors='ignore') as inf:
                                outf.write(inf.read())
                        
                        outf.write('\n\n')
                
                logger.info(f"âœ… æ—¥å¿—å¯¼å‡ºæˆåŠŸ: {export_path}")
                return str(export_path)
            
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format}")
                
        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºæ—¥å¿—å¤±è´¥: {e}")
            raise

    def get_log_statistics(self, days: int = 7) -> Dict[str, Any]:
        """
        è·å–æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            days: ç»Ÿè®¡æœ€è¿‘å‡ å¤©çš„æ—¥å¿—
            
        Returns:
            æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            cutoff_time = datetime.now() - timedelta(days=days)
            
            stats = {
                "total_files": 0,
                "total_size_mb": 0,
                "error_files": 0,
                "recent_errors": [],
                "log_types": {}
            }
            
            for file_path in self.log_dir.glob("*.log*"):
                if not file_path.is_file():
                    continue
                
                stat = file_path.stat()
                modified_time = datetime.fromtimestamp(stat.st_mtime)
                
                if modified_time < cutoff_time:
                    continue
                
                stats["total_files"] += 1
                stats["total_size_mb"] += stat.st_size / (1024 * 1024)
                
                log_type = self._get_log_type(file_path.name)
                stats["log_types"][log_type] = stats["log_types"].get(log_type, 0) + 1
                
                # ç»Ÿè®¡é”™è¯¯æ—¥å¿—
                if log_type == "error":
                    stats["error_files"] += 1
                    # è¯»å–æœ€è¿‘çš„é”™è¯¯
                    try:
                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                            lines = f.readlines()
                            error_lines = [line for line in lines[-100:] if "ERROR" in line]
                            stats["recent_errors"].extend(error_lines[-10:])
                    except Exception:
                        pass
            
            stats["total_size_mb"] = round(stats["total_size_mb"], 2)
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ—¥å¿—ç»Ÿè®¡å¤±è´¥: {e}")
            return {}


# å…¨å±€æœåŠ¡å®ä¾‹
_log_export_service: Optional[LogExportService] = None


def get_log_export_service() -> LogExportService:
    """è·å–æ—¥å¿—å¯¼å‡ºæœåŠ¡å®ä¾‹"""
    global _log_export_service

    if _log_export_service is None:
        # ä»æ—¥å¿—é…ç½®ä¸­è·å–æ—¥å¿—ç›®å½•
        log_dir = _get_log_directory()
        _log_export_service = LogExportService(log_dir=log_dir)

    return _log_export_service


def _get_log_directory() -> str:
    """
    è·å–æ—¥å¿—ç›®å½•è·¯å¾„
    ä¼˜å…ˆçº§ï¼š
    1. ä»æ—¥å¿—é…ç½®æ–‡ä»¶è¯»å–ï¼ˆæ”¯æŒDockerç¯å¢ƒï¼‰
    2. ä»settingsé…ç½®è¯»å–
    3. ä½¿ç”¨é»˜è®¤å€¼ ./logs
    """
    import os
    from pathlib import Path

    try:
        logger.info(f"ğŸ” [_get_log_directory] å¼€å§‹è·å–æ—¥å¿—ç›®å½•")

        # æ£€æŸ¥æ˜¯å¦æ˜¯Dockerç¯å¢ƒ
        docker_env = os.environ.get("DOCKER", "")
        dockerenv_exists = Path("/.dockerenv").exists()
        is_docker = docker_env.lower() in {"1", "true", "yes"} or dockerenv_exists

        logger.info(f"ğŸ” [_get_log_directory] DOCKERç¯å¢ƒå˜é‡: {docker_env}")
        logger.info(f"ğŸ” [_get_log_directory] /.dockerenvå­˜åœ¨: {dockerenv_exists}")
        logger.info(f"ğŸ” [_get_log_directory] åˆ¤å®šä¸ºDockerç¯å¢ƒ: {is_docker}")

        # å°è¯•ä»æ—¥å¿—é…ç½®æ–‡ä»¶è¯»å–
        try:
            import tomllib as toml_loader
            logger.info(f"ğŸ” [_get_log_directory] ä½¿ç”¨ tomllib åŠ è½½TOML")
        except ImportError:
            try:
                import tomli as toml_loader
                logger.info(f"ğŸ” [_get_log_directory] ä½¿ç”¨ tomli åŠ è½½TOML")
            except ImportError:
                toml_loader = None
                logger.warning(f"âš ï¸ [_get_log_directory] æ— æ³•å¯¼å…¥TOMLåŠ è½½å™¨")

        if toml_loader:
            # æ ¹æ®ç¯å¢ƒé€‰æ‹©é…ç½®æ–‡ä»¶
            profile = os.environ.get("LOGGING_PROFILE", "")
            logger.info(f"ğŸ” [_get_log_directory] LOGGING_PROFILE: {profile}")

            cfg_path = Path("config/logging_docker.toml") if profile.lower() == "docker" or is_docker else Path("config/logging.toml")
            logger.info(f"ğŸ” [_get_log_directory] é€‰æ‹©é…ç½®æ–‡ä»¶: {cfg_path}")
            logger.info(f"ğŸ” [_get_log_directory] é…ç½®æ–‡ä»¶å­˜åœ¨: {cfg_path.exists()}")

            if cfg_path.exists():
                try:
                    with cfg_path.open("rb") as f:
                        toml_data = toml_loader.load(f)

                    logger.info(f"ğŸ” [_get_log_directory] æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶")

                    # ä»é…ç½®æ–‡ä»¶è¯»å–æ—¥å¿—ç›®å½•
                    handlers_cfg = toml_data.get("logging", {}).get("handlers", {})
                    file_handler_cfg = handlers_cfg.get("file", {})
                    log_dir = file_handler_cfg.get("directory")

                    logger.info(f"ğŸ” [_get_log_directory] é…ç½®æ–‡ä»¶ä¸­çš„æ—¥å¿—ç›®å½•: {log_dir}")

                    if log_dir:
                        logger.info(f"âœ… [_get_log_directory] ä»æ—¥å¿—é…ç½®æ–‡ä»¶è¯»å–æ—¥å¿—ç›®å½•: {log_dir}")
                        return log_dir
                except Exception as e:
                    logger.warning(f"âš ï¸ [_get_log_directory] è¯»å–æ—¥å¿—é…ç½®æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)

        # å›é€€åˆ°settingsé…ç½®
        try:
            from app.core.config import settings
            log_dir = settings.log_dir
            logger.info(f"ğŸ” [_get_log_directory] settings.log_dir: {log_dir}")
            if log_dir:
                logger.info(f"âœ… [_get_log_directory] ä»settingsè¯»å–æ—¥å¿—ç›®å½•: {log_dir}")
                return log_dir
        except Exception as e:
            logger.warning(f"âš ï¸ [_get_log_directory] ä»settingsè¯»å–æ—¥å¿—ç›®å½•å¤±è´¥: {e}", exc_info=True)

        # Dockerç¯å¢ƒé»˜è®¤ä½¿ç”¨ /app/logs
        if is_docker:
            logger.info("âœ… [_get_log_directory] Dockerç¯å¢ƒï¼Œä½¿ç”¨é»˜è®¤æ—¥å¿—ç›®å½•: /app/logs")
            return "/app/logs"

        # éDockerç¯å¢ƒé»˜è®¤ä½¿ç”¨ ./logs
        logger.info("âœ… [_get_log_directory] ä½¿ç”¨é»˜è®¤æ—¥å¿—ç›®å½•: ./logs")
        return "./logs"

    except Exception as e:
        logger.error(f"âŒ [_get_log_directory] è·å–æ—¥å¿—ç›®å½•å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼ ./logs", exc_info=True)
        return "./logs"

