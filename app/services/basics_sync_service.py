"""
Stock basics synchronization service
- Fetches A-share stock basic info from Tushare
- Enriches with latest market cap (total_mv)
- Upserts into MongoDB collection `stock_basic_info`
- Persists status in collection `sync_status` with key `stock_basics`
- Provides a singleton accessor for reuse across routers/scheduler

This module is async-friendly and offloads blocking IO (Tushare/pandas) to a thread.
"""
from __future__ import annotations

import asyncio
import logging
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

from motor.motor_asyncio import AsyncIOMotorDatabase
from pymongo import UpdateOne

from app.core.database import get_mongo_db
from app.core.config import settings

from app.services.basics_sync import (
    fetch_stock_basic_df as _fetch_stock_basic_df_util,
    find_latest_trade_date as _find_latest_trade_date_util,
    fetch_daily_basic_mv_map as _fetch_daily_basic_mv_map_util,
    fetch_latest_roe_map as _fetch_latest_roe_map_util,
)

logger = logging.getLogger(__name__)

STATUS_COLLECTION = "sync_status"
DATA_COLLECTION = "stock_basic_info"
JOB_KEY = "stock_basics"


@dataclass
class SyncStats:
    started_at: Optional[str] = None
    finished_at: Optional[str] = None
    status: str = "idle"  # idle|running|success|failed
    total: int = 0
    inserted: int = 0
    updated: int = 0
    errors: int = 0
    message: str = ""
    last_trade_date: Optional[str] = None  # YYYYMMDD


class BasicsSyncService:
    def __init__(self) -> None:
        self._lock = asyncio.Lock()
        self._running = False
        self._last_status: Optional[Dict[str, Any]] = None
        self._indexes_ensured = False

    async def _ensure_indexes(self, db: AsyncIOMotorDatabase) -> None:
        """ç¡®ä¿å¿…è¦çš„ç´¢å¼•å­˜åœ¨"""
        if self._indexes_ensured:
            return

        try:
            collection = db[DATA_COLLECTION]
            logger.info("ğŸ“Š æ£€æŸ¥å¹¶åˆ›å»ºè‚¡ç¥¨åŸºç¡€ä¿¡æ¯ç´¢å¼•...")

            # 1. å¤åˆå”¯ä¸€ç´¢å¼•ï¼šè‚¡ç¥¨ä»£ç +æ•°æ®æºï¼ˆç”¨äº upsertï¼‰
            await collection.create_index([
                ("code", 1),
                ("source", 1)
            ], unique=True, name="code_source_unique", background=True)

            # 2. è‚¡ç¥¨ä»£ç ç´¢å¼•ï¼ˆæŸ¥è¯¢æ‰€æœ‰æ•°æ®æºï¼‰
            await collection.create_index([("code", 1)], name="code_index", background=True)

            # 3. æ•°æ®æºç´¢å¼•ï¼ˆæŒ‰æ•°æ®æºç­›é€‰ï¼‰
            await collection.create_index([("source", 1)], name="source_index", background=True)

            # 4. è‚¡ç¥¨åç§°ç´¢å¼•ï¼ˆæŒ‰åç§°æœç´¢ï¼‰
            await collection.create_index([("name", 1)], name="name_index", background=True)

            # 5. è¡Œä¸šç´¢å¼•ï¼ˆæŒ‰è¡Œä¸šç­›é€‰ï¼‰
            await collection.create_index([("industry", 1)], name="industry_index", background=True)

            # 6. å¸‚åœºç´¢å¼•ï¼ˆæŒ‰å¸‚åœºç­›é€‰ï¼‰
            await collection.create_index([("market", 1)], name="market_index", background=True)

            # 7. æ€»å¸‚å€¼ç´¢å¼•ï¼ˆæŒ‰å¸‚å€¼æ’åºï¼‰
            await collection.create_index([("total_mv", -1)], name="total_mv_desc", background=True)

            # 8. æµé€šå¸‚å€¼ç´¢å¼•ï¼ˆæŒ‰æµé€šå¸‚å€¼æ’åºï¼‰
            await collection.create_index([("circ_mv", -1)], name="circ_mv_desc", background=True)

            # 9. æ›´æ–°æ—¶é—´ç´¢å¼•ï¼ˆæ•°æ®ç»´æŠ¤ï¼‰
            await collection.create_index([("updated_at", -1)], name="updated_at_desc", background=True)

            # 10. PEç´¢å¼•ï¼ˆæŒ‰ä¼°å€¼ç­›é€‰ï¼‰
            await collection.create_index([("pe", 1)], name="pe_index", background=True)

            # 11. PBç´¢å¼•ï¼ˆæŒ‰ä¼°å€¼ç­›é€‰ï¼‰
            await collection.create_index([("pb", 1)], name="pb_index", background=True)

            # 12. æ¢æ‰‹ç‡ç´¢å¼•ï¼ˆæŒ‰æ´»è·ƒåº¦ç­›é€‰ï¼‰
            await collection.create_index([("turnover_rate", -1)], name="turnover_rate_desc", background=True)

            self._indexes_ensured = True
            logger.info("âœ… è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ç´¢å¼•æ£€æŸ¥å®Œæˆ")
        except Exception as e:
            # ç´¢å¼•åˆ›å»ºå¤±è´¥ä¸åº”è¯¥é˜»æ­¢æœåŠ¡å¯åŠ¨
            logger.warning(f"âš ï¸ åˆ›å»ºç´¢å¼•æ—¶å‡ºç°è­¦å‘Šï¼ˆå¯èƒ½å·²å­˜åœ¨ï¼‰: {e}")

    async def get_status(self, db: Optional[AsyncIOMotorDatabase] = None) -> Dict[str, Any]:
        """Return last persisted status; falls back to in-memory snapshot."""
        try:
            db = db or get_mongo_db()
            doc = await db[STATUS_COLLECTION].find_one({"job": JOB_KEY})
            if doc:
                doc.pop("_id", None)
                return doc
        except Exception as e:
            logger.warning(f"Failed to load sync status from DB: {e}")
        return self._last_status or {"job": JOB_KEY, "status": "idle"}

    async def _persist_status(self, db: AsyncIOMotorDatabase, stats: Dict[str, Any]) -> None:
        stats["job"] = JOB_KEY
        await db[STATUS_COLLECTION].update_one({"job": JOB_KEY}, {"$set": stats}, upsert=True)
        self._last_status = {k: v for k, v in stats.items() if k != "_id"}

    async def _execute_bulk_write_with_retry(
        self,
        db: AsyncIOMotorDatabase,
        operations: List,
        max_retries: int = 3
    ) -> tuple:
        """
        æ‰§è¡Œæ‰¹é‡å†™å…¥ï¼Œå¸¦é‡è¯•æœºåˆ¶

        Args:
            db: MongoDBæ•°æ®åº“å®ä¾‹
            operations: æ‰¹é‡æ“ä½œåˆ—è¡¨
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

        Returns:
            (æ–°å¢æ•°é‡, æ›´æ–°æ•°é‡)
        """
        inserted = 0
        updated = 0
        retry_count = 0

        while retry_count < max_retries:
            try:
                result = await db[DATA_COLLECTION].bulk_write(operations, ordered=False)
                inserted = len(result.upserted_ids) if result.upserted_ids else 0
                updated = result.modified_count or 0
                logger.debug(f"âœ… æ‰¹é‡å†™å…¥æˆåŠŸ: æ–°å¢ {inserted}, æ›´æ–° {updated}")
                return inserted, updated

            except asyncio.TimeoutError as e:
                retry_count += 1
                if retry_count < max_retries:
                    wait_time = 2 ** retry_count  # æŒ‡æ•°é€€é¿ï¼š2ç§’ã€4ç§’ã€8ç§’
                    logger.warning(f"âš ï¸ æ‰¹é‡å†™å…¥è¶…æ—¶ (ç¬¬{retry_count}æ¬¡é‡è¯•)ï¼Œç­‰å¾…{wait_time}ç§’åé‡è¯•...")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"âŒ æ‰¹é‡å†™å…¥å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡: {e}")
                    return 0, 0

            except Exception as e:
                logger.error(f"âŒ æ‰¹é‡å†™å…¥å¤±è´¥: {e}")
                return 0, 0

        return inserted, updated

    async def run_full_sync(self, force: bool = False) -> Dict[str, Any]:
        """Run a full sync. If already running, return current status unless force."""
        async with self._lock:
            if self._running and not force:
                logger.info("Stock basics sync already running; skip start")
                return await self.get_status()
            self._running = True

        db = get_mongo_db()

        # ğŸ”¥ ç¡®ä¿ç´¢å¼•å­˜åœ¨ï¼ˆæå‡æŸ¥è¯¢å’Œ upsert æ€§èƒ½ï¼‰
        await self._ensure_indexes(db)

        stats = SyncStats()
        stats.started_at = datetime.utcnow().isoformat()
        stats.status = "running"
        await self._persist_status(db, stats.__dict__.copy())

        try:
            # Step 0: Check if Tushare is enabled
            if not settings.TUSHARE_ENABLED:
                error_msg = (
                    "âŒ Tushare æ•°æ®æºå·²ç¦ç”¨ (TUSHARE_ENABLED=false)\n"
                    "ğŸ’¡ æ­¤æœåŠ¡ä»…æ”¯æŒ Tushare æ•°æ®æº\n"
                    "ğŸ“‹ è§£å†³æ–¹æ¡ˆï¼š\n"
                    "   1. åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® TUSHARE_ENABLED=true å¹¶é…ç½® TUSHARE_TOKEN\n"
                    "   2. ç³»ç»Ÿå·²è‡ªåŠ¨åˆ‡æ¢åˆ°å¤šæ•°æ®æºåŒæ­¥æœåŠ¡ï¼ˆæ”¯æŒ AKShare/BaoStockï¼‰"
                )
                logger.warning(error_msg)
                raise RuntimeError(error_msg)

            # Step 1: Fetch stock basic list from Tushare (blocking -> thread)
            stock_df = await asyncio.to_thread(self._fetch_stock_basic_df)
            if stock_df is None or getattr(stock_df, "empty", True):
                raise RuntimeError("Tushare returned empty stock_basic list")

            # Step 2: Determine latest trade_date and fetch daily_basic for financial metrics (blocking -> thread)
            latest_trade_date = await asyncio.to_thread(self._find_latest_trade_date)
            stats.last_trade_date = latest_trade_date
            daily_data_map = await asyncio.to_thread(self._fetch_daily_basic_mv_map, latest_trade_date)

            # Step 2b: Fetch latest ROE snapshot from fina_indicator (blocking -> thread)
            roe_map = await asyncio.to_thread(self._fetch_latest_roe_map)

            # Step 3: Upsert into MongoDB (batched bulk writes)
            ops: List[UpdateOne] = []
            now_iso = datetime.utcnow().isoformat()
            for _, row in stock_df.iterrows():  # type: ignore
                name = row.get("name") or ""
                area = row.get("area") or ""
                industry = row.get("industry") or ""
                market = row.get("market") or ""
                list_date = row.get("list_date") or ""
                ts_code = row.get("ts_code") or ""

                # Extract 6-digit stock code from ts_code (e.g., "000001.SZ" -> "000001")
                if isinstance(ts_code, str) and "." in ts_code:
                    code = ts_code.split(".")[0]  # Keep the 6-digit format
                else:
                    # Fallback to symbol with zero-padding if ts_code is invalid
                    symbol = row.get("symbol") or ""
                    code = str(symbol).zfill(6) if symbol else ""

                # æ ¹æ® ts_code åˆ¤æ–­äº¤æ˜“æ‰€
                if isinstance(ts_code, str):
                    if ts_code.endswith(".SH"):
                        sse = "ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€"
                    elif ts_code.endswith(".SZ"):
                        sse = "æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€"
                    elif ts_code.endswith(".BJ"):
                        sse = "åŒ—äº¬è¯åˆ¸äº¤æ˜“æ‰€"
                    else:
                        sse = "æœªçŸ¥"
                else:
                    sse = "æœªçŸ¥"

                category = "stock_cn"

                # Extract daily financial metrics - use ts_code directly for matching
                daily_metrics = {}
                if isinstance(ts_code, str) and ts_code in daily_data_map:
                    daily_metrics = daily_data_map[ts_code]

                # Process market cap (convert from ä¸‡å…ƒ to äº¿å…ƒ)
                total_mv_yi = None
                circ_mv_yi = None
                if "total_mv" in daily_metrics:
                    try:
                        total_mv_yi = float(daily_metrics["total_mv"]) / 10000.0
                    except Exception:
                        pass
                if "circ_mv" in daily_metrics:
                    try:
                        circ_mv_yi = float(daily_metrics["circ_mv"]) / 10000.0
                    except Exception:
                        pass

                # ç”Ÿæˆ full_symbolï¼ˆå®Œæ•´æ ‡å‡†åŒ–ä»£ç ï¼‰
                full_symbol = self._generate_full_symbol(code)

                doc = {
                    "code": code,
                    "symbol": code,  # æ·»åŠ  symbol å­—æ®µï¼ˆæ ‡å‡†åŒ–å­—æ®µï¼‰
                    "name": name,
                    "area": area,
                    "industry": industry,
                    "market": market,
                    "list_date": list_date,
                    "sse": sse,
                    "sec": category,
                    "source": "tushare",  # ğŸ”¥ æ•°æ®æºæ ‡è¯†
                    "updated_at": now_iso,
                    "full_symbol": full_symbol,  # æ·»åŠ å®Œæ•´æ ‡å‡†åŒ–ä»£ç 
                }

                # Add market cap fields
                if total_mv_yi is not None:
                    doc["total_mv"] = total_mv_yi
                if circ_mv_yi is not None:
                    doc["circ_mv"] = circ_mv_yi

                # Add financial ratios (ğŸ”¥ æ–°å¢ ps å’Œ ps_ttm)
                for field in ["pe", "pb", "ps", "pe_ttm", "pb_mrq", "ps_ttm"]:
                    if field in daily_metrics:
                        doc[field] = daily_metrics[field]
                # ROE from fina_indicator snapshot
                if isinstance(ts_code, str) and ts_code in roe_map:
                    roe_val = roe_map[ts_code].get("roe")
                    if roe_val is not None:
                        doc["roe"] = roe_val

                # Add trading metrics
                for field in ["turnover_rate", "volume_ratio"]:
                    if field in daily_metrics:
                        doc[field] = daily_metrics[field]

                # ğŸ”¥ Add share capital fields (total_share, float_share)
                for field in ["total_share", "float_share"]:
                    if field in daily_metrics:
                        doc[field] = daily_metrics[field]

                # ğŸ”¥ ä½¿ç”¨ (code, source) è”åˆæŸ¥è¯¢æ¡ä»¶
                ops.append(
                    UpdateOne({"code": code, "source": "tushare"}, {"$set": doc}, upsert=True)
                )

            inserted = 0
            updated = 0
            errors = 0
            # Execute in chunks to avoid oversized batches
            BATCH = 1000
            for i in range(0, len(ops), BATCH):
                batch = ops[i : i + BATCH]
                batch_inserted, batch_updated = await self._execute_bulk_write_with_retry(db, batch)

                if batch_inserted > 0 or batch_updated > 0:
                    inserted += batch_inserted
                    updated += batch_updated
                else:
                    errors += 1
                    logger.error(f"Bulk write error on batch {i//BATCH}")

            stats.total = len(ops)
            stats.inserted = inserted
            stats.updated = updated
            stats.errors = errors
            stats.status = "success" if errors == 0 else "success_with_errors"
            stats.finished_at = datetime.utcnow().isoformat()
            await self._persist_status(db, stats.__dict__.copy())
            logger.info(
                f"Stock basics sync finished: total={stats.total} inserted={inserted} updated={updated} errors={errors} trade_date={latest_trade_date}"
            )
            return stats.__dict__

        except Exception as e:
            stats.status = "failed"
            stats.message = str(e)
            stats.finished_at = datetime.utcnow().isoformat()
            await self._persist_status(db, stats.__dict__.copy())
            logger.exception(f"Stock basics sync failed: {e}")
            return stats.__dict__
        finally:
            async with self._lock:
                self._running = False

    # ---- Blocking helpers (run in thread) ----
    def _fetch_stock_basic_df(self):
        """å§”æ‰˜åˆ° basics_sync.utils çš„é˜»å¡å¼å®ç°"""
        return _fetch_stock_basic_df_util()

    def _find_latest_trade_date(self) -> str:
        """Delegate to basics_sync.utils (blocking)"""
        return _find_latest_trade_date_util()

    def _fetch_daily_basic_mv_map(self, trade_date: str) -> Dict[str, Dict[str, float]]:
        """Delegate to basics_sync.utils (blocking)"""
        return _fetch_daily_basic_mv_map_util(trade_date)

    def _fetch_latest_roe_map(self) -> Dict[str, Dict[str, float]]:
        """Delegate to basics_sync.utils (blocking)"""
        return _fetch_latest_roe_map_util()

    def _generate_full_symbol(self, code: str) -> str:
        """
        æ ¹æ®è‚¡ç¥¨ä»£ç ç”Ÿæˆå®Œæ•´æ ‡å‡†åŒ–ä»£ç 

        Args:
            code: 6ä½è‚¡ç¥¨ä»£ç 

        Returns:
            å®Œæ•´æ ‡å‡†åŒ–ä»£ç ï¼ˆå¦‚ 000001.SZï¼‰ï¼Œå¦‚æœä»£ç æ— æ•ˆåˆ™è¿”å›åŸå§‹ä»£ç ï¼ˆç¡®ä¿ä¸ä¸ºç©ºï¼‰
        """
        # ç¡®ä¿ code ä¸ä¸ºç©º
        if not code:
            return ""

        # æ ‡å‡†åŒ–ä¸ºå­—ç¬¦ä¸²å¹¶å»é™¤ç©ºæ ¼
        code = str(code).strip()

        # å¦‚æœé•¿åº¦ä¸æ˜¯ 6ï¼Œè¿”å›åŸå§‹ä»£ç ï¼ˆé¿å…è¿”å› Noneï¼‰
        if len(code) != 6:
            return code

        # æ ¹æ®ä»£ç åˆ¤æ–­äº¤æ˜“æ‰€
        if code.startswith(('60', '68', '90')):
            return f"{code}.SS"  # ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€
        elif code.startswith(('00', '30', '20')):
            return f"{code}.SZ"  # æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€
        elif code.startswith(('8', '4')):
            return f"{code}.BJ"  # åŒ—äº¬è¯åˆ¸äº¤æ˜“æ‰€
        else:
            # æ— æ³•è¯†åˆ«çš„ä»£ç ï¼Œè¿”å›åŸå§‹ä»£ç ï¼ˆç¡®ä¿ä¸ä¸ºç©ºï¼‰
            return code if code else ""


# Singleton accessor
_basics_sync_service: Optional[BasicsSyncService] = None


def get_basics_sync_service() -> BasicsSyncService:
    global _basics_sync_service
    if _basics_sync_service is None:
        _basics_sync_service = BasicsSyncService()
    return _basics_sync_service

