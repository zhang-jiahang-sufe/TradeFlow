"""
æ¸¯è‚¡å’Œç¾è‚¡æ•°æ®æœåŠ¡
ğŸ”¥ å¤ç”¨ç»Ÿä¸€æ•°æ®æºç®¡ç†å™¨ï¼ˆUnifiedStockServiceï¼‰
ğŸ”¥ æŒ‰ç…§æ•°æ®åº“é…ç½®çš„æ•°æ®æºä¼˜å…ˆçº§è°ƒç”¨API
ğŸ”¥ è¯·æ±‚å»é‡æœºåˆ¶ï¼šé˜²æ­¢å¹¶å‘è¯·æ±‚é‡å¤è°ƒç”¨API
"""
from typing import Optional, Dict, List, Tuple
from datetime import datetime, timedelta
import logging
import json
import re
import asyncio
from collections import defaultdict

# å¤ç”¨ç°æœ‰ç¼“å­˜ç³»ç»Ÿ
from tradingagents.dataflows.cache import get_cache

# å¤ç”¨ç°æœ‰æ•°æ®æºæä¾›è€…
from tradingagents.dataflows.providers.hk.hk_stock import HKStockProvider

logger = logging.getLogger(__name__)


class ForeignStockService:
    """æ¸¯è‚¡å’Œç¾è‚¡æ•°æ®æœåŠ¡ï¼ˆå¤ç”¨ç»Ÿä¸€æ•°æ®æºç®¡ç†å™¨ï¼ŒæŒ‰æ•°æ®åº“ä¼˜å…ˆçº§è°ƒç”¨ï¼‰"""

    # ç¼“å­˜æ—¶é—´é…ç½®ï¼ˆç§’ï¼‰
    CACHE_TTL = {
        "HK": {
            "quote": 600,        # 10åˆ†é’Ÿï¼ˆå®æ—¶è¡Œæƒ…ï¼‰
            "info": 86400,       # 1å¤©ï¼ˆåŸºç¡€ä¿¡æ¯ï¼‰
            "kline": 7200,       # 2å°æ—¶ï¼ˆKçº¿æ•°æ®ï¼‰
        },
        "US": {
            "quote": 600,        # 10åˆ†é’Ÿ
            "info": 86400,       # 1å¤©
            "kline": 7200,       # 2å°æ—¶
        }
    }

    def __init__(self, db=None):
        # ä½¿ç”¨ç»Ÿä¸€ç¼“å­˜ç³»ç»Ÿï¼ˆè‡ªåŠ¨é€‰æ‹© MongoDB/Redis/Fileï¼‰
        self.cache = get_cache()

        # åˆå§‹åŒ–æ¸¯è‚¡æ•°æ®æºæä¾›è€…
        self.hk_provider = HKStockProvider()

        # ä¿å­˜æ•°æ®åº“è¿æ¥ï¼ˆç”¨äºæŸ¥è¯¢æ•°æ®æºä¼˜å…ˆçº§ï¼‰
        self.db = db

        # ğŸ”¥ è¯·æ±‚å»é‡ï¼šä¸ºæ¯ä¸ª (market, code, data_type) åˆ›å»ºç‹¬ç«‹çš„é”
        self._request_locks = defaultdict(asyncio.Lock)

        # ğŸ”¥ æ­£åœ¨è¿›è¡Œçš„è¯·æ±‚ç¼“å­˜ï¼ˆç”¨äºå…±äº«ç»“æœï¼‰
        self._pending_requests = {}

        logger.info("âœ… ForeignStockService åˆå§‹åŒ–å®Œæˆï¼ˆå·²å¯ç”¨è¯·æ±‚å»é‡ï¼‰")
    
    async def get_quote(self, market: str, code: str, force_refresh: bool = False) -> Dict:
        """
        è·å–å®æ—¶è¡Œæƒ…
        
        Args:
            market: å¸‚åœºç±»å‹ (HK/US)
            code: è‚¡ç¥¨ä»£ç 
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆè·³è¿‡ç¼“å­˜ï¼‰
        
        Returns:
            å®æ—¶è¡Œæƒ…æ•°æ®
        
        æµç¨‹ï¼š
        1. æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
        2. ä»ç¼“å­˜è·å–ï¼ˆRedis â†’ MongoDB â†’ Fileï¼‰
        3. ç¼“å­˜æœªå‘½ä¸­ â†’ è°ƒç”¨æ•°æ®æºAPIï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
        4. ä¿å­˜åˆ°ç¼“å­˜
        """
        if market == 'HK':
            return await self._get_hk_quote(code, force_refresh)
        elif market == 'US':
            return await self._get_us_quote(code, force_refresh)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¸‚åœºç±»å‹: {market}")
    
    async def get_basic_info(self, market: str, code: str, force_refresh: bool = False) -> Dict:
        """
        è·å–åŸºç¡€ä¿¡æ¯
        
        Args:
            market: å¸‚åœºç±»å‹ (HK/US)
            code: è‚¡ç¥¨ä»£ç 
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
        
        Returns:
            åŸºç¡€ä¿¡æ¯æ•°æ®
        """
        if market == 'HK':
            return await self._get_hk_info(code, force_refresh)
        elif market == 'US':
            return await self._get_us_info(code, force_refresh)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¸‚åœºç±»å‹: {market}")
    
    async def get_kline(self, market: str, code: str, period: str = 'day', 
                       limit: int = 120, force_refresh: bool = False) -> List[Dict]:
        """
        è·å–Kçº¿æ•°æ®
        
        Args:
            market: å¸‚åœºç±»å‹ (HK/US)
            code: è‚¡ç¥¨ä»£ç 
            period: å‘¨æœŸ (day/week/month)
            limit: æ•°æ®æ¡æ•°
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
        
        Returns:
            Kçº¿æ•°æ®åˆ—è¡¨
        """
        if market == 'HK':
            return await self._get_hk_kline(code, period, limit, force_refresh)
        elif market == 'US':
            return await self._get_us_kline(code, period, limit, force_refresh)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¸‚åœºç±»å‹: {market}")
    
    async def _get_hk_quote(self, code: str, force_refresh: bool = False) -> Dict:
        """
        è·å–æ¸¯è‚¡å®æ—¶è¡Œæƒ…ï¼ˆå¸¦è¯·æ±‚å»é‡ï¼‰
        ğŸ”¥ æŒ‰ç…§æ•°æ®åº“é…ç½®çš„æ•°æ®æºä¼˜å…ˆçº§è°ƒç”¨API
        ğŸ”¥ é˜²æ­¢å¹¶å‘è¯·æ±‚é‡å¤è°ƒç”¨API
        """
        # 1. æ£€æŸ¥ç¼“å­˜ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
        if not force_refresh:
            cache_key = self.cache.find_cached_stock_data(
                symbol=code,
                data_source="hk_realtime_quote"
            )

            if cache_key:
                cached_data = self.cache.load_stock_data(cache_key)
                if cached_data:
                    logger.info(f"âš¡ ä»ç¼“å­˜è·å–æ¸¯è‚¡è¡Œæƒ…: {code}")
                    return self._parse_cached_data(cached_data, 'HK', code)

        # 2. ğŸ”¥ è¯·æ±‚å»é‡ï¼šä½¿ç”¨é”ç¡®ä¿åŒä¸€è‚¡ç¥¨åŒæ—¶åªæœ‰ä¸€ä¸ªAPIè°ƒç”¨
        request_key = f"HK_quote_{code}_{force_refresh}"
        lock = self._request_locks[request_key]

        async with lock:
            # ğŸ”¥ å†æ¬¡æ£€æŸ¥ç¼“å­˜ï¼ˆå¯èƒ½åœ¨ç­‰å¾…é”çš„è¿‡ç¨‹ä¸­ï¼Œå…¶ä»–è¯·æ±‚å·²ç»å®Œæˆå¹¶ç¼“å­˜äº†æ•°æ®ï¼‰
            # å³ä½¿ force_refresh=Trueï¼Œä¹Ÿè¦æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å¹¶å‘è¯·æ±‚åˆšåˆšå®Œæˆ
            cache_key = self.cache.find_cached_stock_data(
                symbol=code,
                data_source="hk_realtime_quote"
            )
            if cache_key:
                cached_data = self.cache.load_stock_data(cache_key)
                if cached_data:
                    # æ£€æŸ¥ç¼“å­˜æ—¶é—´ï¼Œå¦‚æœæ˜¯æœ€è¿‘1ç§’å†…çš„ï¼Œè¯´æ˜æ˜¯å¹¶å‘è¯·æ±‚åˆšåˆšç¼“å­˜çš„
                    try:
                        data_dict = json.loads(cached_data) if isinstance(cached_data, str) else cached_data
                        updated_at = data_dict.get('updated_at', '')
                        if updated_at:
                            cache_time = datetime.fromisoformat(updated_at)
                            time_diff = (datetime.now() - cache_time).total_seconds()
                            if time_diff < 1:  # 1ç§’å†…çš„ç¼“å­˜ï¼Œè¯´æ˜æ˜¯å¹¶å‘è¯·æ±‚åˆšåˆšå®Œæˆçš„
                                logger.info(f"âš¡ [å»é‡] ä½¿ç”¨å¹¶å‘è¯·æ±‚çš„ç»“æœ: {code} (ç¼“å­˜æ—¶é—´: {time_diff:.2f}ç§’å‰)")
                                return self._parse_cached_data(cached_data, 'HK', code)
                    except Exception as e:
                        logger.debug(f"æ£€æŸ¥ç¼“å­˜æ—¶é—´å¤±è´¥: {e}")

                    # å¦‚æœä¸æ˜¯å¼ºåˆ¶åˆ·æ–°ï¼Œä½¿ç”¨ç¼“å­˜
                    if not force_refresh:
                        logger.info(f"âš¡ [å»é‡å] ä»ç¼“å­˜è·å–æ¸¯è‚¡è¡Œæƒ…: {code}")
                        return self._parse_cached_data(cached_data, 'HK', code)

            logger.info(f"ğŸ”„ å¼€å§‹è·å–æ¸¯è‚¡è¡Œæƒ…: {code} (force_refresh={force_refresh})")

            # 3. ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§ï¼ˆä½¿ç”¨ç»Ÿä¸€æ–¹æ³•ï¼‰
            source_priority = await self._get_source_priority('HK')

            # 4. æŒ‰ä¼˜å…ˆçº§å°è¯•å„ä¸ªæ•°æ®æº
            quote_data = None
            data_source = None

            # æ•°æ®æºåç§°æ˜ å°„ï¼ˆæ•°æ®åº“åç§° â†’ å¤„ç†å‡½æ•°ï¼‰
            # ğŸ”¥ åªæœ‰è¿™äº›æ˜¯æœ‰æ•ˆçš„æ•°æ®æºåç§°
            source_handlers = {
                'yahoo_finance': ('yfinance', self._get_hk_quote_from_yfinance),
                'akshare': ('akshare', self._get_hk_quote_from_akshare),
            }

            # è¿‡æ»¤æœ‰æ•ˆæ•°æ®æºå¹¶å»é‡
            valid_priority = []
            seen = set()
            for source_name in source_priority:
                source_key = source_name.lower()
                # åªä¿ç•™æœ‰æ•ˆçš„æ•°æ®æº
                if source_key in source_handlers and source_key not in seen:
                    seen.add(source_key)
                    valid_priority.append(source_name)

            if not valid_priority:
                logger.warning(f"âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®æœ‰æ•ˆçš„æ¸¯è‚¡æ•°æ®æºï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
                valid_priority = ['yahoo_finance', 'akshare']

            logger.info(f"ğŸ“Š [HKæœ‰æ•ˆæ•°æ®æº] {valid_priority} (è‚¡ç¥¨: {code})")

            for source_name in valid_priority:
                source_key = source_name.lower()
                handler_name, handler_func = source_handlers[source_key]
                try:
                    # ğŸ”¥ ä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                    quote_data = await asyncio.to_thread(handler_func, code)
                    data_source = handler_name

                    if quote_data:
                        logger.info(f"âœ… {data_source}è·å–æ¸¯è‚¡è¡Œæƒ…æˆåŠŸ: {code}")
                        break
                except Exception as e:
                    logger.warning(f"âš ï¸ {source_name}è·å–å¤±è´¥ ({code}): {e}")
                    continue

            if not quote_data:
                raise Exception(f"æ— æ³•è·å–æ¸¯è‚¡{code}çš„è¡Œæƒ…æ•°æ®ï¼šæ‰€æœ‰æ•°æ®æºå‡å¤±è´¥")

            # 5. æ ¼å¼åŒ–æ•°æ®
            formatted_data = self._format_hk_quote(quote_data, code, data_source)

            # 6. ä¿å­˜åˆ°ç¼“å­˜
            self.cache.save_stock_data(
                symbol=code,
                data=json.dumps(formatted_data, ensure_ascii=False),
                data_source="hk_realtime_quote"
            )
            logger.info(f"ğŸ’¾ æ¸¯è‚¡è¡Œæƒ…å·²ç¼“å­˜: {code}")

            return formatted_data

    async def _get_source_priority(self, market: str) -> List[str]:
        """
        ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§ï¼ˆç»Ÿä¸€æ–¹æ³•ï¼‰
        ğŸ”¥ å¤ç”¨ UnifiedStockService çš„å®ç°
        """
        market_category_map = {
            "CN": "a_shares",
            "HK": "hk_stocks",
            "US": "us_stocks"
        }

        market_category_id = market_category_map.get(market)

        try:
            # ä» datasource_groupings é›†åˆæŸ¥è¯¢
            groupings = await self.db.datasource_groupings.find({
                "market_category_id": market_category_id,
                "enabled": True
            }).sort("priority", -1).to_list(length=None)

            if groupings:
                priority_list = [g["data_source_name"] for g in groupings]
                logger.info(f"ğŸ“Š [{market}æ•°æ®æºä¼˜å…ˆçº§] ä»æ•°æ®åº“è¯»å–: {priority_list}")
                return priority_list
        except Exception as e:
            logger.warning(f"âš ï¸ [{market}æ•°æ®æºä¼˜å…ˆçº§] ä»æ•°æ®åº“è¯»å–å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")

        # é»˜è®¤ä¼˜å…ˆçº§
        default_priority = {
            "CN": ["tushare", "akshare", "baostock"],
            "HK": ["yfinance", "akshare"],
            "US": ["yfinance", "alpha_vantage", "finnhub"]
        }
        priority_list = default_priority.get(market, [])
        logger.info(f"ğŸ“Š [{market}æ•°æ®æºä¼˜å…ˆçº§] ä½¿ç”¨é»˜è®¤: {priority_list}")
        return priority_list

    def _get_hk_quote_from_yfinance(self, code: str) -> Dict:
        """ä»yfinanceè·å–æ¸¯è‚¡è¡Œæƒ…"""
        quote_data = self.hk_provider.get_real_time_price(code)
        if not quote_data:
            raise Exception("æ— æ•°æ®")
        return quote_data

    def _get_hk_quote_from_akshare(self, code: str) -> Dict:
        """ä»AKShareè·å–æ¸¯è‚¡è¡Œæƒ…"""
        from tradingagents.dataflows.providers.hk.improved_hk import get_hk_stock_info_akshare
        info = get_hk_stock_info_akshare(code)
        if not info or 'error' in info:
            raise Exception("æ— æ•°æ®")

        # æ£€æŸ¥æ˜¯å¦æœ‰ä»·æ ¼æ•°æ®
        if not info.get('price'):
            raise Exception("æ— ä»·æ ¼æ•°æ®")

        return info
    
    async def _get_us_quote(self, code: str, force_refresh: bool = False) -> Dict:
        """
        è·å–ç¾è‚¡å®æ—¶è¡Œæƒ…ï¼ˆå¸¦è¯·æ±‚å»é‡ï¼‰
        ğŸ”¥ æŒ‰ç…§æ•°æ®åº“é…ç½®çš„æ•°æ®æºä¼˜å…ˆçº§è°ƒç”¨API
        ğŸ”¥ é˜²æ­¢å¹¶å‘è¯·æ±‚é‡å¤è°ƒç”¨API
        """
        # 1. æ£€æŸ¥ç¼“å­˜ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
        if not force_refresh:
            cache_key = self.cache.find_cached_stock_data(
                symbol=code,
                data_source="us_realtime_quote"
            )

            if cache_key:
                cached_data = self.cache.load_stock_data(cache_key)
                if cached_data:
                    logger.info(f"âš¡ ä»ç¼“å­˜è·å–ç¾è‚¡è¡Œæƒ…: {code}")
                    return self._parse_cached_data(cached_data, 'US', code)

        # 2. ğŸ”¥ è¯·æ±‚å»é‡ï¼šä½¿ç”¨é”ç¡®ä¿åŒä¸€è‚¡ç¥¨åŒæ—¶åªæœ‰ä¸€ä¸ªAPIè°ƒç”¨
        request_key = f"US_quote_{code}_{force_refresh}"
        lock = self._request_locks[request_key]

        async with lock:
            # ğŸ”¥ å†æ¬¡æ£€æŸ¥ç¼“å­˜ï¼ˆå¯èƒ½åœ¨ç­‰å¾…é”çš„è¿‡ç¨‹ä¸­ï¼Œå…¶ä»–è¯·æ±‚å·²ç»å®Œæˆå¹¶ç¼“å­˜äº†æ•°æ®ï¼‰
            cache_key = self.cache.find_cached_stock_data(
                symbol=code,
                data_source="us_realtime_quote"
            )
            if cache_key:
                cached_data = self.cache.load_stock_data(cache_key)
                if cached_data:
                    # æ£€æŸ¥ç¼“å­˜æ—¶é—´ï¼Œå¦‚æœæ˜¯æœ€è¿‘1ç§’å†…çš„ï¼Œè¯´æ˜æ˜¯å¹¶å‘è¯·æ±‚åˆšåˆšç¼“å­˜çš„
                    try:
                        data_dict = json.loads(cached_data) if isinstance(cached_data, str) else cached_data
                        updated_at = data_dict.get('updated_at', '')
                        if updated_at:
                            cache_time = datetime.fromisoformat(updated_at)
                            time_diff = (datetime.now() - cache_time).total_seconds()
                            if time_diff < 1:  # 1ç§’å†…çš„ç¼“å­˜ï¼Œè¯´æ˜æ˜¯å¹¶å‘è¯·æ±‚åˆšåˆšå®Œæˆçš„
                                logger.info(f"âš¡ [å»é‡] ä½¿ç”¨å¹¶å‘è¯·æ±‚çš„ç»“æœ: {code} (ç¼“å­˜æ—¶é—´: {time_diff:.2f}ç§’å‰)")
                                return self._parse_cached_data(cached_data, 'US', code)
                    except Exception as e:
                        logger.debug(f"æ£€æŸ¥ç¼“å­˜æ—¶é—´å¤±è´¥: {e}")

                    # å¦‚æœä¸æ˜¯å¼ºåˆ¶åˆ·æ–°ï¼Œä½¿ç”¨ç¼“å­˜
                    if not force_refresh:
                        logger.info(f"âš¡ [å»é‡å] ä»ç¼“å­˜è·å–ç¾è‚¡è¡Œæƒ…: {code}")
                        return self._parse_cached_data(cached_data, 'US', code)

            logger.info(f"ğŸ”„ å¼€å§‹è·å–ç¾è‚¡è¡Œæƒ…: {code} (force_refresh={force_refresh})")

            # 3. ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§ï¼ˆä½¿ç”¨ç»Ÿä¸€æ–¹æ³•ï¼‰
            source_priority = await self._get_source_priority('US')

            # 4. æŒ‰ä¼˜å…ˆçº§å°è¯•å„ä¸ªæ•°æ®æº
            quote_data = None
            data_source = None

            # æ•°æ®æºåç§°æ˜ å°„ï¼ˆæ•°æ®åº“åç§° â†’ å¤„ç†å‡½æ•°ï¼‰
            # ğŸ”¥ åªæœ‰è¿™äº›æ˜¯æœ‰æ•ˆçš„æ•°æ®æºåç§°ï¼šalpha_vantage, yahoo_finance, finnhub
            source_handlers = {
                'alpha_vantage': ('alpha_vantage', self._get_us_quote_from_alpha_vantage),
                'yahoo_finance': ('yfinance', self._get_us_quote_from_yfinance),
                'finnhub': ('finnhub', self._get_us_quote_from_finnhub),
            }

            # è¿‡æ»¤æœ‰æ•ˆæ•°æ®æºå¹¶å»é‡
            valid_priority = []
            seen = set()
            for source_name in source_priority:
                source_key = source_name.lower()
                # åªä¿ç•™æœ‰æ•ˆçš„æ•°æ®æº
                if source_key in source_handlers and source_key not in seen:
                    seen.add(source_key)
                    valid_priority.append(source_name)

            if not valid_priority:
                logger.warning("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®æœ‰æ•ˆçš„ç¾è‚¡æ•°æ®æºï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
                valid_priority = ['yahoo_finance', 'alpha_vantage', 'finnhub']

            logger.info(f"ğŸ“Š [USæœ‰æ•ˆæ•°æ®æº] {valid_priority} (è‚¡ç¥¨: {code})")

            for source_name in valid_priority:
                source_key = source_name.lower()
                handler_name, handler_func = source_handlers[source_key]
                try:
                    # ğŸ”¥ ä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                    quote_data = await asyncio.to_thread(handler_func, code)
                    data_source = handler_name

                    if quote_data:
                        logger.info(f"âœ… {data_source}è·å–ç¾è‚¡è¡Œæƒ…æˆåŠŸ: {code}")
                        break
                except Exception as e:
                    logger.warning(f"âš ï¸ {source_name}è·å–å¤±è´¥ ({code}): {e}")
                    continue

            if not quote_data:
                raise Exception(f"æ— æ³•è·å–ç¾è‚¡{code}çš„è¡Œæƒ…æ•°æ®ï¼šæ‰€æœ‰æ•°æ®æºå‡å¤±è´¥")

            # 5. æ ¼å¼åŒ–æ•°æ®
            formatted_data = {
                'code': code,
                'name': quote_data.get('name', f'ç¾è‚¡{code}'),
                'market': 'US',
                'price': quote_data.get('price'),
                'open': quote_data.get('open'),
                'high': quote_data.get('high'),
                'low': quote_data.get('low'),
                'volume': quote_data.get('volume'),
                'change_percent': quote_data.get('change_percent'),
                'trade_date': quote_data.get('trade_date'),
                'currency': quote_data.get('currency', 'USD'),
                'source': data_source,
                'updated_at': datetime.now().isoformat()
            }

            # 6. ä¿å­˜åˆ°ç¼“å­˜
            self.cache.save_stock_data(
                symbol=code,
                data=json.dumps(formatted_data, ensure_ascii=False),
                data_source="us_realtime_quote"
            )
            logger.info(f"ğŸ’¾ ç¾è‚¡è¡Œæƒ…å·²ç¼“å­˜: {code}")

            return formatted_data

    def _get_us_quote_from_yfinance(self, code: str) -> Dict:
        """ä»yfinanceè·å–ç¾è‚¡è¡Œæƒ…"""
        import yfinance as yf

        ticker = yf.Ticker(code)
        hist = ticker.history(period='1d')

        if hist.empty:
            raise Exception("æ— æ•°æ®")

        latest = hist.iloc[-1]
        info = ticker.info

        return {
            'name': info.get('longName') or info.get('shortName'),
            'price': float(latest['Close']),
            'open': float(latest['Open']),
            'high': float(latest['High']),
            'low': float(latest['Low']),
            'volume': int(latest['Volume']),
            'change_percent': round(((latest['Close'] - latest['Open']) / latest['Open'] * 100), 2),
            'trade_date': hist.index[-1].strftime('%Y-%m-%d'),
            'currency': info.get('currency', 'USD')
        }

    def _get_us_quote_from_alpha_vantage(self, code: str) -> Dict:
        """ä»Alpha Vantageè·å–ç¾è‚¡è¡Œæƒ…"""
        try:
            from tradingagents.dataflows.providers.us.alpha_vantage_common import get_api_key, _make_api_request

            # è·å– API Key
            api_key = get_api_key()
            if not api_key:
                raise Exception("Alpha Vantage API Key æœªé…ç½®")

            # è°ƒç”¨ GLOBAL_QUOTE API
            params = {
                "symbol": code.upper(),
            }

            data = _make_api_request("GLOBAL_QUOTE", params)

            if not data or "Global Quote" not in data:
                raise Exception("Alpha Vantage è¿”å›æ•°æ®ä¸ºç©º")

            quote = data["Global Quote"]

            if not quote:
                raise Exception("æ— æ•°æ®")

            # è§£ææ•°æ®
            return {
                'symbol': quote.get('01. symbol', code),
                'price': float(quote.get('05. price', 0)),
                'open': float(quote.get('02. open', 0)),
                'high': float(quote.get('03. high', 0)),
                'low': float(quote.get('04. low', 0)),
                'volume': int(quote.get('06. volume', 0)),
                'latest_trading_day': quote.get('07. latest trading day', ''),
                'previous_close': float(quote.get('08. previous close', 0)),
                'change': float(quote.get('09. change', 0)),
                'change_percent': quote.get('10. change percent', '0%').rstrip('%'),
            }

        except Exception as e:
            logger.error(f"âŒ Alpha Vantageè·å–ç¾è‚¡è¡Œæƒ…å¤±è´¥: {e}")
            raise

    def _get_us_quote_from_finnhub(self, code: str) -> Dict:
        """ä»Finnhubè·å–ç¾è‚¡è¡Œæƒ…"""
        try:
            import finnhub
            import os

            # è·å– API Key
            api_key = os.getenv('FINNHUB_API_KEY')
            if not api_key:
                raise Exception("Finnhub API Key æœªé…ç½®")

            # åˆ›å»ºå®¢æˆ·ç«¯
            client = finnhub.Client(api_key=api_key)

            # è·å–å®æ—¶æŠ¥ä»·
            quote = client.quote(code.upper())

            if not quote or 'c' not in quote:
                raise Exception("æ— æ•°æ®")

            # è§£ææ•°æ®
            return {
                'symbol': code.upper(),
                'price': quote.get('c', 0),  # current price
                'open': quote.get('o', 0),   # open price
                'high': quote.get('h', 0),   # high price
                'low': quote.get('l', 0),    # low price
                'previous_close': quote.get('pc', 0),  # previous close
                'change': quote.get('d', 0),  # change
                'change_percent': quote.get('dp', 0),  # change percent
                'timestamp': quote.get('t', 0),  # timestamp
            }

        except Exception as e:
            logger.error(f"âŒ Finnhubè·å–ç¾è‚¡è¡Œæƒ…å¤±è´¥: {e}")
            raise
    
    async def _get_hk_info(self, code: str, force_refresh: bool = False) -> Dict:
        """
        è·å–æ¸¯è‚¡åŸºç¡€ä¿¡æ¯
        ğŸ”¥ æŒ‰ç…§æ•°æ®åº“é…ç½®çš„æ•°æ®æºä¼˜å…ˆçº§è°ƒç”¨API
        """
        # 1. æ£€æŸ¥ç¼“å­˜ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
        if not force_refresh:
            cache_key = self.cache.find_cached_stock_data(
                symbol=code,
                data_source="hk_basic_info"
            )

            if cache_key:
                cached_data = self.cache.load_stock_data(cache_key)
                if cached_data:
                    logger.info(f"âš¡ ä»ç¼“å­˜è·å–æ¸¯è‚¡åŸºç¡€ä¿¡æ¯: {code}")
                    return self._parse_cached_data(cached_data, 'HK', code)

        # 2. ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§
        source_priority = await self._get_source_priority('HK')

        # 3. æŒ‰ä¼˜å…ˆçº§å°è¯•å„ä¸ªæ•°æ®æº
        info_data = None
        data_source = None

        # æ•°æ®æºåç§°æ˜ å°„
        source_handlers = {
            'akshare': ('akshare', self._get_hk_info_from_akshare),
            'yahoo_finance': ('yfinance', self._get_hk_info_from_yfinance),
            'finnhub': ('finnhub', self._get_hk_info_from_finnhub),
        }

        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®æºå¹¶å»é‡
        valid_priority = []
        seen = set()
        for source_name in source_priority:
            source_key = source_name.lower()
            if source_key in source_handlers and source_key not in seen:
                seen.add(source_key)
                valid_priority.append(source_name)

        if not valid_priority:
            logger.warning("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®æœ‰æ•ˆçš„æ¸¯è‚¡åŸºç¡€ä¿¡æ¯æ•°æ®æºï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
            valid_priority = ['akshare', 'yahoo_finance', 'finnhub']

        logger.info(f"ğŸ“Š [HKåŸºç¡€ä¿¡æ¯æœ‰æ•ˆæ•°æ®æº] {valid_priority}")

        for source_name in valid_priority:
            source_key = source_name.lower()
            handler_name, handler_func = source_handlers[source_key]
            try:
                # ğŸ”¥ ä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                import asyncio
                info_data = await asyncio.to_thread(handler_func, code)
                data_source = handler_name

                if info_data:
                    logger.info(f"âœ… {data_source}è·å–æ¸¯è‚¡åŸºç¡€ä¿¡æ¯æˆåŠŸ: {code}")
                    break
            except Exception as e:
                logger.warning(f"âš ï¸ {source_name}è·å–åŸºç¡€ä¿¡æ¯å¤±è´¥: {e}")
                continue

        if not info_data:
            raise Exception(f"æ— æ³•è·å–æ¸¯è‚¡{code}çš„åŸºç¡€ä¿¡æ¯ï¼šæ‰€æœ‰æ•°æ®æºå‡å¤±è´¥")

        # 4. æ ¼å¼åŒ–æ•°æ®
        formatted_data = self._format_hk_info(info_data, code, data_source)

        # 5. ä¿å­˜åˆ°ç¼“å­˜
        self.cache.save_stock_data(
            symbol=code,
            data=json.dumps(formatted_data, ensure_ascii=False),
            data_source="hk_basic_info"
        )
        logger.info(f"ğŸ’¾ æ¸¯è‚¡åŸºç¡€ä¿¡æ¯å·²ç¼“å­˜: {code}")

        return formatted_data

    async def _get_us_info(self, code: str, force_refresh: bool = False) -> Dict:
        """
        è·å–ç¾è‚¡åŸºç¡€ä¿¡æ¯
        ğŸ”¥ æŒ‰ç…§æ•°æ®åº“é…ç½®çš„æ•°æ®æºä¼˜å…ˆçº§è°ƒç”¨API
        """
        # 1. æ£€æŸ¥ç¼“å­˜ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
        if not force_refresh:
            cache_key = self.cache.find_cached_stock_data(
                symbol=code,
                data_source="us_basic_info"
            )

            if cache_key:
                cached_data = self.cache.load_stock_data(cache_key)
                if cached_data:
                    logger.info(f"âš¡ ä»ç¼“å­˜è·å–ç¾è‚¡åŸºç¡€ä¿¡æ¯: {code}")
                    return self._parse_cached_data(cached_data, 'US', code)

        # 2. ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§
        source_priority = await self._get_source_priority('US')

        # 3. æŒ‰ä¼˜å…ˆçº§å°è¯•å„ä¸ªæ•°æ®æº
        info_data = None
        data_source = None

        # æ•°æ®æºåç§°æ˜ å°„
        source_handlers = {
            'alpha_vantage': ('alpha_vantage', self._get_us_info_from_alpha_vantage),
            'yahoo_finance': ('yfinance', self._get_us_info_from_yfinance),
            'finnhub': ('finnhub', self._get_us_info_from_finnhub),
        }

        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®æºå¹¶å»é‡
        valid_priority = []
        seen = set()
        for source_name in source_priority:
            source_key = source_name.lower()
            if source_key in source_handlers and source_key not in seen:
                seen.add(source_key)
                valid_priority.append(source_name)

        if not valid_priority:
            logger.warning("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®æœ‰æ•ˆçš„ç¾è‚¡æ•°æ®æºï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
            valid_priority = ['yahoo_finance', 'alpha_vantage', 'finnhub']

        logger.info(f"ğŸ“Š [USåŸºç¡€ä¿¡æ¯æœ‰æ•ˆæ•°æ®æº] {valid_priority}")

        for source_name in valid_priority:
            source_key = source_name.lower()
            handler_name, handler_func = source_handlers[source_key]
            try:
                # ğŸ”¥ ä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                import asyncio
                info_data = await asyncio.to_thread(handler_func, code)
                data_source = handler_name

                if info_data:
                    logger.info(f"âœ… {data_source}è·å–ç¾è‚¡åŸºç¡€ä¿¡æ¯æˆåŠŸ: {code}")
                    break
            except Exception as e:
                logger.warning(f"âš ï¸ {source_name}è·å–åŸºç¡€ä¿¡æ¯å¤±è´¥: {e}")
                continue

        if not info_data:
            raise Exception(f"æ— æ³•è·å–ç¾è‚¡{code}çš„åŸºç¡€ä¿¡æ¯ï¼šæ‰€æœ‰æ•°æ®æºå‡å¤±è´¥")

        # 4. æ ¼å¼åŒ–æ•°æ®ï¼ˆåŒ¹é…å‰ç«¯æœŸæœ›çš„å­—æ®µåï¼‰
        market_cap = info_data.get('market_cap')
        formatted_data = {
            'code': code,
            'name': info_data.get('name') or f'ç¾è‚¡{code}',
            'market': 'US',
            'industry': info_data.get('industry'),
            'sector': info_data.get('sector'),
            # å‰ç«¯æœŸæœ› total_mvï¼ˆå•ä½ï¼šäº¿å…ƒï¼‰
            'total_mv': market_cap / 1e8 if market_cap else None,
            # å‰ç«¯æœŸæœ› pe_ttm æˆ– pe
            'pe_ttm': info_data.get('pe_ratio'),
            'pe': info_data.get('pe_ratio'),
            # å‰ç«¯æœŸæœ› pb
            'pb': info_data.get('pb_ratio'),
            # å‰ç«¯æœŸæœ› psï¼ˆæš‚æ— æ•°æ®ï¼‰
            'ps': None,
            'ps_ttm': None,
            # å‰ç«¯æœŸæœ› roe å’Œ debt_ratioï¼ˆæš‚æ— æ•°æ®ï¼‰
            'roe': None,
            'debt_ratio': None,
            'dividend_yield': info_data.get('dividend_yield'),
            'currency': info_data.get('currency', 'USD'),
            'source': data_source,
            'updated_at': datetime.now().isoformat()
        }

        # 5. ä¿å­˜åˆ°ç¼“å­˜
        self.cache.save_stock_data(
            symbol=code,
            data=json.dumps(formatted_data, ensure_ascii=False),
            data_source="us_basic_info"
        )
        logger.info(f"ğŸ’¾ ç¾è‚¡åŸºç¡€ä¿¡æ¯å·²ç¼“å­˜: {code}")

        return formatted_data

    async def _get_hk_kline(self, code: str, period: str, limit: int, force_refresh: bool = False) -> List[Dict]:
        """
        è·å–æ¸¯è‚¡Kçº¿æ•°æ®
        ğŸ”¥ æŒ‰ç…§æ•°æ®åº“é…ç½®çš„æ•°æ®æºä¼˜å…ˆçº§è°ƒç”¨API
        """
        # 1. æ£€æŸ¥ç¼“å­˜ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
        cache_key_str = f"hk_kline_{period}_{limit}"
        if not force_refresh:
            cache_key = self.cache.find_cached_stock_data(
                symbol=code,
                data_source=cache_key_str
            )

            if cache_key:
                cached_data = self.cache.load_stock_data(cache_key)
                if cached_data:
                    logger.info(f"âš¡ ä»ç¼“å­˜è·å–æ¸¯è‚¡Kçº¿: {code}")
                    return self._parse_cached_kline(cached_data)

        # 2. ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§
        source_priority = await self._get_source_priority('HK')

        # 3. æŒ‰ä¼˜å…ˆçº§å°è¯•å„ä¸ªæ•°æ®æº
        kline_data = None
        data_source = None

        # æ•°æ®æºåç§°æ˜ å°„
        source_handlers = {
            'akshare': ('akshare', self._get_hk_kline_from_akshare),
            'yahoo_finance': ('yfinance', self._get_hk_kline_from_yfinance),
            'finnhub': ('finnhub', self._get_hk_kline_from_finnhub),
        }

        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®æºå¹¶å»é‡
        valid_priority = []
        seen = set()
        for source_name in source_priority:
            source_key = source_name.lower()
            if source_key in source_handlers and source_key not in seen:
                seen.add(source_key)
                valid_priority.append(source_name)

        if not valid_priority:
            logger.warning("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®æœ‰æ•ˆçš„æ¸¯è‚¡Kçº¿æ•°æ®æºï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
            valid_priority = ['akshare', 'yahoo_finance', 'finnhub']

        logger.info(f"ğŸ“Š [HK Kçº¿æœ‰æ•ˆæ•°æ®æº] {valid_priority}")

        for source_name in valid_priority:
            source_key = source_name.lower()
            handler_name, handler_func = source_handlers[source_key]
            try:
                # ğŸ”¥ ä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                import asyncio
                kline_data = await asyncio.to_thread(handler_func, code, period, limit)
                data_source = handler_name

                if kline_data:
                    logger.info(f"âœ… {data_source}è·å–æ¸¯è‚¡Kçº¿æˆåŠŸ: {code}")
                    break
            except Exception as e:
                logger.warning(f"âš ï¸ {source_name}è·å–Kçº¿å¤±è´¥: {e}")
                continue

        if not kline_data:
            raise Exception(f"æ— æ³•è·å–æ¸¯è‚¡{code}çš„Kçº¿æ•°æ®ï¼šæ‰€æœ‰æ•°æ®æºå‡å¤±è´¥")

        # 4. ä¿å­˜åˆ°ç¼“å­˜
        self.cache.save_stock_data(
            symbol=code,
            data=json.dumps(kline_data, ensure_ascii=False),
            data_source=cache_key_str
        )
        logger.info(f"ğŸ’¾ æ¸¯è‚¡Kçº¿å·²ç¼“å­˜: {code}")

        return kline_data

    async def _get_us_kline(self, code: str, period: str, limit: int, force_refresh: bool = False) -> List[Dict]:
        """
        è·å–ç¾è‚¡Kçº¿æ•°æ®
        ğŸ”¥ æŒ‰ç…§æ•°æ®åº“é…ç½®çš„æ•°æ®æºä¼˜å…ˆçº§è°ƒç”¨API
        """
        # 1. æ£€æŸ¥ç¼“å­˜ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
        cache_key_str = f"us_kline_{period}_{limit}"
        if not force_refresh:
            cache_key = self.cache.find_cached_stock_data(
                symbol=code,
                data_source=cache_key_str
            )

            if cache_key:
                cached_data = self.cache.load_stock_data(cache_key)
                if cached_data:
                    logger.info(f"âš¡ ä»ç¼“å­˜è·å–ç¾è‚¡Kçº¿: {code}")
                    return self._parse_cached_kline(cached_data)

        # 2. ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§
        source_priority = await self._get_source_priority('US')

        # 3. æŒ‰ä¼˜å…ˆçº§å°è¯•å„ä¸ªæ•°æ®æº
        kline_data = None
        data_source = None

        # æ•°æ®æºåç§°æ˜ å°„
        source_handlers = {
            'alpha_vantage': ('alpha_vantage', self._get_us_kline_from_alpha_vantage),
            'yahoo_finance': ('yfinance', self._get_us_kline_from_yfinance),
            'finnhub': ('finnhub', self._get_us_kline_from_finnhub),
        }

        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®æºå¹¶å»é‡
        valid_priority = []
        seen = set()
        for source_name in source_priority:
            source_key = source_name.lower()
            if source_key in source_handlers and source_key not in seen:
                seen.add(source_key)
                valid_priority.append(source_name)

        if not valid_priority:
            logger.warning("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®æœ‰æ•ˆçš„ç¾è‚¡æ•°æ®æºï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
            valid_priority = ['yahoo_finance', 'alpha_vantage', 'finnhub']

        logger.info(f"ğŸ“Š [US Kçº¿æœ‰æ•ˆæ•°æ®æº] {valid_priority}")

        for source_name in valid_priority:
            source_key = source_name.lower()
            handler_name, handler_func = source_handlers[source_key]
            try:
                # ğŸ”¥ ä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                import asyncio
                kline_data = await asyncio.to_thread(handler_func, code, period, limit)
                data_source = handler_name

                if kline_data:
                    logger.info(f"âœ… {data_source}è·å–ç¾è‚¡Kçº¿æˆåŠŸ: {code}")
                    break
            except Exception as e:
                logger.warning(f"âš ï¸ {source_name}è·å–Kçº¿å¤±è´¥: {e}")
                continue

        if not kline_data:
            raise Exception(f"æ— æ³•è·å–ç¾è‚¡{code}çš„Kçº¿æ•°æ®ï¼šæ‰€æœ‰æ•°æ®æºå‡å¤±è´¥")

        # 4. ä¿å­˜åˆ°ç¼“å­˜
        self.cache.save_stock_data(
            symbol=code,
            data=json.dumps(kline_data, ensure_ascii=False),
            data_source=cache_key_str
        )
        logger.info(f"ğŸ’¾ ç¾è‚¡Kçº¿å·²ç¼“å­˜: {code}")

        return kline_data
    
    def _format_hk_quote(self, data: Dict, code: str, source: str) -> Dict:
        """æ ¼å¼åŒ–æ¸¯è‚¡è¡Œæƒ…æ•°æ®"""
        return {
            'code': code,
            'name': data.get('name', f'æ¸¯è‚¡{code}'),
            'market': 'HK',
            'price': data.get('price') or data.get('close'),
            'open': data.get('open'),
            'high': data.get('high'),
            'low': data.get('low'),
            'volume': data.get('volume'),
            'currency': data.get('currency', 'HKD'),
            'source': source,
            'trade_date': data.get('timestamp', datetime.now().strftime('%Y-%m-%d')),
            'updated_at': datetime.now().isoformat()
        }

    def _format_hk_info(self, data: Dict, code: str, source: str) -> Dict:
        """æ ¼å¼åŒ–æ¸¯è‚¡åŸºç¡€ä¿¡æ¯"""
        market_cap = data.get('market_cap')
        return {
            'code': code,
            'name': data.get('name', f'æ¸¯è‚¡{code}'),
            'market': 'HK',
            'industry': data.get('industry'),
            'sector': data.get('sector'),
            # å‰ç«¯æœŸæœ› total_mvï¼ˆå•ä½ï¼šäº¿å…ƒï¼‰
            'total_mv': market_cap / 1e8 if market_cap else None,
            # å‰ç«¯æœŸæœ› pe_ttm æˆ– pe
            'pe_ttm': data.get('pe_ratio'),
            'pe': data.get('pe_ratio'),
            # å‰ç«¯æœŸæœ› pb
            'pb': data.get('pb_ratio'),
            # å‰ç«¯æœŸæœ› ps
            'ps': data.get('ps_ratio'),
            'ps_ttm': data.get('ps_ratio'),
            # ğŸ”¥ ä»è´¢åŠ¡æŒ‡æ ‡ä¸­è·å– roe å’Œ debt_ratio
            'roe': data.get('roe'),
            'debt_ratio': data.get('debt_ratio'),
            'dividend_yield': data.get('dividend_yield'),
            'currency': data.get('currency', 'HKD'),
            'source': source,
            'updated_at': datetime.now().isoformat()
        }

    def _parse_cached_data(self, cached_data: str, market: str, code: str) -> Dict:
        """è§£æç¼“å­˜çš„æ•°æ®"""
        try:
            # å°è¯•è§£æJSON
            if isinstance(cached_data, str):
                data = json.loads(cached_data)
            else:
                data = cached_data

            # ç¡®ä¿åŒ…å«å¿…è¦å­—æ®µ
            if isinstance(data, dict):
                data['market'] = market
                data['code'] = code
                return data
            else:
                raise ValueError("ç¼“å­˜æ•°æ®æ ¼å¼é”™è¯¯")
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æç¼“å­˜æ•°æ®å¤±è´¥: {e}")
            # è¿”å›ç©ºæ•°æ®ï¼Œè§¦å‘é‡æ–°è·å–
            return None

    def _parse_cached_kline(self, cached_data: str) -> List[Dict]:
        """è§£æç¼“å­˜çš„Kçº¿æ•°æ®"""
        try:
            # å°è¯•è§£æJSON
            if isinstance(cached_data, str):
                data = json.loads(cached_data)
            else:
                data = cached_data

            # ç¡®ä¿æ˜¯åˆ—è¡¨
            if isinstance(data, list):
                return data
            else:
                raise ValueError("ç¼“å­˜Kçº¿æ•°æ®æ ¼å¼é”™è¯¯")
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æç¼“å­˜Kçº¿æ•°æ®å¤±è´¥: {e}")
            # è¿”å›ç©ºåˆ—è¡¨ï¼Œè§¦å‘é‡æ–°è·å–
            return []

    def _get_us_info_from_yfinance(self, code: str) -> Dict:
        """ä»yfinanceè·å–ç¾è‚¡åŸºç¡€ä¿¡æ¯"""
        import yfinance as yf

        ticker = yf.Ticker(code)
        info = ticker.info

        if not info:
            raise Exception("æ— æ•°æ®")

        return {
            'name': info.get('longName') or info.get('shortName'),
            'industry': info.get('industry'),
            'sector': info.get('sector'),
            'market_cap': info.get('marketCap'),
            'pe_ratio': info.get('trailingPE'),
            'pb_ratio': info.get('priceToBook'),
            'dividend_yield': info.get('dividendYield'),
            'currency': info.get('currency', 'USD'),
        }

    def _safe_float(self, value, default=None):
        """å®‰å…¨åœ°è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼Œå¤„ç† 'None' å­—ç¬¦ä¸²å’Œç©ºå€¼"""
        if value is None or value == '' or value == 'None' or value == 'N/A':
            return default
        try:
            return float(value)
        except (ValueError, TypeError):
            return default

    def _get_us_info_from_alpha_vantage(self, code: str) -> Dict:
        """ä»Alpha Vantageè·å–ç¾è‚¡åŸºç¡€ä¿¡æ¯"""
        from tradingagents.dataflows.providers.us.alpha_vantage_common import get_api_key, _make_api_request

        # è·å– API Key
        api_key = get_api_key()
        if not api_key:
            raise Exception("Alpha Vantage API Key æœªé…ç½®")

        # è°ƒç”¨ OVERVIEW API
        params = {"symbol": code.upper()}
        data = _make_api_request("OVERVIEW", params)

        if not data or not data.get('Symbol'):
            raise Exception("æ— æ•°æ®")

        return {
            'name': data.get('Name'),
            'industry': data.get('Industry'),
            'sector': data.get('Sector'),
            'market_cap': self._safe_float(data.get('MarketCapitalization')),
            'pe_ratio': self._safe_float(data.get('TrailingPE')),
            'pb_ratio': self._safe_float(data.get('PriceToBookRatio')),
            'dividend_yield': self._safe_float(data.get('DividendYield')),
            'currency': 'USD',
        }

    def _get_us_info_from_finnhub(self, code: str) -> Dict:
        """ä»Finnhubè·å–ç¾è‚¡åŸºç¡€ä¿¡æ¯"""
        import finnhub
        import os

        # è·å– API Key
        api_key = os.getenv('FINNHUB_API_KEY')
        if not api_key:
            raise Exception("Finnhub API Key æœªé…ç½®")

        # åˆ›å»ºå®¢æˆ·ç«¯
        client = finnhub.Client(api_key=api_key)

        # è·å–å…¬å¸ä¿¡æ¯
        profile = client.company_profile2(symbol=code.upper())

        if not profile:
            raise Exception("æ— æ•°æ®")

        return {
            'name': profile.get('name'),
            'industry': profile.get('finnhubIndustry'),
            'sector': None,  # Finnhub ä¸æä¾› sector
            'market_cap': profile.get('marketCapitalization') * 1000000 if profile.get('marketCapitalization') else None,  # è½¬æ¢ä¸ºç¾å…ƒ
            'pe_ratio': None,  # Finnhub profile ä¸ç›´æ¥æä¾› PE
            'pb_ratio': None,  # Finnhub profile ä¸ç›´æ¥æä¾› PB
            'dividend_yield': None,  # Finnhub profile ä¸ç›´æ¥æä¾›è‚¡æ¯ç‡
            'currency': profile.get('currency', 'USD'),
        }

    def _get_us_kline_from_yfinance(self, code: str, period: str, limit: int) -> List[Dict]:
        """ä»yfinanceè·å–ç¾è‚¡Kçº¿æ•°æ®"""
        import yfinance as yf

        ticker = yf.Ticker(code)

        # å‘¨æœŸæ˜ å°„
        period_map = {
            'day': '1d',
            'week': '1wk',
            'month': '1mo',
            '5m': '5m',
            '15m': '15m',
            '30m': '30m',
            '60m': '60m'
        }

        interval = period_map.get(period, '1d')
        hist = ticker.history(period=f'{limit}d', interval=interval)

        if hist.empty:
            raise Exception("æ— æ•°æ®")

        # æ ¼å¼åŒ–æ•°æ®
        kline_data = []
        for date, row in hist.iterrows():
            date_str = date.strftime('%Y-%m-%d')
            kline_data.append({
                'date': date_str,
                'trade_date': date_str,  # å‰ç«¯éœ€è¦è¿™ä¸ªå­—æ®µ
                'open': float(row['Open']),
                'high': float(row['High']),
                'low': float(row['Low']),
                'close': float(row['Close']),
                'volume': int(row['Volume'])
            })

        return kline_data

    def _get_us_kline_from_alpha_vantage(self, code: str, period: str, limit: int) -> List[Dict]:
        """ä»Alpha Vantageè·å–ç¾è‚¡Kçº¿æ•°æ®"""
        from tradingagents.dataflows.providers.us.alpha_vantage_common import get_api_key, _make_api_request
        import pandas as pd

        # è·å– API Key
        api_key = get_api_key()
        if not api_key:
            raise Exception("Alpha Vantage API Key æœªé…ç½®")

        # æ ¹æ®å‘¨æœŸé€‰æ‹©APIå‡½æ•°
        if period in ['5m', '15m', '30m', '60m']:
            function = "TIME_SERIES_INTRADAY"
            params = {
                "symbol": code.upper(),
                "interval": period,
                "outputsize": "full"
            }
            time_series_key = f"Time Series ({period})"
        else:
            function = "TIME_SERIES_DAILY"
            params = {
                "symbol": code.upper(),
                "outputsize": "full"
            }
            time_series_key = "Time Series (Daily)"

        data = _make_api_request(function, params)

        if not data or time_series_key not in data:
            raise Exception("æ— æ•°æ®")

        time_series = data[time_series_key]

        # è½¬æ¢ä¸º DataFrame
        df = pd.DataFrame.from_dict(time_series, orient='index')
        df.index = pd.to_datetime(df.index)
        df = df.sort_index(ascending=False)  # æœ€æ–°çš„åœ¨å‰

        # é™åˆ¶æ•°é‡
        df = df.head(limit)

        # æ ¼å¼åŒ–æ•°æ®
        kline_data = []
        for date, row in df.iterrows():
            date_str = date.strftime('%Y-%m-%d')
            kline_data.append({
                'date': date_str,
                'trade_date': date_str,  # å‰ç«¯éœ€è¦è¿™ä¸ªå­—æ®µ
                'open': float(row['1. open']),
                'high': float(row['2. high']),
                'low': float(row['3. low']),
                'close': float(row['4. close']),
                'volume': int(row['5. volume'])
            })

        return kline_data

    def _get_us_kline_from_finnhub(self, code: str, period: str, limit: int) -> List[Dict]:
        """ä»Finnhubè·å–ç¾è‚¡Kçº¿æ•°æ®"""
        import finnhub
        import os
        from datetime import datetime, timedelta

        # è·å– API Key
        api_key = os.getenv('FINNHUB_API_KEY')
        if not api_key:
            raise Exception("Finnhub API Key æœªé…ç½®")

        # åˆ›å»ºå®¢æˆ·ç«¯
        client = finnhub.Client(api_key=api_key)

        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now()

        # æ ¹æ®å‘¨æœŸè®¡ç®—å¼€å§‹æ—¥æœŸ
        if period == 'day':
            start_date = end_date - timedelta(days=limit)
            resolution = 'D'
        elif period == 'week':
            start_date = end_date - timedelta(weeks=limit)
            resolution = 'W'
        elif period == 'month':
            start_date = end_date - timedelta(days=limit * 30)
            resolution = 'M'
        elif period == '5m':
            start_date = end_date - timedelta(days=limit)
            resolution = '5'
        elif period == '15m':
            start_date = end_date - timedelta(days=limit)
            resolution = '15'
        elif period == '30m':
            start_date = end_date - timedelta(days=limit)
            resolution = '30'
        elif period == '60m':
            start_date = end_date - timedelta(days=limit)
            resolution = '60'
        else:
            start_date = end_date - timedelta(days=limit)
            resolution = 'D'

        # è·å–Kçº¿æ•°æ®
        candles = client.stock_candles(
            code.upper(),
            resolution,
            int(start_date.timestamp()),
            int(end_date.timestamp())
        )

        if not candles or candles.get('s') != 'ok':
            raise Exception("æ— æ•°æ®")

        # æ ¼å¼åŒ–æ•°æ®
        kline_data = []
        for i in range(len(candles['t'])):
            date_str = datetime.fromtimestamp(candles['t'][i]).strftime('%Y-%m-%d')
            kline_data.append({
                'date': date_str,
                'trade_date': date_str,  # å‰ç«¯éœ€è¦è¿™ä¸ªå­—æ®µ
                'open': float(candles['o'][i]),
                'high': float(candles['h'][i]),
                'low': float(candles['l'][i]),
                'close': float(candles['c'][i]),
                'volume': int(candles['v'][i])
            })

        return kline_data

    async def get_hk_news(self, code: str, days: int = 2, limit: int = 50) -> Dict:
        """
        è·å–æ¸¯è‚¡æ–°é—»

        Args:
            code: è‚¡ç¥¨ä»£ç 
            days: å›æº¯å¤©æ•°
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            åŒ…å«æ–°é—»åˆ—è¡¨å’Œæ•°æ®æºçš„å­—å…¸
        """
        from datetime import datetime, timedelta

        logger.info(f"ğŸ“° å¼€å§‹è·å–æ¸¯è‚¡æ–°é—»: {code}, days={days}, limit={limit}")

        # 1. å°è¯•ä»ç¼“å­˜è·å–
        cache_key_str = f"hk_news_{days}_{limit}"
        cache_key = self.cache.find_cached_stock_data(
            symbol=code,
            data_source=cache_key_str
        )

        if cache_key:
            cached_data = self.cache.load_stock_data(cache_key)
            if cached_data:
                logger.info(f"âš¡ ä»ç¼“å­˜è·å–æ¸¯è‚¡æ–°é—»: {code}")
                return json.loads(cached_data)

        # 2. ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§
        source_priority = await self._get_source_priority('HK')

        # 3. æŒ‰ä¼˜å…ˆçº§å°è¯•å„ä¸ªæ•°æ®æº
        news_data = None
        data_source = None

        # æ•°æ®æºåç§°æ˜ å°„
        source_handlers = {
            'akshare': ('akshare', self._get_hk_news_from_akshare),
            'finnhub': ('finnhub', self._get_hk_news_from_finnhub),
        }

        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®æºå¹¶å»é‡
        valid_priority = []
        seen = set()
        for source_name in source_priority:
            source_key = source_name.lower()
            if source_key in source_handlers and source_key not in seen:
                seen.add(source_key)
                valid_priority.append(source_name)

        if not valid_priority:
            logger.warning("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®æœ‰æ•ˆçš„æ¸¯è‚¡æ–°é—»æ•°æ®æºï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
            valid_priority = ['akshare', 'finnhub']

        logger.info(f"ğŸ“Š [HKæ–°é—»æœ‰æ•ˆæ•°æ®æº] {valid_priority}")

        for source_name in valid_priority:
            source_key = source_name.lower()
            handler_name, handler_func = source_handlers[source_key]
            try:
                # ğŸ”¥ ä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                import asyncio
                news_data = await asyncio.to_thread(handler_func, code, days, limit)
                data_source = handler_name

                if news_data:
                    logger.info(f"âœ… {data_source}è·å–æ¸¯è‚¡æ–°é—»æˆåŠŸ: {code}, è¿”å› {len(news_data)} æ¡")
                    break
            except Exception as e:
                logger.warning(f"âš ï¸ {source_name}è·å–æ–°é—»å¤±è´¥: {e}")
                continue

        if not news_data:
            logger.warning(f"âš ï¸ æ— æ³•è·å–æ¸¯è‚¡{code}çš„æ–°é—»æ•°æ®ï¼šæ‰€æœ‰æ•°æ®æºå‡å¤±è´¥")
            news_data = []
            data_source = 'none'

        # 4. æ„å»ºè¿”å›æ•°æ®
        result = {
            'code': code,
            'days': days,
            'limit': limit,
            'source': data_source,
            'items': news_data
        }

        # 5. ç¼“å­˜æ•°æ®
        self.cache.save_stock_data(
            symbol=code,
            data=json.dumps(result, ensure_ascii=False),
            data_source=cache_key_str
        )

        return result

    async def get_us_news(self, code: str, days: int = 2, limit: int = 50) -> Dict:
        """
        è·å–ç¾è‚¡æ–°é—»

        Args:
            code: è‚¡ç¥¨ä»£ç 
            days: å›æº¯å¤©æ•°
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            åŒ…å«æ–°é—»åˆ—è¡¨å’Œæ•°æ®æºçš„å­—å…¸
        """
        from datetime import datetime, timedelta

        logger.info(f"ğŸ“° å¼€å§‹è·å–ç¾è‚¡æ–°é—»: {code}, days={days}, limit={limit}")

        # 1. å°è¯•ä»ç¼“å­˜è·å–
        cache_key_str = f"us_news_{days}_{limit}"
        cache_key = self.cache.find_cached_stock_data(
            symbol=code,
            data_source=cache_key_str
        )

        if cache_key:
            cached_data = self.cache.load_stock_data(cache_key)
            if cached_data:
                logger.info(f"âš¡ ä»ç¼“å­˜è·å–ç¾è‚¡æ–°é—»: {code}")
                return json.loads(cached_data)

        # 2. ä»æ•°æ®åº“è·å–æ•°æ®æºä¼˜å…ˆçº§
        source_priority = await self._get_source_priority('US')

        # 3. æŒ‰ä¼˜å…ˆçº§å°è¯•å„ä¸ªæ•°æ®æº
        news_data = None
        data_source = None

        # æ•°æ®æºåç§°æ˜ å°„
        source_handlers = {
            'alpha_vantage': ('alpha_vantage', self._get_us_news_from_alpha_vantage),
            'finnhub': ('finnhub', self._get_us_news_from_finnhub),
        }

        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®æºå¹¶å»é‡
        valid_priority = []
        seen = set()
        for source_name in source_priority:
            source_key = source_name.lower()
            if source_key in source_handlers and source_key not in seen:
                seen.add(source_key)
                valid_priority.append(source_name)

        if not valid_priority:
            logger.warning("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®æœ‰æ•ˆçš„ç¾è‚¡æ–°é—»æ•°æ®æºï¼Œä½¿ç”¨é»˜è®¤é¡ºåº")
            valid_priority = ['alpha_vantage', 'finnhub']

        logger.info(f"ğŸ“Š [USæ–°é—»æœ‰æ•ˆæ•°æ®æº] {valid_priority}")

        for source_name in valid_priority:
            source_key = source_name.lower()
            handler_name, handler_func = source_handlers[source_key]
            try:
                # ğŸ”¥ ä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                import asyncio
                news_data = await asyncio.to_thread(handler_func, code, days, limit)
                data_source = handler_name

                if news_data:
                    logger.info(f"âœ… {data_source}è·å–ç¾è‚¡æ–°é—»æˆåŠŸ: {code}, è¿”å› {len(news_data)} æ¡")
                    break
            except Exception as e:
                logger.warning(f"âš ï¸ {source_name}è·å–æ–°é—»å¤±è´¥: {e}")
                continue

        if not news_data:
            logger.warning(f"âš ï¸ æ— æ³•è·å–ç¾è‚¡{code}çš„æ–°é—»æ•°æ®ï¼šæ‰€æœ‰æ•°æ®æºå‡å¤±è´¥")
            news_data = []
            data_source = 'none'

        # 4. æ„å»ºè¿”å›æ•°æ®
        result = {
            'code': code,
            'days': days,
            'limit': limit,
            'source': data_source,
            'items': news_data
        }

        # 5. ç¼“å­˜æ•°æ®
        self.cache.save_stock_data(
            symbol=code,
            data=json.dumps(result, ensure_ascii=False),
            data_source=cache_key_str
        )

        return result

    def _get_us_news_from_alpha_vantage(self, code: str, days: int, limit: int) -> List[Dict]:
        """ä»Alpha Vantageè·å–ç¾è‚¡æ–°é—»"""
        from tradingagents.dataflows.providers.us.alpha_vantage_common import get_api_key, _make_api_request
        from datetime import datetime, timedelta

        # è·å– API Key
        api_key = get_api_key()
        if not api_key:
            raise Exception("Alpha Vantage API Key æœªé…ç½®")

        # è®¡ç®—æ—¶é—´èŒƒå›´
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)

        # è°ƒç”¨ NEWS_SENTIMENT API
        params = {
            "tickers": code.upper(),
            "time_from": start_date.strftime('%Y%m%dT%H%M'),
            "time_to": end_date.strftime('%Y%m%dT%H%M'),
            "sort": "LATEST",
            "limit": str(limit),
        }

        data = _make_api_request("NEWS_SENTIMENT", params)

        if not data or 'feed' not in data:
            raise Exception("æ— æ•°æ®")

        # æ ¼å¼åŒ–æ–°é—»æ•°æ®
        news_list = []
        for article in data.get('feed', [])[:limit]:
            # è§£ææ—¶é—´
            time_published = article.get('time_published', '')
            try:
                # Alpha Vantage æ—¶é—´æ ¼å¼: 20240101T120000
                pub_time = datetime.strptime(time_published, '%Y%m%dT%H%M%S')
                pub_time_str = pub_time.strftime('%Y-%m-%d %H:%M:%S')
            except:
                pub_time_str = time_published

            # æå–ç›¸å…³è‚¡ç¥¨çš„æƒ…æ„Ÿåˆ†æ•°
            sentiment_score = None
            sentiment_label = article.get('overall_sentiment_label', 'Neutral')

            ticker_sentiment = article.get('ticker_sentiment', [])
            for ts in ticker_sentiment:
                if ts.get('ticker', '').upper() == code.upper():
                    sentiment_score = ts.get('ticker_sentiment_score')
                    sentiment_label = ts.get('ticker_sentiment_label', sentiment_label)
                    break

            news_list.append({
                'title': article.get('title', ''),
                'summary': article.get('summary', ''),
                'url': article.get('url', ''),
                'source': article.get('source', ''),
                'publish_time': pub_time_str,
                'sentiment': sentiment_label,
                'sentiment_score': sentiment_score,
            })

        return news_list

    def _get_us_news_from_finnhub(self, code: str, days: int, limit: int) -> List[Dict]:
        """ä»Finnhubè·å–ç¾è‚¡æ–°é—»"""
        import finnhub
        import os
        from datetime import datetime, timedelta

        # è·å– API Key
        api_key = os.getenv('FINNHUB_API_KEY')
        if not api_key:
            raise Exception("Finnhub API Key æœªé…ç½®")

        # åˆ›å»ºå®¢æˆ·ç«¯
        client = finnhub.Client(api_key=api_key)

        # è®¡ç®—æ—¶é—´èŒƒå›´
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)

        # è·å–å…¬å¸æ–°é—»
        news = client.company_news(
            code.upper(),
            _from=start_date.strftime('%Y-%m-%d'),
            to=end_date.strftime('%Y-%m-%d')
        )

        if not news:
            raise Exception("æ— æ•°æ®")

        # æ ¼å¼åŒ–æ–°é—»æ•°æ®
        news_list = []
        for article in news[:limit]:
            # è§£ææ—¶é—´æˆ³
            timestamp = article.get('datetime', 0)
            pub_time = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')

            news_list.append({
                'title': article.get('headline', ''),
                'summary': article.get('summary', ''),
                'url': article.get('url', ''),
                'source': article.get('source', ''),
                'publish_time': pub_time,
                'sentiment': None,  # Finnhub ä¸æä¾›æƒ…æ„Ÿåˆ†æ
                'sentiment_score': None,
            })

        return news_list

    def _get_hk_news_from_finnhub(self, code: str, days: int, limit: int) -> List[Dict]:
        """ä»Finnhubè·å–æ¸¯è‚¡æ–°é—»"""
        import finnhub
        import os
        from datetime import datetime, timedelta

        # è·å– API Key
        api_key = os.getenv('FINNHUB_API_KEY')
        if not api_key:
            raise Exception("Finnhub API Key æœªé…ç½®")

        # åˆ›å»ºå®¢æˆ·ç«¯
        client = finnhub.Client(api_key=api_key)

        # è®¡ç®—æ—¶é—´èŒƒå›´
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)

        # æ¸¯è‚¡ä»£ç éœ€è¦æ·»åŠ  .HK åç¼€
        hk_symbol = f"{code}.HK" if not code.endswith('.HK') else code

        # è·å–å…¬å¸æ–°é—»
        news = client.company_news(
            hk_symbol,
            _from=start_date.strftime('%Y-%m-%d'),
            to=end_date.strftime('%Y-%m-%d')
        )

        if not news:
            raise Exception("æ— æ•°æ®")

        # æ ¼å¼åŒ–æ–°é—»æ•°æ®
        news_list = []
        for article in news[:limit]:
            # è§£ææ—¶é—´æˆ³
            timestamp = article.get('datetime', 0)
            pub_time = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')

            news_list.append({
                'title': article.get('headline', ''),
                'summary': article.get('summary', ''),
                'url': article.get('url', ''),
                'source': article.get('source', ''),
                'publish_time': pub_time,
                'sentiment': None,  # Finnhub ä¸æä¾›æƒ…æ„Ÿåˆ†æ
                'sentiment_score': None,
            })

        return news_list

    def _get_hk_info_from_akshare(self, code: str) -> Dict:
        """ä»AKShareè·å–æ¸¯è‚¡åŸºç¡€ä¿¡æ¯å’Œè´¢åŠ¡æŒ‡æ ‡"""
        from tradingagents.dataflows.providers.hk.improved_hk import (
            get_hk_stock_info_akshare,
            get_hk_financial_indicators
        )

        # 1. è·å–åŸºç¡€ä¿¡æ¯ï¼ˆåŒ…å«å½“å‰ä»·æ ¼ï¼‰
        info = get_hk_stock_info_akshare(code)
        if not info or 'error' in info:
            raise Exception("æ— æ•°æ®")

        # 2. è·å–è´¢åŠ¡æŒ‡æ ‡ï¼ˆEPSã€BPSã€ROEã€è´Ÿå€ºç‡ç­‰ï¼‰
        financial_indicators = {}
        try:
            financial_indicators = get_hk_financial_indicators(code)
            logger.info(f"âœ… è·å–æ¸¯è‚¡{code}è´¢åŠ¡æŒ‡æ ‡æˆåŠŸ: {list(financial_indicators.keys())}")
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–æ¸¯è‚¡{code}è´¢åŠ¡æŒ‡æ ‡å¤±è´¥: {e}")

        # 3. è®¡ç®— PEã€PBã€PSï¼ˆå‚è€ƒåˆ†ææ¨¡å—çš„è®¡ç®—æ–¹å¼ï¼‰
        current_price = info.get('price')  # å½“å‰ä»·æ ¼
        pe_ratio = None
        pb_ratio = None
        ps_ratio = None

        if current_price and financial_indicators:
            # è®¡ç®— PE = å½“å‰ä»· / EPS_TTM
            eps_ttm = financial_indicators.get('eps_ttm')
            if eps_ttm and eps_ttm > 0:
                pe_ratio = current_price / eps_ttm
                logger.info(f"ğŸ“Š è®¡ç®— PE: {current_price} / {eps_ttm} = {pe_ratio:.2f}")

            # è®¡ç®— PB = å½“å‰ä»· / BPS
            bps = financial_indicators.get('bps')
            if bps and bps > 0:
                pb_ratio = current_price / bps
                logger.info(f"ğŸ“Š è®¡ç®— PB: {current_price} / {bps} = {pb_ratio:.2f}")

            # è®¡ç®— PS = å¸‚å€¼ / è¥ä¸šæ”¶å…¥ï¼ˆéœ€è¦å¸‚å€¼æ•°æ®ï¼Œæš‚æ—¶æ— æ³•è®¡ç®—ï¼‰
            # ps_ratio æš‚æ—¶ä¸º None

        # 4. åˆå¹¶æ•°æ®
        return {
            'name': info.get('name', f'æ¸¯è‚¡{code}'),
            'market_cap': None,  # AKShare åŸºç¡€ä¿¡æ¯ä¸åŒ…å«å¸‚å€¼
            'industry': None,
            'sector': None,
            # ğŸ”¥ è®¡ç®—å¾—åˆ°çš„ä¼°å€¼æŒ‡æ ‡
            'pe_ratio': pe_ratio,
            'pb_ratio': pb_ratio,
            'ps_ratio': ps_ratio,
            'dividend_yield': None,
            'currency': 'HKD',
            # ğŸ”¥ ä»è´¢åŠ¡æŒ‡æ ‡ä¸­è·å–
            'roe': financial_indicators.get('roe_avg'),  # å¹³å‡å‡€èµ„äº§æ”¶ç›Šç‡
            'debt_ratio': financial_indicators.get('debt_asset_ratio'),  # èµ„äº§è´Ÿå€ºç‡
        }

    def _get_hk_info_from_yfinance(self, code: str) -> Dict:
        """ä»Yahoo Financeè·å–æ¸¯è‚¡åŸºç¡€ä¿¡æ¯"""
        import yfinance as yf

        ticker = yf.Ticker(f"{code}.HK")
        info = ticker.info

        return {
            'name': info.get('longName') or info.get('shortName') or f'æ¸¯è‚¡{code}',
            'market_cap': info.get('marketCap'),
            'industry': info.get('industry'),
            'sector': info.get('sector'),
            'pe_ratio': info.get('trailingPE'),
            'pb_ratio': info.get('priceToBook'),
            'dividend_yield': info.get('dividendYield'),
            'currency': info.get('currency', 'HKD'),
        }

    def _get_hk_info_from_finnhub(self, code: str) -> Dict:
        """ä»Finnhubè·å–æ¸¯è‚¡åŸºç¡€ä¿¡æ¯"""
        import finnhub
        import os

        # è·å– API Key
        api_key = os.getenv('FINNHUB_API_KEY')
        if not api_key:
            raise Exception("Finnhub API Key æœªé…ç½®")

        # åˆ›å»ºå®¢æˆ·ç«¯
        client = finnhub.Client(api_key=api_key)

        # æ¸¯è‚¡ä»£ç éœ€è¦æ·»åŠ  .HK åç¼€
        hk_symbol = f"{code}.HK" if not code.endswith('.HK') else code

        # è·å–å…¬å¸åŸºæœ¬ä¿¡æ¯
        profile = client.company_profile2(symbol=hk_symbol)

        if not profile:
            raise Exception("æ— æ•°æ®")

        return {
            'name': profile.get('name', f'æ¸¯è‚¡{code}'),
            'market_cap': profile.get('marketCapitalization') * 1e6 if profile.get('marketCapitalization') else None,  # Finnhubè¿”å›çš„æ˜¯ç™¾ä¸‡å•ä½
            'industry': profile.get('finnhubIndustry'),
            'sector': None,
            'pe_ratio': None,
            'pb_ratio': None,
            'dividend_yield': None,
            'currency': profile.get('currency', 'HKD'),
        }

    def _get_hk_kline_from_akshare(self, code: str, period: str, limit: int) -> List[Dict]:
        """ä»AKShareè·å–æ¸¯è‚¡Kçº¿æ•°æ®"""
        import akshare as ak
        import pandas as pd
        from datetime import datetime, timedelta
        from tradingagents.dataflows.providers.hk.improved_hk import get_improved_hk_provider

        # æ ‡å‡†åŒ–ä»£ç 
        provider = get_improved_hk_provider()
        normalized_code = provider._normalize_hk_symbol(code)

        # ç›´æ¥ä½¿ç”¨ AKShare API
        df = ak.stock_hk_daily(symbol=normalized_code, adjust="qfq")

        if df is None or df.empty:
            raise Exception("æ— æ•°æ®")

        # è¿‡æ»¤æœ€è¿‘çš„æ•°æ®
        df = df.tail(limit)

        # æ ¼å¼åŒ–æ•°æ®
        kline_data = []
        for _, row in df.iterrows():
            # AKShare è¿”å›çš„åˆ—åï¼šdate, open, close, high, low, volume
            date_str = row['date'].strftime('%Y-%m-%d') if hasattr(row['date'], 'strftime') else str(row['date'])
            kline_data.append({
                'date': date_str,
                'trade_date': date_str,
                'open': float(row['open']),
                'high': float(row['high']),
                'low': float(row['low']),
                'close': float(row['close']),
                'volume': int(row['volume']) if 'volume' in row else 0
            })

        return kline_data

    def _get_hk_kline_from_yfinance(self, code: str, period: str, limit: int) -> List[Dict]:
        """ä»Yahoo Financeè·å–æ¸¯è‚¡Kçº¿æ•°æ®"""
        import yfinance as yf
        import pandas as pd

        ticker = yf.Ticker(f"{code}.HK")

        # å‘¨æœŸæ˜ å°„
        period_map = {
            'day': '1d',
            'week': '1wk',
            'month': '1mo',
            '5m': '5m',
            '15m': '15m',
            '30m': '30m',
            '60m': '60m'
        }

        interval = period_map.get(period, '1d')
        hist = ticker.history(period=f'{limit}d', interval=interval)

        if hist.empty:
            raise Exception("æ— æ•°æ®")

        # æ ¼å¼åŒ–æ•°æ®
        kline_data = []
        for date, row in hist.iterrows():
            date_str = date.strftime('%Y-%m-%d')
            kline_data.append({
                'date': date_str,
                'trade_date': date_str,
                'open': float(row['Open']),
                'high': float(row['High']),
                'low': float(row['Low']),
                'close': float(row['Close']),
                'volume': int(row['Volume'])
            })

        return kline_data[-limit:]  # è¿”å›æœ€ålimitæ¡

    def _get_hk_kline_from_finnhub(self, code: str, period: str, limit: int) -> List[Dict]:
        """ä»Finnhubè·å–æ¸¯è‚¡Kçº¿æ•°æ®"""
        import finnhub
        import os
        from datetime import datetime, timedelta

        # è·å– API Key
        api_key = os.getenv('FINNHUB_API_KEY')
        if not api_key:
            raise Exception("Finnhub API Key æœªé…ç½®")

        # åˆ›å»ºå®¢æˆ·ç«¯
        client = finnhub.Client(api_key=api_key)

        # æ¸¯è‚¡ä»£ç éœ€è¦æ·»åŠ  .HK åç¼€
        hk_symbol = f"{code}.HK" if not code.endswith('.HK') else code

        # å‘¨æœŸæ˜ å°„
        resolution_map = {
            'day': 'D',
            'week': 'W',
            'month': 'M',
            '5m': '5',
            '15m': '15',
            '30m': '30',
            '60m': '60'
        }

        resolution = resolution_map.get(period, 'D')

        # è®¡ç®—æ—¶é—´èŒƒå›´
        end_time = int(datetime.now().timestamp())
        start_time = int((datetime.now() - timedelta(days=limit * 2)).timestamp())

        # è·å–Kçº¿æ•°æ®
        candles = client.stock_candles(hk_symbol, resolution, start_time, end_time)

        if not candles or candles.get('s') != 'ok':
            raise Exception("æ— æ•°æ®")

        # æ ¼å¼åŒ–æ•°æ®
        kline_data = []
        for i in range(len(candles['t'])):
            date_str = datetime.fromtimestamp(candles['t'][i]).strftime('%Y-%m-%d')
            kline_data.append({
                'date': date_str,
                'trade_date': date_str,
                'open': float(candles['o'][i]),
                'high': float(candles['h'][i]),
                'low': float(candles['l'][i]),
                'close': float(candles['c'][i]),
                'volume': int(candles['v'][i])
            })

        return kline_data[-limit:]  # è¿”å›æœ€ålimitæ¡

    def _get_hk_news_from_akshare(self, code: str, days: int, limit: int) -> List[Dict]:
        """ä»AKShareè·å–æ¸¯è‚¡æ–°é—»"""
        try:
            import akshare as ak
            from datetime import datetime, timedelta

            # AKShare çš„æ¸¯è‚¡æ–°é—»æ¥å£
            # æ³¨æ„ï¼šAKShare å¯èƒ½æ²¡æœ‰ä¸“é—¨çš„æ¸¯è‚¡æ–°é—»æ¥å£ï¼Œè¿™é‡Œä½¿ç”¨é€šç”¨æ–°é—»æ¥å£
            # å¦‚æœæ²¡æœ‰åˆé€‚çš„æ¥å£ï¼ŒæŠ›å‡ºå¼‚å¸¸è®©ç³»ç»Ÿå°è¯•ä¸‹ä¸€ä¸ªæ•°æ®æº

            # å°è¯•è·å–æ¸¯è‚¡æ–°é—»ï¼ˆä½¿ç”¨ä¸œæ–¹è´¢å¯Œæ¸¯è‚¡æ–°é—»ï¼‰
            try:
                df = ak.stock_news_em(symbol=code)
                if df is None or df.empty:
                    raise Exception("æ— æ•°æ®")

                # æ ¼å¼åŒ–æ–°é—»æ•°æ®
                news_list = []
                for _, row in df.head(limit).iterrows():
                    pub_time = row['å‘å¸ƒæ—¶é—´'] if 'å‘å¸ƒæ—¶é—´' in row else datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    news_list.append({
                        'title': row['æ–°é—»æ ‡é¢˜'] if 'æ–°é—»æ ‡é¢˜' in row else '',
                        'summary': row['æ–°é—»å†…å®¹'] if 'æ–°é—»å†…å®¹' in row else '',
                        'url': row['æ–°é—»é“¾æ¥'] if 'æ–°é—»é“¾æ¥' in row else '',
                        'source': 'AKShare-ä¸œæ–¹è´¢å¯Œ',
                        'publish_time': pub_time,
                        'sentiment': None,
                        'sentiment_score': None,
                    })

                return news_list
            except Exception as e:
                logger.debug(f"AKShare ä¸œæ–¹è´¢å¯Œæ¥å£å¤±è´¥: {e}")
                raise Exception("AKShare æš‚ä¸æ”¯æŒæ¸¯è‚¡æ–°é—»")

        except Exception as e:
            logger.warning(f"âš ï¸ AKShareè·å–æ¸¯è‚¡æ–°é—»å¤±è´¥: {e}")
            raise

