"""
æ¨¡å‹èƒ½åŠ›ç®¡ç†æœåŠ¡

æä¾›æ¨¡å‹èƒ½åŠ›è¯„ä¼°ã€éªŒè¯å’Œæ¨èåŠŸèƒ½ã€‚
"""

from typing import Tuple, Dict, Optional, List, Any
from app.constants.model_capabilities import (
    ANALYSIS_DEPTH_REQUIREMENTS,
    DEFAULT_MODEL_CAPABILITIES,
    CAPABILITY_DESCRIPTIONS,
    ModelRole,
    ModelFeature
)
from app.core.unified_config import unified_config
import logging
import re

logger = logging.getLogger(__name__)


class ModelCapabilityService:
    """æ¨¡å‹èƒ½åŠ›ç®¡ç†æœåŠ¡"""

    def _parse_aggregator_model_name(self, model_name: str) -> Tuple[Optional[str], str]:
        """
        è§£æèšåˆæ¸ é“çš„æ¨¡å‹åç§°

        Args:
            model_name: æ¨¡å‹åç§°ï¼Œå¯èƒ½åŒ…å«å‰ç¼€ï¼ˆå¦‚ openai/gpt-4, anthropic/claude-3-sonnetï¼‰

        Returns:
            (åŸå‚å•†, åŸæ¨¡å‹å) å…ƒç»„
        """
        # å¸¸è§çš„èšåˆæ¸ é“æ¨¡å‹åç§°æ ¼å¼ï¼š
        # - openai/gpt-4
        # - anthropic/claude-3-sonnet
        # - google/gemini-pro

        if "/" in model_name:
            parts = model_name.split("/", 1)
            if len(parts) == 2:
                provider_hint = parts[0].lower()
                original_model = parts[1]

                # æ˜ å°„æä¾›å•†æç¤ºåˆ°æ ‡å‡†åç§°
                provider_map = {
                    "openai": "openai",
                    "anthropic": "anthropic",
                    "google": "google",
                    "deepseek": "deepseek",
                    "alibaba": "qwen",
                    "qwen": "qwen",
                    "zhipu": "zhipu",
                    "baidu": "baidu",
                    "moonshot": "moonshot"
                }

                provider = provider_map.get(provider_hint)
                return provider, original_model

        return None, model_name

    def _get_model_capability_with_mapping(self, model_name: str) -> Tuple[int, Optional[str]]:
        """
        è·å–æ¨¡å‹èƒ½åŠ›ç­‰çº§ï¼ˆæ”¯æŒèšåˆæ¸ é“æ˜ å°„ï¼‰

        Returns:
            (èƒ½åŠ›ç­‰çº§, æ˜ å°„çš„åŸæ¨¡å‹å) å…ƒç»„
        """
        # 1. å…ˆå°è¯•ç›´æ¥åŒ¹é…
        if model_name in DEFAULT_MODEL_CAPABILITIES:
            return DEFAULT_MODEL_CAPABILITIES[model_name]["capability_level"], None

        # 2. å°è¯•è§£æèšåˆæ¸ é“æ¨¡å‹å
        provider, original_model = self._parse_aggregator_model_name(model_name)

        if original_model and original_model != model_name:
            # å°è¯•ç”¨åŸæ¨¡å‹åæŸ¥æ‰¾
            if original_model in DEFAULT_MODEL_CAPABILITIES:
                logger.info(f"ğŸ”„ èšåˆæ¸ é“æ¨¡å‹æ˜ å°„: {model_name} -> {original_model}")
                return DEFAULT_MODEL_CAPABILITIES[original_model]["capability_level"], original_model

        # 3. è¿”å›é»˜è®¤å€¼
        return 2, None

    def get_model_capability(self, model_name: str) -> int:
        """
        è·å–æ¨¡å‹çš„èƒ½åŠ›ç­‰çº§ï¼ˆæ”¯æŒèšåˆæ¸ é“æ¨¡å‹æ˜ å°„ï¼‰

        Args:
            model_name: æ¨¡å‹åç§°ï¼ˆå¯èƒ½åŒ…å«èšåˆæ¸ é“å‰ç¼€ï¼Œå¦‚ openai/gpt-4ï¼‰

        Returns:
            èƒ½åŠ›ç­‰çº§ (1-5)
        """
        # 1. ä¼˜å…ˆä»æ•°æ®åº“é…ç½®è¯»å–
        try:
            llm_configs = unified_config.get_llm_configs()
            for config in llm_configs:
                if config.model_name == model_name:
                    return getattr(config, 'capability_level', 2)
        except Exception as e:
            logger.warning(f"ä»é…ç½®è¯»å–æ¨¡å‹èƒ½åŠ›å¤±è´¥: {e}")

        # 2. ä»é»˜è®¤æ˜ å°„è¡¨è¯»å–ï¼ˆæ”¯æŒèšåˆæ¸ é“æ˜ å°„ï¼‰
        capability, mapped_model = self._get_model_capability_with_mapping(model_name)
        if mapped_model:
            logger.info(f"âœ… ä½¿ç”¨æ˜ å°„æ¨¡å‹ {mapped_model} çš„èƒ½åŠ›ç­‰çº§: {capability}")

        return capability
    
    def get_model_config(self, model_name: str) -> Dict[str, Any]:
        """
        è·å–æ¨¡å‹çš„å®Œæ•´é…ç½®ä¿¡æ¯ï¼ˆæ”¯æŒèšåˆæ¸ é“æ¨¡å‹æ˜ å°„ï¼‰

        Args:
            model_name: æ¨¡å‹åç§°ï¼ˆå¯èƒ½åŒ…å«èšåˆæ¸ é“å‰ç¼€ï¼‰

        Returns:
            æ¨¡å‹é…ç½®å­—å…¸
        """
        # 1. ä¼˜å…ˆä» MongoDB æ•°æ®åº“é…ç½®è¯»å–ï¼ˆä½¿ç”¨åŒæ­¥å®¢æˆ·ç«¯ï¼‰
        try:
            from pymongo import MongoClient
            from app.core.config import settings
            from app.models.config import SystemConfig

            # ä½¿ç”¨åŒæ­¥ MongoDB å®¢æˆ·ç«¯
            client = MongoClient(settings.MONGO_URI)
            db = client[settings.MONGO_DB]
            collection = db.system_configs  # æ³¨æ„ï¼šé›†åˆåæ˜¯å¤æ•°

            # æŸ¥è¯¢ç³»ç»Ÿé…ç½®ï¼ˆä¸ config_service ä¿æŒä¸€è‡´ï¼‰
            doc = collection.find_one({"is_active": True}, sort=[("version", -1)])

            logger.info(f"ğŸ” [MongoDB] æŸ¥è¯¢ç»“æœ: doc={'å­˜åœ¨' if doc else 'ä¸å­˜åœ¨'}")
            if doc:
                logger.info(f"ğŸ” [MongoDB] æ–‡æ¡£ç‰ˆæœ¬: {doc.get('version')}, is_active: {doc.get('is_active')}")

            if doc and "llm_configs" in doc:
                llm_configs = doc["llm_configs"]
                logger.info(f"ğŸ” [MongoDB] llm_configs æ•°é‡: {len(llm_configs)}")

                for config_dict in llm_configs:
                    if config_dict.get("model_name") == model_name:
                        logger.info(f"ğŸ” [MongoDB] æ‰¾åˆ°æ¨¡å‹é…ç½®: {model_name}")
                        # ğŸ”§ å°†å­—ç¬¦ä¸²åˆ—è¡¨è½¬æ¢ä¸ºæšä¸¾åˆ—è¡¨
                        features_str = config_dict.get('features', [])
                        features_enum = []
                        for feature_str in features_str:
                            try:
                                # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸º ModelFeature æšä¸¾
                                features_enum.append(ModelFeature(feature_str))
                            except ValueError:
                                logger.warning(f"âš ï¸ æœªçŸ¥çš„ç‰¹æ€§å€¼: {feature_str}")

                        # ğŸ”§ å°†å­—ç¬¦ä¸²åˆ—è¡¨è½¬æ¢ä¸ºæšä¸¾åˆ—è¡¨
                        roles_str = config_dict.get('suitable_roles', ["both"])
                        roles_enum = []
                        for role_str in roles_str:
                            try:
                                # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸º ModelRole æšä¸¾
                                roles_enum.append(ModelRole(role_str))
                            except ValueError:
                                logger.warning(f"âš ï¸ æœªçŸ¥çš„è§’è‰²å€¼: {role_str}")

                        # å¦‚æœæ²¡æœ‰è§’è‰²ï¼Œé»˜è®¤ä¸º both
                        if not roles_enum:
                            roles_enum = [ModelRole.BOTH]

                        logger.info(f"ğŸ“Š [MongoDBé…ç½®] {model_name}: features={features_enum}, roles={roles_enum}")

                        # å…³é—­è¿æ¥
                        client.close()

                        return {
                            "model_name": config_dict.get("model_name"),
                            "capability_level": config_dict.get('capability_level', 2),
                            "suitable_roles": roles_enum,
                            "features": features_enum,
                            "recommended_depths": config_dict.get('recommended_depths', ["å¿«é€Ÿ", "åŸºç¡€", "æ ‡å‡†"]),
                            "performance_metrics": config_dict.get('performance_metrics', None)
                        }

            # å…³é—­è¿æ¥
            client.close()

        except Exception as e:
            logger.warning(f"ä» MongoDB è¯»å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)

        # 2. ä»é»˜è®¤æ˜ å°„è¡¨è¯»å–ï¼ˆç›´æ¥åŒ¹é…ï¼‰
        if model_name in DEFAULT_MODEL_CAPABILITIES:
            return DEFAULT_MODEL_CAPABILITIES[model_name]

        # 3. å°è¯•èšåˆæ¸ é“æ¨¡å‹æ˜ å°„
        provider, original_model = self._parse_aggregator_model_name(model_name)
        if original_model and original_model != model_name:
            if original_model in DEFAULT_MODEL_CAPABILITIES:
                logger.info(f"ğŸ”„ èšåˆæ¸ é“æ¨¡å‹æ˜ å°„: {model_name} -> {original_model}")
                config = DEFAULT_MODEL_CAPABILITIES[original_model].copy()
                config["model_name"] = model_name  # ä¿æŒåŸå§‹æ¨¡å‹å
                config["_mapped_from"] = original_model  # è®°å½•æ˜ å°„æ¥æº
                return config

        # 4. è¿”å›é»˜è®¤é…ç½®
        logger.warning(f"æœªæ‰¾åˆ°æ¨¡å‹ {model_name} çš„é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return {
            "model_name": model_name,
            "capability_level": 2,
            "suitable_roles": [ModelRole.BOTH],
            "features": [ModelFeature.TOOL_CALLING],
            "recommended_depths": ["å¿«é€Ÿ", "åŸºç¡€", "æ ‡å‡†"],
            "performance_metrics": {"speed": 3, "cost": 3, "quality": 3}
        }
    
    def validate_model_pair(
        self,
        quick_model: str,
        deep_model: str,
        research_depth: str
    ) -> Dict[str, Any]:
        """
        éªŒè¯æ¨¡å‹å¯¹æ˜¯å¦é€‚åˆå½“å‰åˆ†ææ·±åº¦

        Args:
            quick_model: å¿«é€Ÿåˆ†ææ¨¡å‹åç§°
            deep_model: æ·±åº¦åˆ†ææ¨¡å‹åç§°
            research_depth: ç ”ç©¶æ·±åº¦ï¼ˆå¿«é€Ÿ/åŸºç¡€/æ ‡å‡†/æ·±åº¦/å…¨é¢ï¼‰

        Returns:
            éªŒè¯ç»“æœå­—å…¸ï¼ŒåŒ…å« valid, warnings, recommendations
        """
        logger.info(f"ğŸ” å¼€å§‹éªŒè¯æ¨¡å‹å¯¹: quick={quick_model}, deep={deep_model}, depth={research_depth}")

        requirements = ANALYSIS_DEPTH_REQUIREMENTS.get(research_depth, ANALYSIS_DEPTH_REQUIREMENTS["æ ‡å‡†"])
        logger.info(f"ğŸ” åˆ†ææ·±åº¦è¦æ±‚: {requirements}")

        quick_config = self.get_model_config(quick_model)
        deep_config = self.get_model_config(deep_model)

        logger.info(f"ğŸ” å¿«é€Ÿæ¨¡å‹é…ç½®: {quick_config}")
        logger.info(f"ğŸ” æ·±åº¦æ¨¡å‹é…ç½®: {deep_config}")

        result = {
            "valid": True,
            "warnings": [],
            "recommendations": []
        }
        
        # æ£€æŸ¥å¿«é€Ÿæ¨¡å‹
        quick_level = quick_config["capability_level"]
        logger.info(f"ğŸ” æ£€æŸ¥å¿«é€Ÿæ¨¡å‹èƒ½åŠ›ç­‰çº§: {quick_level} >= {requirements['quick_model_min']}?")
        if quick_level < requirements["quick_model_min"]:
            warning = f"âš ï¸ å¿«é€Ÿæ¨¡å‹ {quick_model} (èƒ½åŠ›ç­‰çº§{quick_level}) ä½äº {research_depth} åˆ†æçš„å»ºè®®ç­‰çº§({requirements['quick_model_min']})"
            result["warnings"].append(warning)
            logger.warning(warning)

        # æ£€æŸ¥å¿«é€Ÿæ¨¡å‹è§’è‰²é€‚é…
        quick_roles = quick_config.get("suitable_roles", [])
        logger.info(f"ğŸ” æ£€æŸ¥å¿«é€Ÿæ¨¡å‹è§’è‰²: {quick_roles}")
        if ModelRole.QUICK_ANALYSIS not in quick_roles and ModelRole.BOTH not in quick_roles:
            warning = f"ğŸ’¡ æ¨¡å‹ {quick_model} ä¸æ˜¯ä¸ºå¿«é€Ÿåˆ†æä¼˜åŒ–çš„ï¼Œå¯èƒ½å½±å“æ•°æ®æ”¶é›†æ•ˆç‡"
            result["warnings"].append(warning)
            logger.warning(warning)

        # æ£€æŸ¥å¿«é€Ÿæ¨¡å‹æ˜¯å¦æ”¯æŒå·¥å…·è°ƒç”¨
        quick_features = quick_config.get("features", [])
        logger.info(f"ğŸ” æ£€æŸ¥å¿«é€Ÿæ¨¡å‹ç‰¹æ€§: {quick_features}")
        if ModelFeature.TOOL_CALLING not in quick_features:
            result["valid"] = False
            warning = f"âŒ å¿«é€Ÿæ¨¡å‹ {quick_model} ä¸æ”¯æŒå·¥å…·è°ƒç”¨ï¼Œæ— æ³•å®Œæˆæ•°æ®æ”¶é›†ä»»åŠ¡"
            result["warnings"].append(warning)
            logger.error(warning)

        # æ£€æŸ¥æ·±åº¦æ¨¡å‹
        deep_level = deep_config["capability_level"]
        logger.info(f"ğŸ” æ£€æŸ¥æ·±åº¦æ¨¡å‹èƒ½åŠ›ç­‰çº§: {deep_level} >= {requirements['deep_model_min']}?")
        if deep_level < requirements["deep_model_min"]:
            result["valid"] = False
            warning = f"âŒ æ·±åº¦æ¨¡å‹ {deep_model} (èƒ½åŠ›ç­‰çº§{deep_level}) ä¸æ»¡è¶³ {research_depth} åˆ†æçš„æœ€ä½è¦æ±‚(ç­‰çº§{requirements['deep_model_min']})"
            result["warnings"].append(warning)
            logger.error(warning)
            result["recommendations"].append(
                self._recommend_model("deep", requirements["deep_model_min"])
            )

        # æ£€æŸ¥æ·±åº¦æ¨¡å‹è§’è‰²é€‚é…
        deep_roles = deep_config.get("suitable_roles", [])
        logger.info(f"ğŸ” æ£€æŸ¥æ·±åº¦æ¨¡å‹è§’è‰²: {deep_roles}")
        if ModelRole.DEEP_ANALYSIS not in deep_roles and ModelRole.BOTH not in deep_roles:
            warning = f"ğŸ’¡ æ¨¡å‹ {deep_model} ä¸æ˜¯ä¸ºæ·±åº¦æ¨ç†ä¼˜åŒ–çš„ï¼Œå¯èƒ½å½±å“åˆ†æè´¨é‡"
            result["warnings"].append(warning)
            logger.warning(warning)

        # æ£€æŸ¥å¿…éœ€ç‰¹æ€§
        logger.info(f"ğŸ” æ£€æŸ¥å¿…éœ€ç‰¹æ€§: {requirements['required_features']}")
        for feature in requirements["required_features"]:
            if feature == ModelFeature.REASONING:
                deep_features = deep_config.get("features", [])
                logger.info(f"ğŸ” æ£€æŸ¥æ·±åº¦æ¨¡å‹æ¨ç†èƒ½åŠ›: {deep_features}")
                if feature not in deep_features:
                    warning = f"ğŸ’¡ {research_depth} åˆ†æå»ºè®®ä½¿ç”¨å…·æœ‰å¼ºæ¨ç†èƒ½åŠ›çš„æ·±åº¦æ¨¡å‹"
                    result["warnings"].append(warning)
                    logger.warning(warning)

        logger.info(f"ğŸ” éªŒè¯ç»“æœ: valid={result['valid']}, warnings={len(result['warnings'])}æ¡")
        logger.info(f"ğŸ” è­¦å‘Šè¯¦æƒ…: {result['warnings']}")

        return result
    
    def recommend_models_for_depth(
        self,
        research_depth: str
    ) -> Tuple[str, str]:
        """
        æ ¹æ®åˆ†ææ·±åº¦æ¨èåˆé€‚çš„æ¨¡å‹å¯¹
        
        Args:
            research_depth: ç ”ç©¶æ·±åº¦ï¼ˆå¿«é€Ÿ/åŸºç¡€/æ ‡å‡†/æ·±åº¦/å…¨é¢ï¼‰
            
        Returns:
            (quick_model, deep_model) å…ƒç»„
        """
        requirements = ANALYSIS_DEPTH_REQUIREMENTS.get(research_depth, ANALYSIS_DEPTH_REQUIREMENTS["æ ‡å‡†"])
        
        # è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
        try:
            llm_configs = unified_config.get_llm_configs()
            enabled_models = [c for c in llm_configs if c.enabled]
        except Exception as e:
            logger.error(f"è·å–æ¨¡å‹é…ç½®å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤æ¨¡å‹
            return self._get_default_models()
        
        if not enabled_models:
            logger.warning("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_models()
        
        # ç­›é€‰é€‚åˆå¿«é€Ÿåˆ†æçš„æ¨¡å‹
        quick_candidates = []
        for m in enabled_models:
            roles = getattr(m, 'suitable_roles', [ModelRole.BOTH])
            level = getattr(m, 'capability_level', 2)
            features = getattr(m, 'features', [])
            
            if (ModelRole.QUICK_ANALYSIS in roles or ModelRole.BOTH in roles) and \
               level >= requirements["quick_model_min"] and \
               ModelFeature.TOOL_CALLING in features:
                quick_candidates.append(m)
        
        # ç­›é€‰é€‚åˆæ·±åº¦åˆ†æçš„æ¨¡å‹
        deep_candidates = []
        for m in enabled_models:
            roles = getattr(m, 'suitable_roles', [ModelRole.BOTH])
            level = getattr(m, 'capability_level', 2)
            
            if (ModelRole.DEEP_ANALYSIS in roles or ModelRole.BOTH in roles) and \
               level >= requirements["deep_model_min"]:
                deep_candidates.append(m)
        
        # æŒ‰æ€§ä»·æ¯”æ’åºï¼ˆèƒ½åŠ›ç­‰çº§ vs æˆæœ¬ï¼‰
        quick_candidates.sort(
            key=lambda x: (
                getattr(x, 'capability_level', 2),
                -getattr(x, 'performance_metrics', {}).get("cost", 3) if getattr(x, 'performance_metrics', None) else 0
            ),
            reverse=True
        )
        
        deep_candidates.sort(
            key=lambda x: (
                getattr(x, 'capability_level', 2),
                getattr(x, 'performance_metrics', {}).get("quality", 3) if getattr(x, 'performance_metrics', None) else 0
            ),
            reverse=True
        )
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        quick_model = quick_candidates[0].model_name if quick_candidates else None
        deep_model = deep_candidates[0].model_name if deep_candidates else None
        
        # å¦‚æœæ²¡æ‰¾åˆ°åˆé€‚çš„ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤
        if not quick_model or not deep_model:
            return self._get_default_models()
        
        logger.info(
            f"ğŸ¤– ä¸º {research_depth} åˆ†ææ¨èæ¨¡å‹: "
            f"quick={quick_model} (è§’è‰²:å¿«é€Ÿåˆ†æ), "
            f"deep={deep_model} (è§’è‰²:æ·±åº¦æ¨ç†)"
        )
        
        return quick_model, deep_model
    
    def _get_default_models(self) -> Tuple[str, str]:
        """è·å–é»˜è®¤æ¨¡å‹å¯¹"""
        try:
            quick_model = unified_config.get_quick_analysis_model()
            deep_model = unified_config.get_deep_analysis_model()
            logger.info(f"ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ¨¡å‹: quick={quick_model}, deep={deep_model}")
            return quick_model, deep_model
        except Exception as e:
            logger.error(f"è·å–é»˜è®¤æ¨¡å‹å¤±è´¥: {e}")
            return "qwen-turbo", "qwen-plus"
    
    def _recommend_model(self, model_type: str, min_level: int) -> str:
        """æ¨èæ»¡è¶³è¦æ±‚çš„æ¨¡å‹"""
        try:
            llm_configs = unified_config.get_llm_configs()
            for config in llm_configs:
                if config.enabled and getattr(config, 'capability_level', 2) >= min_level:
                    display_name = config.model_display_name or config.model_name
                    return f"å»ºè®®ä½¿ç”¨: {display_name}"
        except Exception as e:
            logger.warning(f"æ¨èæ¨¡å‹å¤±è´¥: {e}")
        
        return "å»ºè®®å‡çº§æ¨¡å‹é…ç½®"


# å•ä¾‹
_model_capability_service = None


def get_model_capability_service() -> ModelCapabilityService:
    """è·å–æ¨¡å‹èƒ½åŠ›æœåŠ¡å•ä¾‹"""
    global _model_capability_service
    if _model_capability_service is None:
        _model_capability_service = ModelCapabilityService()
    return _model_capability_service

