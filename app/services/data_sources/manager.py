"""
Data source manager that orchestrates multiple adapters with priority and optional consistency checks
"""
from typing import List, Optional, Tuple, Dict
import logging
from datetime import datetime, timedelta
import pandas as pd

from .base import DataSourceAdapter
from .tushare_adapter import TushareAdapter
from .akshare_adapter import AKShareAdapter
from .baostock_adapter import BaoStockAdapter

logger = logging.getLogger(__name__)


class DataSourceManager:
    """
    æ•°æ®æºç®¡ç†å™¨
    - ç®¡ç†å¤šä¸ªé€‚é…å™¨ï¼ŒåŸºäºä¼˜å…ˆçº§æ’åº
    - æä¾› fallback è·å–èƒ½åŠ›
    - å¯é€‰ï¼šä¸€è‡´æ€§æ£€æŸ¥ï¼ˆè‹¥ä¾èµ–å­˜åœ¨ï¼‰
    """

    def __init__(self):
        self.adapters: List[DataSourceAdapter] = [
            TushareAdapter(),
            AKShareAdapter(),
            BaoStockAdapter(),
        ]

        # ä»æ•°æ®åº“åŠ è½½ä¼˜å…ˆçº§é…ç½®
        self._load_priority_from_database()

        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆæ•°å­—è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜ï¼Œæ‰€ä»¥é™åºæ’åˆ—ï¼‰
        self.adapters.sort(key=lambda x: x.priority, reverse=True)

        try:
            from .data_consistency_checker import DataConsistencyChecker  # type: ignore
            self.consistency_checker = DataConsistencyChecker()
        except Exception:
            logger.warning("âš ï¸ æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å™¨ä¸å¯ç”¨")
            self.consistency_checker = None

    def _load_priority_from_database(self):
        """ä»æ•°æ®åº“åŠ è½½æ•°æ®æºä¼˜å…ˆçº§é…ç½®ï¼ˆä» datasource_groupings é›†åˆè¯»å– Aè‚¡å¸‚åœºçš„ä¼˜å…ˆçº§ï¼‰"""
        try:
            from app.core.database import get_mongo_db_sync
            db = get_mongo_db_sync()
            groupings_collection = db.datasource_groupings

            # æŸ¥è¯¢ Aè‚¡å¸‚åœºçš„æ•°æ®æºåˆ†ç»„é…ç½®
            groupings = list(groupings_collection.find({
                "market_category_id": "a_shares",
                "enabled": True
            }))

            if groupings:
                # åˆ›å»ºåç§°åˆ°ä¼˜å…ˆçº§çš„æ˜ å°„ï¼ˆæ•°æ®æºåç§°éœ€è¦è½¬æ¢ä¸ºå°å†™ï¼‰
                priority_map = {}
                for grouping in groupings:
                    data_source_name = grouping.get('data_source_name', '').lower()
                    priority = grouping.get('priority')
                    if data_source_name and priority is not None:
                        priority_map[data_source_name] = priority
                        logger.info(f"ğŸ“Š ä»æ•°æ®åº“è¯»å– {data_source_name} åœ¨ Aè‚¡å¸‚åœºçš„ä¼˜å…ˆçº§: {priority}")

                # æ›´æ–°å„ä¸ª Adapter çš„ä¼˜å…ˆçº§
                for adapter in self.adapters:
                    if adapter.name in priority_map:
                        # åŠ¨æ€è®¾ç½®ä¼˜å…ˆçº§
                        adapter._priority = priority_map[adapter.name]
                        logger.info(f"âœ… è®¾ç½® {adapter.name} ä¼˜å…ˆçº§: {adapter._priority}")
                    else:
                        # ä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§
                        adapter._priority = adapter._get_default_priority()
                        logger.info(f"âš ï¸ æ•°æ®åº“ä¸­æœªæ‰¾åˆ° {adapter.name} é…ç½®ï¼Œä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§: {adapter._priority}")
            else:
                logger.info("âš ï¸ æ•°æ®åº“ä¸­æœªæ‰¾åˆ° Aè‚¡å¸‚åœºçš„æ•°æ®æºé…ç½®ï¼Œä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§")
                # ä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§
                for adapter in self.adapters:
                    adapter._priority = adapter._get_default_priority()
        except Exception as e:
            logger.warning(f"âš ï¸ ä»æ•°æ®åº“åŠ è½½ä¼˜å…ˆçº§å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§")
            import traceback
            logger.warning(f"å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
            # ä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§
            for adapter in self.adapters:
                adapter._priority = adapter._get_default_priority()

    def get_available_adapters(self) -> List[DataSourceAdapter]:
        available: List[DataSourceAdapter] = []
        for adapter in self.adapters:
            if adapter.is_available():
                available.append(adapter)
                logger.info(
                    f"Data source {adapter.name} is available (priority: {adapter.priority})"
                )
            else:
                logger.warning(f"Data source {adapter.name} is not available")
        return available

    def get_stock_list_with_fallback(self, preferred_sources: Optional[List[str]] = None) -> Tuple[Optional[pd.DataFrame], Optional[str]]:
        """
        è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œæ”¯æŒæŒ‡å®šä¼˜å…ˆæ•°æ®æº

        Args:
            preferred_sources: ä¼˜å…ˆä½¿ç”¨çš„æ•°æ®æºåˆ—è¡¨ï¼Œä¾‹å¦‚ ['akshare', 'baostock']
                             å¦‚æœä¸º Noneï¼Œåˆ™æŒ‰ç…§é»˜è®¤ä¼˜å…ˆçº§é¡ºåº

        Returns:
            (DataFrame, source_name) æˆ– (None, None)
        """
        available_adapters = self.get_available_adapters()

        # å¦‚æœæŒ‡å®šäº†ä¼˜å…ˆæ•°æ®æºï¼Œé‡æ–°æ’åº
        if preferred_sources:
            logger.info(f"Using preferred data sources: {preferred_sources}")
            # åˆ›å»ºä¼˜å…ˆçº§æ˜ å°„
            priority_map = {name: idx for idx, name in enumerate(preferred_sources)}
            # å°†æŒ‡å®šçš„æ•°æ®æºæ’åœ¨å‰é¢ï¼Œå…¶ä»–çš„ä¿æŒåŸé¡ºåº
            preferred = [a for a in available_adapters if a.name in priority_map]
            others = [a for a in available_adapters if a.name not in priority_map]
            # æŒ‰ç…§ preferred_sources çš„é¡ºåºæ’åº
            preferred.sort(key=lambda a: priority_map.get(a.name, 999))
            available_adapters = preferred + others
            logger.info(f"Reordered adapters: {[a.name for a in available_adapters]}")

        for adapter in available_adapters:
            try:
                logger.info(f"Trying to fetch stock list from {adapter.name}")
                df = adapter.get_stock_list()
                if df is not None and not df.empty:
                    return df, adapter.name
            except Exception as e:
                logger.error(f"Failed to fetch stock list from {adapter.name}: {e}")
                continue
        return None, None

    def get_daily_basic_with_fallback(self, trade_date: str, preferred_sources: Optional[List[str]] = None) -> Tuple[Optional[pd.DataFrame], Optional[str]]:
        """
        è·å–æ¯æ—¥åŸºç¡€æ•°æ®ï¼Œæ”¯æŒæŒ‡å®šä¼˜å…ˆæ•°æ®æº

        Args:
            trade_date: äº¤æ˜“æ—¥æœŸ
            preferred_sources: ä¼˜å…ˆä½¿ç”¨çš„æ•°æ®æºåˆ—è¡¨

        Returns:
            (DataFrame, source_name) æˆ– (None, None)
        """
        available_adapters = self.get_available_adapters()

        # å¦‚æœæŒ‡å®šäº†ä¼˜å…ˆæ•°æ®æºï¼Œé‡æ–°æ’åº
        if preferred_sources:
            priority_map = {name: idx for idx, name in enumerate(preferred_sources)}
            preferred = [a for a in available_adapters if a.name in priority_map]
            others = [a for a in available_adapters if a.name not in priority_map]
            preferred.sort(key=lambda a: priority_map.get(a.name, 999))
            available_adapters = preferred + others

        for adapter in available_adapters:
            try:
                logger.info(f"Trying to fetch daily basic data from {adapter.name}")
                df = adapter.get_daily_basic(trade_date)
                if df is not None and not df.empty:
                    return df, adapter.name
            except Exception as e:
                logger.error(f"Failed to fetch daily basic data from {adapter.name}: {e}")
                continue
        return None, None

    def find_latest_trade_date_with_fallback(self, preferred_sources: Optional[List[str]] = None) -> Optional[str]:
        """
        æŸ¥æ‰¾æœ€æ–°äº¤æ˜“æ—¥æœŸï¼Œæ”¯æŒæŒ‡å®šä¼˜å…ˆæ•°æ®æº

        Args:
            preferred_sources: ä¼˜å…ˆä½¿ç”¨çš„æ•°æ®æºåˆ—è¡¨

        Returns:
            äº¤æ˜“æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆYYYYMMDDæ ¼å¼ï¼‰æˆ– None
        """
        available_adapters = self.get_available_adapters()

        # å¦‚æœæŒ‡å®šäº†ä¼˜å…ˆæ•°æ®æºï¼Œé‡æ–°æ’åº
        if preferred_sources:
            priority_map = {name: idx for idx, name in enumerate(preferred_sources)}
            preferred = [a for a in available_adapters if a.name in priority_map]
            others = [a for a in available_adapters if a.name not in priority_map]
            preferred.sort(key=lambda a: priority_map.get(a.name, 999))
            available_adapters = preferred + others

        for adapter in available_adapters:
            try:
                trade_date = adapter.find_latest_trade_date()
                if trade_date:
                    return trade_date
            except Exception as e:
                logger.error(f"Failed to find trade date from {adapter.name}: {e}")
                continue
        return (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")

    def get_realtime_quotes_with_fallback(self) -> Tuple[Optional[Dict], Optional[str]]:
        """
        è·å–å…¨å¸‚åœºå®æ—¶å¿«ç…§ï¼ŒæŒ‰é€‚é…å™¨ä¼˜å…ˆçº§ä¾æ¬¡å°è¯•ï¼Œè¿”å›é¦–ä¸ªæˆåŠŸç»“æœ
        Returns: (quotes_dict, source_name)
        quotes_dict å½¢å¦‚ { '000001': {'close': 10.0, 'pct_chg': 1.2, 'amount': 1.2e8}, ... }
        """
        available_adapters = self.get_available_adapters()
        for adapter in available_adapters:
            try:
                logger.info(f"Trying to fetch realtime quotes from {adapter.name}")
                data = adapter.get_realtime_quotes()
                if data:
                    return data, adapter.name
            except Exception as e:
                logger.error(f"Failed to fetch realtime quotes from {adapter.name}: {e}")
                continue
        return None, None


    def get_daily_basic_with_consistency_check(
        self, trade_date: str
    ) -> Tuple[Optional[pd.DataFrame], Optional[str], Optional[Dict]]:
        """
        ä½¿ç”¨ä¸€è‡´æ€§æ£€æŸ¥è·å–æ¯æ—¥åŸºç¡€æ•°æ®

        Returns:
            Tuple[DataFrame, source_name, consistency_report]
        """
        available_adapters = self.get_available_adapters()
        if len(available_adapters) < 2:
            df, source = self.get_daily_basic_with_fallback(trade_date)
            return df, source, None
        primary_adapter = available_adapters[0]
        secondary_adapter = available_adapters[1]
        try:
            logger.info(
                f"ğŸ” è·å–æ•°æ®è¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥: {primary_adapter.name} vs {secondary_adapter.name}"
            )
            primary_data = primary_adapter.get_daily_basic(trade_date)
            secondary_data = secondary_adapter.get_daily_basic(trade_date)
            if primary_data is None or primary_data.empty:
                logger.warning(f"âš ï¸ ä¸»æ•°æ®æº{primary_adapter.name}å¤±è´¥ï¼Œä½¿ç”¨fallback")
                df, source = self.get_daily_basic_with_fallback(trade_date)
                return df, source, None
            if secondary_data is None or secondary_data.empty:
                logger.warning(f"âš ï¸ æ¬¡æ•°æ®æº{secondary_adapter.name}å¤±è´¥ï¼Œä½¿ç”¨ä¸»æ•°æ®æº")
                return primary_data, primary_adapter.name, None
            if self.consistency_checker:
                consistency_result = self.consistency_checker.check_daily_basic_consistency(
                    primary_data,
                    secondary_data,
                    primary_adapter.name,
                    secondary_adapter.name,
                )
                final_data, resolution_strategy = self.consistency_checker.resolve_data_conflicts(
                    primary_data, secondary_data, consistency_result
                )
                consistency_report = {
                    'is_consistent': consistency_result.is_consistent,
                    'confidence_score': consistency_result.confidence_score,
                    'recommended_action': consistency_result.recommended_action,
                    'resolution_strategy': resolution_strategy,
                    'differences': consistency_result.differences,
                    'primary_source': primary_adapter.name,
                    'secondary_source': secondary_adapter.name,
                }
                logger.info(
                    f"ğŸ“Š æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆ: ç½®ä¿¡åº¦={consistency_result.confidence_score:.2f}, ç­–ç•¥={consistency_result.recommended_action}"
                )
                return final_data, primary_adapter.name, consistency_report
            else:
                logger.warning("âš ï¸ ä¸€è‡´æ€§æ£€æŸ¥å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¸»æ•°æ®æº")
                return primary_data, primary_adapter.name, None
        except Exception as e:
            logger.error(f"âŒ ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            df, source = self.get_daily_basic_with_fallback(trade_date)
            return df, source, None



    def get_kline_with_fallback(self, code: str, period: str = "day", limit: int = 120, adj: Optional[str] = None) -> Tuple[Optional[List[Dict]], Optional[str]]:
        """æŒ‰ä¼˜å…ˆçº§å°è¯•è·å–Kçº¿ï¼Œè¿”å›(items, source)"""
        available_adapters = self.get_available_adapters()
        for adapter in available_adapters:
            try:
                logger.info(f"Trying to fetch kline from {adapter.name}")
                items = adapter.get_kline(code=code, period=period, limit=limit, adj=adj)
                if items:
                    return items, adapter.name
            except Exception as e:
                logger.error(f"Failed to fetch kline from {adapter.name}: {e}")
                continue
        return None, None

    def get_news_with_fallback(self, code: str, days: int = 2, limit: int = 50, include_announcements: bool = True) -> Tuple[Optional[List[Dict]], Optional[str]]:
        """æŒ‰ä¼˜å…ˆçº§å°è¯•è·å–æ–°é—»ä¸å…¬å‘Šï¼Œè¿”å›(items, source)"""
        available_adapters = self.get_available_adapters()
        for adapter in available_adapters:
            try:
                logger.info(f"Trying to fetch news from {adapter.name}")
                items = adapter.get_news(code=code, days=days, limit=limit, include_announcements=include_announcements)
                if items:
                    return items, adapter.name
            except Exception as e:
                logger.error(f"Failed to fetch news from {adapter.name}: {e}")
                continue
        return None, None
