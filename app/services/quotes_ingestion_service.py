import logging
from datetime import datetime, time as dtime, timedelta
from typing import Dict, Optional, Tuple, List
from zoneinfo import ZoneInfo
from collections import deque

from pymongo import UpdateOne

from app.core.config import settings
from app.core.database import get_mongo_db
from app.services.data_sources.manager import DataSourceManager

logger = logging.getLogger(__name__)


class QuotesIngestionService:
    """
    å®šæ—¶ä»æ•°æ®æºé€‚é…å±‚è·å–å…¨å¸‚åœºè¿‘å®æ—¶è¡Œæƒ…ï¼Œå…¥åº“åˆ° MongoDB é›†åˆ `market_quotes`ã€‚

    æ ¸å¿ƒç‰¹æ€§ï¼š
    - è°ƒåº¦é¢‘ç‡ï¼šç”± settings.QUOTES_INGEST_INTERVAL_SECONDS æ§åˆ¶ï¼ˆé»˜è®¤360ç§’=6åˆ†é’Ÿï¼‰
    - æ¥å£è½®æ¢ï¼šTushare â†’ AKShareä¸œæ–¹è´¢å¯Œ â†’ AKShareæ–°æµªè´¢ç»ï¼ˆé¿å…å•ä¸€æ¥å£è¢«é™æµï¼‰
    - æ™ºèƒ½é™æµï¼šTushareå…è´¹ç”¨æˆ·æ¯å°æ—¶æœ€å¤š2æ¬¡ï¼Œä»˜è´¹ç”¨æˆ·è‡ªåŠ¨åˆ‡æ¢åˆ°é«˜é¢‘æ¨¡å¼ï¼ˆ5ç§’ï¼‰
    - ä¼‘å¸‚æ—¶é—´ï¼šè·³è¿‡ä»»åŠ¡ï¼Œä¿æŒä¸Šæ¬¡æ”¶ç›˜æ•°æ®ï¼›å¿…è¦æ—¶æ‰§è¡Œä¸€æ¬¡æ€§å…œåº•è¡¥æ•°
    - å­—æ®µï¼šcode(6ä½)ã€closeã€pct_chgã€amountã€openã€highã€lowã€pre_closeã€trade_dateã€updated_at
    """

    def __init__(self, collection_name: str = "market_quotes") -> None:
        from collections import deque

        self.collection_name = collection_name
        self.status_collection_name = "quotes_ingestion_status"  # çŠ¶æ€è®°å½•é›†åˆ
        self.tz = ZoneInfo(settings.TIMEZONE)

        # Tushare æƒé™æ£€æµ‹ç›¸å…³å±æ€§
        self._tushare_permission_checked = False  # æ˜¯å¦å·²æ£€æµ‹è¿‡æƒé™
        self._tushare_has_premium = False  # æ˜¯å¦æœ‰ä»˜è´¹æƒé™
        self._tushare_last_call_time = None  # ä¸Šæ¬¡è°ƒç”¨æ—¶é—´ï¼ˆç”¨äºå…è´¹ç”¨æˆ·é™æµï¼‰
        self._tushare_hourly_limit = 2  # å…è´¹ç”¨æˆ·æ¯å°æ—¶æœ€å¤šè°ƒç”¨æ¬¡æ•°
        self._tushare_call_count = 0  # å½“å‰å°æ—¶å†…è°ƒç”¨æ¬¡æ•°
        self._tushare_call_times = deque()  # è®°å½•è°ƒç”¨æ—¶é—´çš„é˜Ÿåˆ—ï¼ˆç”¨äºé™æµï¼‰

        # æ¥å£è½®æ¢ç›¸å…³å±æ€§
        self._rotation_sources = ["tushare", "akshare_eastmoney", "akshare_sina"]
        self._rotation_index = 0  # å½“å‰è½®æ¢ç´¢å¼•

    @staticmethod
    def _normalize_stock_code(code: str) -> str:
        """
        æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ä¸º6ä½æ•°å­—

        å¤„ç†ä»¥ä¸‹æƒ…å†µï¼š
        - sz000001 -> 000001
        - sh600036 -> 600036
        - 000001 -> 000001
        - 1 -> 000001

        Args:
            code: åŸå§‹è‚¡ç¥¨ä»£ç 

        Returns:
            str: æ ‡å‡†åŒ–åçš„6ä½è‚¡ç¥¨ä»£ç 
        """
        if not code:
            return ""

        code_str = str(code).strip()

        # å¦‚æœä»£ç é•¿åº¦è¶…è¿‡6ä½ï¼Œå»æ‰å‰é¢çš„äº¤æ˜“æ‰€å‰ç¼€ï¼ˆå¦‚ sz, shï¼‰
        if len(code_str) > 6:
            # æå–æ‰€æœ‰æ•°å­—å­—ç¬¦
            code_str = ''.join(filter(str.isdigit, code_str))

        # å¦‚æœæ˜¯çº¯æ•°å­—ï¼Œè¡¥é½åˆ°6ä½
        if code_str.isdigit():
            code_clean = code_str.lstrip('0') or '0'  # ç§»é™¤å‰å¯¼0ï¼Œå¦‚æœå…¨æ˜¯0åˆ™ä¿ç•™ä¸€ä¸ª0
            return code_clean.zfill(6)  # è¡¥é½åˆ°6ä½

        # å¦‚æœä¸æ˜¯çº¯æ•°å­—ï¼Œå°è¯•æå–æ•°å­—éƒ¨åˆ†
        code_digits = ''.join(filter(str.isdigit, code_str))
        if code_digits:
            return code_digits.zfill(6)

        # æ— æ³•æå–æœ‰æ•ˆä»£ç ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ""

    async def ensure_indexes(self) -> None:
        db = get_mongo_db()
        coll = db[self.collection_name]
        try:
            await coll.create_index("code", unique=True)
            await coll.create_index("updated_at")
        except Exception as e:
            logger.warning(f"åˆ›å»ºè¡Œæƒ…è¡¨ç´¢å¼•å¤±è´¥ï¼ˆå¿½ç•¥ï¼‰: {e}")

    async def _record_sync_status(
        self,
        success: bool,
        source: Optional[str] = None,
        records_count: int = 0,
        error_msg: Optional[str] = None
    ) -> None:
        """
        è®°å½•åŒæ­¥çŠ¶æ€

        Args:
            success: æ˜¯å¦æˆåŠŸ
            source: æ•°æ®æºåç§°
            records_count: è®°å½•æ•°é‡
            error_msg: é”™è¯¯ä¿¡æ¯
        """
        try:
            db = get_mongo_db()
            status_coll = db[self.status_collection_name]

            now = datetime.now(self.tz)

            status_doc = {
                "job": "quotes_ingestion",
                "last_sync_time": now,
                "last_sync_time_iso": now.isoformat(),
                "success": success,
                "data_source": source,
                "records_count": records_count,
                "interval_seconds": settings.QUOTES_INGEST_INTERVAL_SECONDS,
                "error_message": error_msg,
                "updated_at": now,
            }

            await status_coll.update_one(
                {"job": "quotes_ingestion"},
                {"$set": status_doc},
                upsert=True
            )

        except Exception as e:
            logger.warning(f"è®°å½•åŒæ­¥çŠ¶æ€å¤±è´¥ï¼ˆå¿½ç•¥ï¼‰: {e}")

    async def get_sync_status(self) -> Dict[str, any]:
        """
        è·å–åŒæ­¥çŠ¶æ€

        Returns:
            {
                "last_sync_time": "2025-10-28 15:06:00",
                "last_sync_time_iso": "2025-10-28T15:06:00+08:00",
                "interval_seconds": 360,
                "interval_minutes": 6,
                "data_source": "tushare",
                "success": True,
                "records_count": 5440,
                "error_message": None
            }
        """
        try:
            db = get_mongo_db()
            status_coll = db[self.status_collection_name]

            doc = await status_coll.find_one({"job": "quotes_ingestion"})

            if not doc:
                return {
                    "last_sync_time": None,
                    "last_sync_time_iso": None,
                    "interval_seconds": settings.QUOTES_INGEST_INTERVAL_SECONDS,
                    "interval_minutes": settings.QUOTES_INGEST_INTERVAL_SECONDS / 60,
                    "data_source": None,
                    "success": None,
                    "records_count": 0,
                    "error_message": "å°šæœªæ‰§è¡Œè¿‡åŒæ­¥"
                }

            # ç§»é™¤ _id å­—æ®µ
            doc.pop("_id", None)
            doc.pop("job", None)

            # æ·»åŠ åˆ†é’Ÿæ•°
            doc["interval_minutes"] = doc.get("interval_seconds", 0) / 60

            # ğŸ”¥ æ ¼å¼åŒ–æ—¶é—´ï¼ˆç¡®ä¿è½¬æ¢ä¸ºæœ¬åœ°æ—¶åŒºï¼‰
            if "last_sync_time" in doc and doc["last_sync_time"]:
                dt = doc["last_sync_time"]
                # MongoDB è¿”å›çš„æ˜¯ UTC æ—¶é—´çš„ datetime å¯¹è±¡ï¼ˆaware æˆ– naiveï¼‰
                # å¦‚æœæ˜¯ naiveï¼Œæ·»åŠ  UTC æ—¶åŒºï¼›å¦‚æœæ˜¯ awareï¼Œè½¬æ¢ä¸ºæœ¬åœ°æ—¶åŒº
                if dt.tzinfo is None:
                    # naive datetimeï¼Œå‡è®¾æ˜¯ UTC
                    dt = dt.replace(tzinfo=ZoneInfo("UTC"))
                # è½¬æ¢ä¸ºæœ¬åœ°æ—¶åŒº
                dt_local = dt.astimezone(self.tz)
                doc["last_sync_time"] = dt_local.strftime("%Y-%m-%d %H:%M:%S")

            return doc

        except Exception as e:
            logger.error(f"è·å–åŒæ­¥çŠ¶æ€å¤±è´¥: {e}")
            return {
                "last_sync_time": None,
                "last_sync_time_iso": None,
                "interval_seconds": settings.QUOTES_INGEST_INTERVAL_SECONDS,
                "interval_minutes": settings.QUOTES_INGEST_INTERVAL_SECONDS / 60,
                "data_source": None,
                "success": None,
                "records_count": 0,
                "error_message": f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}"
            }

    def _check_tushare_permission(self) -> bool:
        """
        æ£€æµ‹ Tushare rt_k æ¥å£æƒé™

        Returns:
            True: æœ‰ä»˜è´¹æƒé™ï¼ˆå¯é«˜é¢‘è°ƒç”¨ï¼‰
            False: å…è´¹ç”¨æˆ·ï¼ˆæ¯å°æ—¶æœ€å¤š2æ¬¡ï¼‰
        """
        if self._tushare_permission_checked:
            return self._tushare_has_premium or False

        try:
            from app.services.data_sources.tushare_adapter import TushareAdapter
            adapter = TushareAdapter()

            if not adapter.is_available():
                logger.info("Tushare ä¸å¯ç”¨ï¼Œè·³è¿‡æƒé™æ£€æµ‹")
                self._tushare_has_premium = False
                self._tushare_permission_checked = True
                return False

            # å°è¯•è°ƒç”¨ rt_k æ¥å£æµ‹è¯•æƒé™
            try:
                df = adapter._provider.api.rt_k(ts_code='000001.SZ')
                if df is not None and not getattr(df, 'empty', True):
                    logger.info("âœ… æ£€æµ‹åˆ° Tushare rt_k æ¥å£æƒé™ï¼ˆä»˜è´¹ç”¨æˆ·ï¼‰")
                    self._tushare_has_premium = True
                else:
                    logger.info("âš ï¸ Tushare rt_k æ¥å£è¿”å›ç©ºæ•°æ®ï¼ˆå¯èƒ½æ˜¯å…è´¹ç”¨æˆ·æˆ–æ¥å£é™åˆ¶ï¼‰")
                    self._tushare_has_premium = False
            except Exception as e:
                error_msg = str(e).lower()
                if "æƒé™" in error_msg or "permission" in error_msg or "æ²¡æœ‰è®¿é—®" in error_msg:
                    logger.info("âš ï¸ Tushare rt_k æ¥å£æ— æƒé™ï¼ˆå…è´¹ç”¨æˆ·ï¼‰")
                    self._tushare_has_premium = False
                else:
                    logger.warning(f"âš ï¸ Tushare rt_k æ¥å£æµ‹è¯•å¤±è´¥: {e}")
                    self._tushare_has_premium = False

            self._tushare_permission_checked = True
            return self._tushare_has_premium or False

        except Exception as e:
            logger.warning(f"Tushare æƒé™æ£€æµ‹å¤±è´¥: {e}")
            self._tushare_has_premium = False
            self._tushare_permission_checked = True
            return False

    def _can_call_tushare(self) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦å¯ä»¥è°ƒç”¨ Tushare rt_k æ¥å£

        Returns:
            True: å¯ä»¥è°ƒç”¨
            False: è¶…è¿‡é™åˆ¶ï¼Œä¸èƒ½è°ƒç”¨
        """
        # å¦‚æœæ˜¯ä»˜è´¹ç”¨æˆ·ï¼Œä¸é™åˆ¶è°ƒç”¨æ¬¡æ•°
        if self._tushare_has_premium:
            return True

        # å…è´¹ç”¨æˆ·ï¼šæ£€æŸ¥æ¯å°æ—¶è°ƒç”¨æ¬¡æ•°
        now = datetime.now(self.tz)
        one_hour_ago = now - timedelta(hours=1)

        # æ¸…ç†1å°æ—¶å‰çš„è®°å½•
        while self._tushare_call_times and self._tushare_call_times[0] < one_hour_ago:
            self._tushare_call_times.popleft()

        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        if len(self._tushare_call_times) >= self._tushare_hourly_limit:
            logger.warning(
                f"âš ï¸ Tushare rt_k æ¥å£å·²è¾¾åˆ°æ¯å°æ—¶è°ƒç”¨é™åˆ¶ ({self._tushare_hourly_limit}æ¬¡)ï¼Œ"
                f"è·³è¿‡æœ¬æ¬¡è°ƒç”¨ï¼Œä½¿ç”¨ AKShare å¤‡ç”¨æ¥å£"
            )
            return False

        return True

    def _record_tushare_call(self) -> None:
        """è®°å½• Tushare è°ƒç”¨æ—¶é—´"""
        self._tushare_call_times.append(datetime.now(self.tz))

    def _get_next_source(self) -> Tuple[str, Optional[str]]:
        """
        è·å–ä¸‹ä¸€ä¸ªæ•°æ®æºï¼ˆè½®æ¢æœºåˆ¶ï¼‰

        Returns:
            (source_type, akshare_api):
                - source_type: "tushare" | "akshare"
                - akshare_api: "eastmoney" | "sina" (ä»…å½“ source_type="akshare" æ—¶æœ‰æ•ˆ)
        """
        if not settings.QUOTES_ROTATION_ENABLED:
            # æœªå¯ç”¨è½®æ¢ï¼Œä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§
            return "tushare", None

        # è½®æ¢é€»è¾‘ï¼š0=Tushare, 1=AKShareä¸œæ–¹è´¢å¯Œ, 2=AKShareæ–°æµªè´¢ç»
        current_source = self._rotation_sources[self._rotation_index]

        # æ›´æ–°è½®æ¢ç´¢å¼•ï¼ˆä¸‹æ¬¡ä½¿ç”¨ä¸‹ä¸€ä¸ªæ¥å£ï¼‰
        self._rotation_index = (self._rotation_index + 1) % len(self._rotation_sources)

        if current_source == "tushare":
            return "tushare", None
        elif current_source == "akshare_eastmoney":
            return "akshare", "eastmoney"
        else:  # akshare_sina
            return "akshare", "sina"

    def _is_trading_time(self, now: Optional[datetime] = None) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´æˆ–æ”¶ç›˜åç¼“å†²æœŸ

        äº¤æ˜“æ—¶é—´ï¼š
        - ä¸Šåˆï¼š9:30-11:30
        - ä¸‹åˆï¼š13:00-15:00
        - æ”¶ç›˜åç¼“å†²æœŸï¼š15:00-15:30ï¼ˆç¡®ä¿è·å–åˆ°æ”¶ç›˜ä»·ï¼‰

        æ”¶ç›˜åç¼“å†²æœŸè¯´æ˜ï¼š
        - äº¤æ˜“æ—¶é—´ç»“æŸåç»§ç»­è·å–30åˆ†é’Ÿ
        - å‡è®¾6åˆ†é’Ÿä¸€æ¬¡ï¼Œå¯ä»¥å¢åŠ 3æ¬¡åŒæ­¥æœºä¼šï¼ˆ15:06, 15:12, 15:18ï¼‰
        - å¤§å¤§é™ä½é”™è¿‡æ”¶ç›˜ä»·çš„é£é™©
        """
        now = now or datetime.now(self.tz)
        # å·¥ä½œæ—¥ Mon-Fri
        if now.weekday() > 4:
            return False
        t = now.time()
        # ä¸Šäº¤æ‰€/æ·±äº¤æ‰€å¸¸è§„äº¤æ˜“æ—¶æ®µ
        morning = dtime(9, 30)
        noon = dtime(11, 30)
        afternoon_start = dtime(13, 0)
        # æ”¶ç›˜åç¼“å†²æœŸï¼ˆå»¶é•¿30åˆ†é’Ÿåˆ°15:30ï¼‰
        buffer_end = dtime(15, 30)

        return (morning <= t <= noon) or (afternoon_start <= t <= buffer_end)

    async def _collection_empty(self) -> bool:
        db = get_mongo_db()
        coll = db[self.collection_name]
        try:
            count = await coll.estimated_document_count()
            return count == 0
        except Exception:
            return True

    async def _collection_stale(self, latest_trade_date: Optional[str]) -> bool:
        if not latest_trade_date:
            return False
        db = get_mongo_db()
        coll = db[self.collection_name]
        try:
            cursor = coll.find({}, {"trade_date": 1}).sort("trade_date", -1).limit(1)
            docs = await cursor.to_list(length=1)
            if not docs:
                return True
            doc_td = str(docs[0].get("trade_date") or "")
            return doc_td < str(latest_trade_date)
        except Exception:
            return True

    async def _bulk_upsert(self, quotes_map: Dict[str, Dict], trade_date: str, source: Optional[str] = None) -> None:
        db = get_mongo_db()
        coll = db[self.collection_name]
        ops = []
        updated_at = datetime.now(self.tz)
        for code, q in quotes_map.items():
            if not code:
                continue
            # ä½¿ç”¨æ ‡å‡†åŒ–æ–¹æ³•å¤„ç†è‚¡ç¥¨ä»£ç ï¼ˆå»æ‰äº¤æ˜“æ‰€å‰ç¼€ï¼Œå¦‚ sz000001 -> 000001ï¼‰
            code6 = self._normalize_stock_code(code)
            if not code6:
                continue

            # ğŸ”¥ æ—¥å¿—ï¼šè®°å½•å†™å…¥çš„æˆäº¤é‡å€¼
            volume = q.get("volume")
            if code6 in ["300750", "000001", "600000"]:  # åªè®°å½•å‡ ä¸ªç¤ºä¾‹è‚¡ç¥¨
                logger.info(f"ğŸ“Š [å†™å…¥market_quotes] {code6} - volume={volume}, amount={q.get('amount')}, source={source}")

            ops.append(
                UpdateOne(
                    {"code": code6},
                    {"$set": {
                        "code": code6,
                        "symbol": code6,  # æ·»åŠ  symbol å­—æ®µï¼Œä¸ code ä¿æŒä¸€è‡´
                        "close": q.get("close"),
                        "pct_chg": q.get("pct_chg"),
                        "amount": q.get("amount"),
                        "volume": volume,
                        "open": q.get("open"),
                        "high": q.get("high"),
                        "low": q.get("low"),
                        "pre_close": q.get("pre_close"),
                        "trade_date": trade_date,
                        "updated_at": updated_at,
                    }},
                    upsert=True,
                )
            )
        if not ops:
            logger.info("æ— å¯å†™å…¥çš„æ•°æ®ï¼Œè·³è¿‡")
            return
        result = await coll.bulk_write(ops, ordered=False)
        logger.info(
            f"âœ… è¡Œæƒ…å…¥åº“å®Œæˆ source={source}, matched={result.matched_count}, upserted={len(result.upserted_ids) if result.upserted_ids else 0}, modified={result.modified_count}"
        )

    async def backfill_from_historical_data(self) -> None:
        """
        ä»å†å²æ•°æ®é›†åˆå¯¼å…¥å‰ä¸€å¤©çš„æ”¶ç›˜æ•°æ®åˆ° market_quotes
        - å¦‚æœ market_quotes é›†åˆä¸ºç©ºï¼Œå¯¼å…¥æ‰€æœ‰æ•°æ®
        - å¦‚æœ market_quotes é›†åˆä¸ä¸ºç©ºï¼Œæ£€æŸ¥å¹¶ä¿®å¤ç¼ºå¤±çš„æˆäº¤é‡å­—æ®µ
        """
        try:
            # æ£€æŸ¥ market_quotes æ˜¯å¦ä¸ºç©º
            is_empty = await self._collection_empty()

            if not is_empty:
                # é›†åˆä¸ä¸ºç©ºï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æˆäº¤é‡ç¼ºå¤±çš„è®°å½•
                logger.info("âœ… market_quotes é›†åˆä¸ä¸ºç©ºï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦ä¿®å¤æˆäº¤é‡...")
                await self._fix_missing_volume()
                return

            logger.info("ğŸ“Š market_quotes é›†åˆä¸ºç©ºï¼Œå¼€å§‹ä»å†å²æ•°æ®å¯¼å…¥")

            db = get_mongo_db()
            manager = DataSourceManager()

            # è·å–æœ€æ–°äº¤æ˜“æ—¥
            try:
                latest_trade_date = manager.find_latest_trade_date_with_fallback()
                if not latest_trade_date:
                    logger.warning("âš ï¸ æ— æ³•è·å–æœ€æ–°äº¤æ˜“æ—¥ï¼Œè·³è¿‡å†å²æ•°æ®å¯¼å…¥")
                    return
            except Exception as e:
                logger.warning(f"âš ï¸ è·å–æœ€æ–°äº¤æ˜“æ—¥å¤±è´¥: {e}ï¼Œè·³è¿‡å†å²æ•°æ®å¯¼å…¥")
                return

            logger.info(f"ğŸ“Š ä»å†å²æ•°æ®é›†åˆå¯¼å…¥ {latest_trade_date} çš„æ”¶ç›˜æ•°æ®åˆ° market_quotes")

            # ä» stock_daily_quotes é›†åˆæŸ¥è¯¢æœ€æ–°äº¤æ˜“æ—¥çš„æ•°æ®
            daily_quotes_collection = db["stock_daily_quotes"]
            cursor = daily_quotes_collection.find({
                "trade_date": latest_trade_date,
                "period": "daily"
            })

            docs = await cursor.to_list(length=None)

            if not docs:
                logger.warning(f"âš ï¸ å†å²æ•°æ®é›†åˆä¸­æœªæ‰¾åˆ° {latest_trade_date} çš„æ•°æ®")
                logger.warning("âš ï¸ market_quotes å’Œå†å²æ•°æ®é›†åˆéƒ½ä¸ºç©ºï¼Œè¯·å…ˆåŒæ­¥å†å²æ•°æ®æˆ–å®æ—¶è¡Œæƒ…")
                return

            logger.info(f"âœ… ä»å†å²æ•°æ®é›†åˆæ‰¾åˆ° {len(docs)} æ¡è®°å½•")

            # è½¬æ¢ä¸º quotes_map æ ¼å¼
            quotes_map = {}
            for doc in docs:
                code = doc.get("symbol") or doc.get("code")
                if not code:
                    continue
                code6 = str(code).zfill(6)

                # ğŸ”¥ è·å–æˆäº¤é‡ï¼Œä¼˜å…ˆä½¿ç”¨ volume å­—æ®µ
                volume_value = doc.get("volume") or doc.get("vol")
                data_source = doc.get("data_source", "")

                # ğŸ”¥ æ—¥å¿—ï¼šè®°å½•åŸå§‹æˆäº¤é‡å€¼
                if code6 in ["300750", "000001", "600000"]:  # åªè®°å½•å‡ ä¸ªç¤ºä¾‹è‚¡ç¥¨
                    logger.info(f"ğŸ“Š [å›å¡«] {code6} - volume={doc.get('volume')}, vol={doc.get('vol')}, data_source={data_source}")

                quotes_map[code6] = {
                    "close": doc.get("close"),
                    "pct_chg": doc.get("pct_chg"),
                    "amount": doc.get("amount"),
                    "volume": volume_value,
                    "open": doc.get("open"),
                    "high": doc.get("high"),
                    "low": doc.get("low"),
                    "pre_close": doc.get("pre_close"),
                }

            if quotes_map:
                await self._bulk_upsert(quotes_map, latest_trade_date, "historical_data")
                logger.info(f"âœ… æˆåŠŸä»å†å²æ•°æ®å¯¼å…¥ {len(quotes_map)} æ¡æ”¶ç›˜æ•°æ®åˆ° market_quotes")
            else:
                logger.warning("âš ï¸ å†å²æ•°æ®è½¬æ¢åä¸ºç©ºï¼Œæ— æ³•å¯¼å…¥")

        except Exception as e:
            logger.error(f"âŒ ä»å†å²æ•°æ®å¯¼å…¥å¤±è´¥: {e}")
            import traceback
            logger.error(f"å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")

    async def backfill_last_close_snapshot(self) -> None:
        """ä¸€æ¬¡æ€§è¡¥é½ä¸Šä¸€ç¬”æ”¶ç›˜å¿«ç…§ï¼ˆç”¨äºå†·å¯åŠ¨æˆ–æ•°æ®é™ˆæ—§ï¼‰ã€‚å…è®¸åœ¨ä¼‘å¸‚æœŸè°ƒç”¨ã€‚"""
        try:
            manager = DataSourceManager()
            # ä½¿ç”¨è¿‘å®æ—¶å¿«ç…§ä½œä¸ºå…œåº•ï¼Œä¼‘å¸‚æœŸè¿”å›çš„å³ä¸ºæœ€åæ”¶ç›˜æ•°æ®
            quotes_map, source = manager.get_realtime_quotes_with_fallback()
            if not quotes_map:
                logger.warning("backfill: æœªè·å–åˆ°è¡Œæƒ…æ•°æ®ï¼Œè·³è¿‡")
                return
            try:
                trade_date = manager.find_latest_trade_date_with_fallback() or datetime.now(self.tz).strftime("%Y%m%d")
            except Exception:
                trade_date = datetime.now(self.tz).strftime("%Y%m%d")
            await self._bulk_upsert(quotes_map, trade_date, source)
        except Exception as e:
            logger.error(f"âŒ backfill è¡Œæƒ…è¡¥æ•°å¤±è´¥: {e}")

    async def backfill_last_close_snapshot_if_needed(self) -> None:
        """è‹¥é›†åˆä¸ºç©ºæˆ– trade_date è½åäºæœ€æ–°äº¤æ˜“æ—¥ï¼Œåˆ™æ‰§è¡Œä¸€æ¬¡ backfill"""
        try:
            is_empty = await self._collection_empty()

            # å¦‚æœé›†åˆä¸ºç©ºï¼Œä¼˜å…ˆä»å†å²æ•°æ®å¯¼å…¥
            if is_empty:
                logger.info("ğŸ” market_quotes é›†åˆä¸ºç©ºï¼Œå°è¯•ä»å†å²æ•°æ®å¯¼å…¥")
                await self.backfill_from_historical_data()
                return

            # å¦‚æœé›†åˆä¸ä¸ºç©ºä½†æ•°æ®é™ˆæ—§ï¼Œä½¿ç”¨å®æ—¶æ¥å£æ›´æ–°
            manager = DataSourceManager()
            latest_td = manager.find_latest_trade_date_with_fallback()
            if await self._collection_stale(latest_td):
                logger.info("ğŸ” è§¦å‘ä¼‘å¸‚æœŸ/å¯åŠ¨æœŸ backfill ä»¥å¡«å……æœ€æ–°æ”¶ç›˜æ•°æ®")
                await self.backfill_last_close_snapshot()
        except Exception as e:
            logger.warning(f"backfill è§¦å‘æ£€æŸ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼‰: {e}")

    def _fetch_quotes_from_source(self, source_type: str, akshare_api: Optional[str] = None) -> Tuple[Optional[Dict], Optional[str]]:
        """
        ä»æŒ‡å®šæ•°æ®æºè·å–è¡Œæƒ…

        Args:
            source_type: "tushare" | "akshare"
            akshare_api: "eastmoney" | "sina" (ä»…å½“ source_type="akshare" æ—¶æœ‰æ•ˆ)

        Returns:
            (quotes_map, source_name)
        """
        try:
            if source_type == "tushare":
                # æ£€æŸ¥æ˜¯å¦å¯ä»¥è°ƒç”¨ Tushare
                if not self._can_call_tushare():
                    return None, None

                from app.services.data_sources.tushare_adapter import TushareAdapter
                adapter = TushareAdapter()

                if not adapter.is_available():
                    logger.warning("Tushare ä¸å¯ç”¨")
                    return None, None

                logger.info("ğŸ“Š ä½¿ç”¨ Tushare rt_k æ¥å£è·å–å®æ—¶è¡Œæƒ…")
                quotes_map = adapter.get_realtime_quotes()

                if quotes_map:
                    self._record_tushare_call()
                    return quotes_map, "tushare"
                else:
                    logger.warning("Tushare rt_k è¿”å›ç©ºæ•°æ®")
                    return None, None

            elif source_type == "akshare":
                from app.services.data_sources.akshare_adapter import AKShareAdapter
                adapter = AKShareAdapter()

                if not adapter.is_available():
                    logger.warning("AKShare ä¸å¯ç”¨")
                    return None, None

                api_name = akshare_api or "eastmoney"
                logger.info(f"ğŸ“Š ä½¿ç”¨ AKShare {api_name} æ¥å£è·å–å®æ—¶è¡Œæƒ…")
                quotes_map = adapter.get_realtime_quotes(source=api_name)

                if quotes_map:
                    return quotes_map, f"akshare_{api_name}"
                else:
                    logger.warning(f"AKShare {api_name} è¿”å›ç©ºæ•°æ®")
                    return None, None

            else:
                logger.error(f"æœªçŸ¥æ•°æ®æºç±»å‹: {source_type}")
                return None, None

        except Exception as e:
            logger.error(f"ä» {source_type} è·å–è¡Œæƒ…å¤±è´¥: {e}")
            return None, None

    async def run_once(self) -> None:
        """
        æ‰§è¡Œä¸€æ¬¡é‡‡é›†ä¸å…¥åº“

        æ ¸å¿ƒé€»è¾‘ï¼š
        1. æ£€æµ‹ Tushare æƒé™ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
        2. æŒ‰è½®æ¢é¡ºåºå°è¯•è·å–è¡Œæƒ…ï¼šTushare â†’ AKShareä¸œæ–¹è´¢å¯Œ â†’ AKShareæ–°æµªè´¢ç»
        3. ä»»æ„ä¸€ä¸ªæ¥å£æˆåŠŸå³å…¥åº“ï¼Œå¤±è´¥åˆ™è·³è¿‡æœ¬æ¬¡é‡‡é›†
        """
        # éäº¤æ˜“æ—¶æ®µå¤„ç†
        if not self._is_trading_time():
            if settings.QUOTES_BACKFILL_ON_OFFHOURS:
                await self.backfill_last_close_snapshot_if_needed()
            else:
                logger.info("â­ï¸ éäº¤æ˜“æ—¶æ®µï¼Œè·³è¿‡è¡Œæƒ…é‡‡é›†")
            return

        try:
            # é¦–æ¬¡è¿è¡Œï¼šæ£€æµ‹ Tushare æƒé™
            if settings.QUOTES_AUTO_DETECT_TUSHARE_PERMISSION and not self._tushare_permission_checked:
                logger.info("ğŸ” é¦–æ¬¡è¿è¡Œï¼Œæ£€æµ‹ Tushare rt_k æ¥å£æƒé™...")
                has_premium = self._check_tushare_permission()

                if has_premium:
                    logger.info(
                        "âœ… æ£€æµ‹åˆ° Tushare ä»˜è´¹æƒé™ï¼å»ºè®®å°† QUOTES_INGEST_INTERVAL_SECONDS è®¾ç½®ä¸º 5-60 ç§’ä»¥å……åˆ†åˆ©ç”¨æƒé™"
                    )
                else:
                    logger.info(
                        f"â„¹ï¸ Tushare å…è´¹ç”¨æˆ·ï¼Œæ¯å°æ—¶æœ€å¤šè°ƒç”¨ {self._tushare_hourly_limit} æ¬¡ rt_k æ¥å£ã€‚"
                        f"å½“å‰é‡‡é›†é—´éš”: {settings.QUOTES_INGEST_INTERVAL_SECONDS} ç§’"
                    )

            # è·å–ä¸‹ä¸€ä¸ªæ•°æ®æº
            source_type, akshare_api = self._get_next_source()

            # å°è¯•è·å–è¡Œæƒ…
            quotes_map, source_name = self._fetch_quotes_from_source(source_type, akshare_api)

            if not quotes_map:
                logger.warning(f"âš ï¸ {source_name or source_type} æœªè·å–åˆ°è¡Œæƒ…æ•°æ®ï¼Œè·³è¿‡æœ¬æ¬¡å…¥åº“")
                # è®°å½•å¤±è´¥çŠ¶æ€
                await self._record_sync_status(
                    success=False,
                    source=source_name or source_type,
                    records_count=0,
                    error_msg="æœªè·å–åˆ°è¡Œæƒ…æ•°æ®"
                )
                return

            # è·å–äº¤æ˜“æ—¥
            try:
                manager = DataSourceManager()
                trade_date = manager.find_latest_trade_date_with_fallback() or datetime.now(self.tz).strftime("%Y%m%d")
            except Exception:
                trade_date = datetime.now(self.tz).strftime("%Y%m%d")

            # å…¥åº“
            await self._bulk_upsert(quotes_map, trade_date, source_name)

            # è®°å½•æˆåŠŸçŠ¶æ€
            await self._record_sync_status(
                success=True,
                source=source_name,
                records_count=len(quotes_map),
                error_msg=None
            )

        except Exception as e:
            logger.error(f"âŒ è¡Œæƒ…å…¥åº“å¤±è´¥: {e}")
            # è®°å½•å¤±è´¥çŠ¶æ€
            await self._record_sync_status(
                success=False,
                source=None,
                records_count=0,
                error_msg=str(e)
            )

