#!/usr/bin/env python3
"""
ç»Ÿä¸€å†å²æ•°æ®ç®¡ç†æœåŠ¡
ä¸ºä¸‰æ•°æ®æºæä¾›ç»Ÿä¸€çš„å†å²æ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢æ¥å£
"""
import asyncio
import logging
from datetime import datetime, date
from typing import Dict, Any, List, Optional, Union
import pandas as pd
from motor.motor_asyncio import AsyncIOMotorDatabase

from app.core.database import get_database

logger = logging.getLogger(__name__)


class HistoricalDataService:
    """ç»Ÿä¸€å†å²æ•°æ®ç®¡ç†æœåŠ¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        self.db = None
        self.collection = None
        
    async def initialize(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        try:
            self.db = get_database()
            self.collection = self.db.stock_daily_quotes

            # ğŸ”¥ ç¡®ä¿ç´¢å¼•å­˜åœ¨ï¼ˆæå‡æŸ¥è¯¢å’Œ upsert æ€§èƒ½ï¼‰
            await self._ensure_indexes()

            logger.info("âœ… å†å²æ•°æ®æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ å†å²æ•°æ®æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    async def _ensure_indexes(self):
        """ç¡®ä¿å¿…è¦çš„ç´¢å¼•å­˜åœ¨"""
        try:
            logger.info("ğŸ“Š æ£€æŸ¥å¹¶åˆ›å»ºå†å²æ•°æ®ç´¢å¼•...")

            # 1. å¤åˆå”¯ä¸€ç´¢å¼•ï¼šè‚¡ç¥¨ä»£ç +äº¤æ˜“æ—¥æœŸ+æ•°æ®æº+å‘¨æœŸï¼ˆç”¨äº upsertï¼‰
            await self.collection.create_index([
                ("symbol", 1),
                ("trade_date", 1),
                ("data_source", 1),
                ("period", 1)
            ], unique=True, name="symbol_date_source_period_unique", background=True)

            # 2. è‚¡ç¥¨ä»£ç ç´¢å¼•ï¼ˆæŸ¥è¯¢å•åªè‚¡ç¥¨çš„å†å²æ•°æ®ï¼‰
            await self.collection.create_index([("symbol", 1)], name="symbol_index", background=True)

            # 3. äº¤æ˜“æ—¥æœŸç´¢å¼•ï¼ˆæŒ‰æ—¥æœŸèŒƒå›´æŸ¥è¯¢ï¼‰
            await self.collection.create_index([("trade_date", -1)], name="trade_date_index", background=True)

            # 4. å¤åˆç´¢å¼•ï¼šè‚¡ç¥¨ä»£ç +äº¤æ˜“æ—¥æœŸï¼ˆå¸¸ç”¨æŸ¥è¯¢ï¼‰
            await self.collection.create_index([
                ("symbol", 1),
                ("trade_date", -1)
            ], name="symbol_date_index", background=True)

            logger.info("âœ… å†å²æ•°æ®ç´¢å¼•æ£€æŸ¥å®Œæˆ")
        except Exception as e:
            # ç´¢å¼•åˆ›å»ºå¤±è´¥ä¸åº”è¯¥é˜»æ­¢æœåŠ¡å¯åŠ¨
            logger.warning(f"âš ï¸ åˆ›å»ºç´¢å¼•æ—¶å‡ºç°è­¦å‘Šï¼ˆå¯èƒ½å·²å­˜åœ¨ï¼‰: {e}")
    
    async def save_historical_data(
        self,
        symbol: str,
        data: pd.DataFrame,
        data_source: str,
        market: str = "CN",
        period: str = "daily"
    ) -> int:
        """
        ä¿å­˜å†å²æ•°æ®åˆ°æ•°æ®åº“

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data: å†å²æ•°æ®DataFrame
            data_source: æ•°æ®æº (tushare/akshare/baostock)
            market: å¸‚åœºç±»å‹ (CN/HK/US)
            period: æ•°æ®å‘¨æœŸ (daily/weekly/monthly)

        Returns:
            ä¿å­˜çš„è®°å½•æ•°é‡
        """
        if self.collection is None:
            await self.initialize()
        
        try:
            if data is None or data.empty:
                logger.warning(f"âš ï¸ {symbol} å†å²æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜")
                return 0

            from datetime import datetime
            total_start = datetime.now()

            logger.info(f"ğŸ’¾ å¼€å§‹ä¿å­˜ {symbol} å†å²æ•°æ®: {len(data)}æ¡è®°å½• (æ•°æ®æº: {data_source})")

            # â±ï¸ æ€§èƒ½ç›‘æ§ï¼šå•ä½è½¬æ¢
            convert_start = datetime.now()
            # ğŸ”¥ åœ¨ DataFrame å±‚é¢åšå•ä½è½¬æ¢ï¼ˆå‘é‡åŒ–æ“ä½œï¼Œæ¯”é€è¡Œå¿«å¾—å¤šï¼‰
            if data_source == "tushare":
                # æˆäº¤é¢ï¼šåƒå…ƒ -> å…ƒ
                if 'amount' in data.columns:
                    data['amount'] = data['amount'] * 1000
                elif 'turnover' in data.columns:
                    data['turnover'] = data['turnover'] * 1000

                # æˆäº¤é‡ï¼šæ‰‹ -> è‚¡
                if 'volume' in data.columns:
                    data['volume'] = data['volume'] * 100
                elif 'vol' in data.columns:
                    data['vol'] = data['vol'] * 100

            # ğŸ”¥ æ¸¯è‚¡/ç¾è‚¡æ•°æ®ï¼šæ·»åŠ  pre_close å­—æ®µï¼ˆä»å‰ä¸€å¤©çš„ close è·å–ï¼‰
            if market in ["HK", "US"] and 'pre_close' not in data.columns and 'close' in data.columns:
                # ä½¿ç”¨ shift(1) å°† close åˆ—å‘ä¸‹ç§»åŠ¨ä¸€è¡Œï¼Œå¾—åˆ°å‰ä¸€å¤©çš„æ”¶ç›˜ä»·
                data['pre_close'] = data['close'].shift(1)
                logger.debug(f"âœ… {symbol} æ·»åŠ  pre_close å­—æ®µï¼ˆä»å‰ä¸€å¤©çš„ close è·å–ï¼‰")

            convert_duration = (datetime.now() - convert_start).total_seconds()

            # â±ï¸ æ€§èƒ½ç›‘æ§ï¼šæ„å»ºæ“ä½œåˆ—è¡¨
            prepare_start = datetime.now()
            # å‡†å¤‡æ‰¹é‡æ“ä½œ
            operations = []
            saved_count = 0
            batch_size = 200  # è¿›ä¸€æ­¥å‡å°æ‰¹é‡å¤§å°ï¼Œé¿å…è¶…æ—¶ï¼ˆä»500æ”¹ä¸º200ï¼‰

            for date_index, row in data.iterrows():
                try:
                    # æ ‡å‡†åŒ–æ•°æ®ï¼ˆä¼ é€’æ—¥æœŸç´¢å¼•ï¼‰
                    doc = self._standardize_record(symbol, row, data_source, market, period, date_index)

                    # åˆ›å»ºupsertæ“ä½œ
                    filter_doc = {
                        "symbol": doc["symbol"],
                        "trade_date": doc["trade_date"],
                        "data_source": doc["data_source"],
                        "period": doc["period"]
                    }

                    from pymongo import ReplaceOne
                    operations.append(ReplaceOne(
                        filter=filter_doc,
                        replacement=doc,
                        upsert=True
                    ))

                    # æ‰¹é‡æ‰§è¡Œï¼ˆæ¯200æ¡ï¼‰
                    if len(operations) >= batch_size:
                        batch_write_start = datetime.now()
                        batch_saved = await self._execute_bulk_write_with_retry(symbol, operations)
                        batch_write_duration = (datetime.now() - batch_write_start).total_seconds()
                        logger.debug(f"   æ‰¹é‡å†™å…¥ {len(operations)} æ¡ï¼Œè€—æ—¶ {batch_write_duration:.2f}ç§’")
                        saved_count += batch_saved
                        operations = []

                except Exception as e:
                    # è·å–æ—¥æœŸä¿¡æ¯ç”¨äºé”™è¯¯æ—¥å¿—
                    date_str = str(date_index) if hasattr(date_index, '__str__') else 'unknown'
                    logger.error(f"âŒ å¤„ç†è®°å½•å¤±è´¥ {symbol} {date_str}: {e}")
                    continue

            prepare_duration = (datetime.now() - prepare_start).total_seconds()

            # â±ï¸ æ€§èƒ½ç›‘æ§ï¼šæœ€åä¸€æ‰¹å†™å…¥
            final_write_start = datetime.now()
            # æ‰§è¡Œå‰©ä½™æ“ä½œ
            if operations:
                saved_count += await self._execute_bulk_write_with_retry(
                    symbol, operations
                )
            final_write_duration = (datetime.now() - final_write_start).total_seconds()

            total_duration = (datetime.now() - total_start).total_seconds()
            logger.info(
                f"âœ… {symbol} å†å²æ•°æ®ä¿å­˜å®Œæˆ: {saved_count}æ¡è®°å½•ï¼Œ"
                f"æ€»è€—æ—¶ {total_duration:.2f}ç§’ "
                f"(è½¬æ¢: {convert_duration:.3f}ç§’, å‡†å¤‡: {prepare_duration:.2f}ç§’, æœ€åå†™å…¥: {final_write_duration:.2f}ç§’)"
            )
            return saved_count
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å†å²æ•°æ®å¤±è´¥ {symbol}: {e}")
            return 0

    async def _execute_bulk_write_with_retry(
        self,
        symbol: str,
        operations: List,
        max_retries: int = 5  # å¢åŠ é‡è¯•æ¬¡æ•°ï¼šä»3æ¬¡æ”¹ä¸º5æ¬¡
    ) -> int:
        """
        æ‰§è¡Œæ‰¹é‡å†™å…¥ï¼Œå¸¦é‡è¯•æœºåˆ¶

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            operations: æ‰¹é‡æ“ä½œåˆ—è¡¨
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

        Returns:
            æˆåŠŸä¿å­˜çš„è®°å½•æ•°
        """
        saved_count = 0
        retry_count = 0

        while retry_count < max_retries:
            try:
                result = await self.collection.bulk_write(operations, ordered=False)
                saved_count = result.upserted_count + result.modified_count
                logger.debug(f"âœ… {symbol} æ‰¹é‡ä¿å­˜ {len(operations)} æ¡è®°å½•æˆåŠŸ (æ–°å¢: {result.upserted_count}, æ›´æ–°: {result.modified_count})")
                return saved_count

            except asyncio.TimeoutError as e:
                retry_count += 1
                if retry_count < max_retries:
                    wait_time = 3 ** retry_count  # æ›´é•¿çš„æŒ‡æ•°é€€é¿ï¼š3ç§’ã€9ç§’ã€27ç§’ã€81ç§’
                    logger.warning(f"âš ï¸ {symbol} æ‰¹é‡å†™å…¥è¶…æ—¶ (ç¬¬{retry_count}/{max_retries}æ¬¡é‡è¯•)ï¼Œç­‰å¾…{wait_time}ç§’åé‡è¯•...")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"âŒ {symbol} æ‰¹é‡å†™å…¥å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡: {e}")
                    return 0

            except Exception as e:
                # æ£€æŸ¥æ˜¯å¦æ˜¯è¶…æ—¶ç›¸å…³çš„é”™è¯¯
                error_msg = str(e).lower()
                if 'timeout' in error_msg or 'timed out' in error_msg:
                    retry_count += 1
                    if retry_count < max_retries:
                        wait_time = 3 ** retry_count
                        logger.warning(f"âš ï¸ {symbol} æ‰¹é‡å†™å…¥è¶…æ—¶ (ç¬¬{retry_count}/{max_retries}æ¬¡é‡è¯•)ï¼Œç­‰å¾…{wait_time}ç§’åé‡è¯•... é”™è¯¯: {e}")
                        await asyncio.sleep(wait_time)
                    else:
                        logger.error(f"âŒ {symbol} æ‰¹é‡å†™å…¥å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡: {e}")
                        return 0
                else:
                    logger.error(f"âŒ {symbol} æ‰¹é‡å†™å…¥å¤±è´¥: {e}")
                    return 0

        return saved_count

    def _standardize_record(
        self,
        symbol: str,
        row: pd.Series,
        data_source: str,
        market: str,
        period: str = "daily",
        date_index = None
    ) -> Dict[str, Any]:
        """æ ‡å‡†åŒ–å•æ¡è®°å½•"""
        now = datetime.utcnow()

        # è·å–æ—¥æœŸ - ä¼˜å…ˆä»åˆ—ä¸­è·å–ï¼Œå¦‚æœç´¢å¼•æ˜¯æ—¥æœŸç±»å‹æ‰ä½¿ç”¨ç´¢å¼•
        trade_date = None

        # å…ˆå°è¯•ä»åˆ—ä¸­è·å–æ—¥æœŸ
        date_from_column = row.get('date') or row.get('trade_date')

        # å¦‚æœåˆ—ä¸­æœ‰æ—¥æœŸï¼Œä¼˜å…ˆä½¿ç”¨åˆ—ä¸­çš„æ—¥æœŸ
        if date_from_column is not None:
            trade_date = self._format_date(date_from_column)
        # å¦‚æœåˆ—ä¸­æ²¡æœ‰æ—¥æœŸï¼Œä¸”ç´¢å¼•æ˜¯æ—¥æœŸç±»å‹ï¼Œæ‰ä½¿ç”¨ç´¢å¼•
        elif date_index is not None and isinstance(date_index, (date, datetime, pd.Timestamp)):
            trade_date = self._format_date(date_index)
        # å¦åˆ™ä½¿ç”¨å½“å‰æ—¥æœŸ
        else:
            trade_date = self._format_date(None)

        # åŸºç¡€å­—æ®µæ˜ å°„
        doc = {
            "symbol": symbol,
            "code": symbol,  # æ·»åŠ  code å­—æ®µï¼Œä¸ symbol ä¿æŒä¸€è‡´ï¼ˆå‘åå…¼å®¹ï¼‰
            "full_symbol": self._get_full_symbol(symbol, market),
            "market": market,
            "trade_date": trade_date,
            "period": period,
            "data_source": data_source,
            "created_at": now,
            "updated_at": now,
            "version": 1
        }
        
        # OHLCVæ•°æ®ï¼ˆå•ä½è½¬æ¢å·²åœ¨ DataFrame å±‚é¢å®Œæˆï¼‰
        amount_value = self._safe_float(row.get('amount') or row.get('turnover'))
        volume_value = self._safe_float(row.get('volume') or row.get('vol'))

        doc.update({
            "open": self._safe_float(row.get('open')),
            "high": self._safe_float(row.get('high')),
            "low": self._safe_float(row.get('low')),
            "close": self._safe_float(row.get('close')),
            "pre_close": self._safe_float(row.get('pre_close') or row.get('preclose')),
            "volume": volume_value,
            "amount": amount_value
        })
        
        # è®¡ç®—æ¶¨è·Œæ•°æ®
        if doc["close"] and doc["pre_close"]:
            doc["change"] = round(doc["close"] - doc["pre_close"], 4)
            doc["pct_chg"] = round((doc["change"] / doc["pre_close"]) * 100, 4)
        else:
            doc["change"] = self._safe_float(row.get('change'))
            doc["pct_chg"] = self._safe_float(row.get('pct_chg') or row.get('change_percent'))
        
        # å¯é€‰å­—æ®µ
        optional_fields = {
            "turnover_rate": row.get('turnover_rate') or row.get('turn'),
            "volume_ratio": row.get('volume_ratio'),
            "pe": row.get('pe'),
            "pb": row.get('pb'),
            "ps": row.get('ps'),
            "adjustflag": row.get('adjustflag') or row.get('adj_factor'),
            "tradestatus": row.get('tradestatus'),
            "isST": row.get('isST')
        }
        
        for key, value in optional_fields.items():
            if value is not None:
                doc[key] = self._safe_float(value)
        
        return doc
    
    def _get_full_symbol(self, symbol: str, market: str) -> str:
        """ç”Ÿæˆå®Œæ•´è‚¡ç¥¨ä»£ç """
        if market == "CN":
            if symbol.startswith('6'):
                return f"{symbol}.SH"
            elif symbol.startswith(('0', '3')):
                return f"{symbol}.SZ"
            else:
                return f"{symbol}.SZ"  # é»˜è®¤æ·±åœ³
        elif market == "HK":
            return f"{symbol}.HK"
        elif market == "US":
            return symbol
        else:
            return symbol
    
    def _format_date(self, date_value) -> str:
        """æ ¼å¼åŒ–æ—¥æœŸ"""
        if date_value is None:
            return datetime.now().strftime('%Y-%m-%d')
        
        if isinstance(date_value, str):
            # å¤„ç†ä¸åŒçš„æ—¥æœŸæ ¼å¼
            if len(date_value) == 8:  # YYYYMMDD
                return f"{date_value[:4]}-{date_value[4:6]}-{date_value[6:8]}"
            elif len(date_value) == 10:  # YYYY-MM-DD
                return date_value
            else:
                return date_value
        elif isinstance(date_value, (date, datetime)):
            return date_value.strftime('%Y-%m-%d')
        else:
            return str(date_value)
    
    def _safe_float(self, value) -> Optional[float]:
        """å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•°"""
        if value is None or value == '' or pd.isna(value):
            return None
        try:
            return float(value)
        except (ValueError, TypeError):
            return None
    
    async def get_historical_data(
        self,
        symbol: str,
        start_date: str = None,
        end_date: str = None,
        data_source: str = None,
        period: str = None,
        limit: int = None
    ) -> List[Dict[str, Any]]:
        """
        æŸ¥è¯¢å†å²æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            data_source: æ•°æ®æºç­›é€‰
            period: æ•°æ®å‘¨æœŸç­›é€‰ (daily/weekly/monthly)
            limit: é™åˆ¶è¿”å›æ•°é‡

        Returns:
            å†å²æ•°æ®åˆ—è¡¨
        """
        if self.collection is None:
            await self.initialize()
        
        try:
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query = {"symbol": symbol}
            
            if start_date or end_date:
                date_filter = {}
                if start_date:
                    date_filter["$gte"] = start_date
                if end_date:
                    date_filter["$lte"] = end_date
                query["trade_date"] = date_filter
            
            if data_source:
                query["data_source"] = data_source

            if period:
                query["period"] = period
            
            # æ‰§è¡ŒæŸ¥è¯¢
            cursor = self.collection.find(query).sort("trade_date", -1)
            
            if limit:
                cursor = cursor.limit(limit)
            
            results = await cursor.to_list(length=None)
            
            logger.info(f"ğŸ“Š æŸ¥è¯¢å†å²æ•°æ®: {symbol} è¿”å› {len(results)} æ¡è®°å½•")
            return results
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢å†å²æ•°æ®å¤±è´¥ {symbol}: {e}")
            return []
    
    async def get_latest_date(self, symbol: str, data_source: str) -> Optional[str]:
        """è·å–æœ€æ–°æ•°æ®æ—¥æœŸ"""
        if self.collection is None:
            await self.initialize()
        
        try:
            result = await self.collection.find_one(
                {"symbol": symbol, "data_source": data_source},
                sort=[("trade_date", -1)]
            )
            
            if result:
                return result["trade_date"]
            return None
            
        except Exception as e:
            logger.error(f"âŒ è·å–æœ€æ–°æ—¥æœŸå¤±è´¥ {symbol}: {e}")
            return None
    
    async def get_data_statistics(self) -> Dict[str, Any]:
        """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        if self.collection is None:
            await self.initialize()
        
        try:
            # æ€»è®°å½•æ•°
            total_count = await self.collection.count_documents({})
            
            # æŒ‰æ•°æ®æºç»Ÿè®¡
            source_stats = await self.collection.aggregate([
                {"$group": {
                    "_id": "$data_source",
                    "count": {"$sum": 1},
                    "latest_date": {"$max": "$trade_date"}
                }}
            ]).to_list(length=None)
            
            # æŒ‰å¸‚åœºç»Ÿè®¡
            market_stats = await self.collection.aggregate([
                {"$group": {
                    "_id": "$market",
                    "count": {"$sum": 1}
                }}
            ]).to_list(length=None)
            
            # è‚¡ç¥¨æ•°é‡ç»Ÿè®¡
            symbol_count = len(await self.collection.distinct("symbol"))
            
            return {
                "total_records": total_count,
                "total_symbols": symbol_count,
                "by_source": {item["_id"]: {
                    "count": item["count"],
                    "latest_date": item.get("latest_date")
                } for item in source_stats},
                "by_market": {item["_id"]: item["count"] for item in market_stats},
                "last_updated": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}


# å…¨å±€æœåŠ¡å®ä¾‹
_historical_data_service = None


async def get_historical_data_service() -> HistoricalDataService:
    """è·å–å†å²æ•°æ®æœåŠ¡å®ä¾‹"""
    global _historical_data_service
    if _historical_data_service is None:
        _historical_data_service = HistoricalDataService()
        await _historical_data_service.initialize()
    return _historical_data_service
