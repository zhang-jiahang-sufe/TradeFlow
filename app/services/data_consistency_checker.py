"""
æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å’Œå¤„ç†æœåŠ¡
å¤„ç†å¤šæ•°æ®æºä¹‹é—´çš„æ•°æ®ä¸ä¸€è‡´æ€§é—®é¢˜
"""
import logging
import pandas as pd
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from datetime import datetime
import numpy as np

logger = logging.getLogger(__name__)

@dataclass
class DataConsistencyResult:
    """æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ"""
    is_consistent: bool
    primary_source: str
    secondary_source: str
    differences: Dict[str, Any]
    confidence_score: float
    recommended_action: str
    details: Dict[str, Any]

@dataclass
class FinancialMetricComparison:
    """è´¢åŠ¡æŒ‡æ ‡æ¯”è¾ƒç»“æœ"""
    metric_name: str
    primary_value: Optional[float]
    secondary_value: Optional[float]
    difference_pct: Optional[float]
    is_significant: bool
    tolerance: float

class DataConsistencyChecker:
    """æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å™¨"""
    
    def __init__(self):
        # è®¾ç½®å„ç§æŒ‡æ ‡çš„å®¹å¿åº¦é˜ˆå€¼
        self.tolerance_thresholds = {
            'pe': 0.05,      # PEå…è®¸5%å·®å¼‚
            'pb': 0.05,      # PBå…è®¸5%å·®å¼‚
            'total_mv': 0.02, # å¸‚å€¼å…è®¸2%å·®å¼‚
            'price': 0.01,   # è‚¡ä»·å…è®¸1%å·®å¼‚
            'volume': 0.10,  # æˆäº¤é‡å…è®¸10%å·®å¼‚
            'turnover_rate': 0.05  # æ¢æ‰‹ç‡å…è®¸5%å·®å¼‚
        }
        
        # å…³é”®æŒ‡æ ‡æƒé‡ï¼ˆç”¨äºè®¡ç®—ç½®ä¿¡åº¦åˆ†æ•°ï¼‰
        self.metric_weights = {
            'pe': 0.25,
            'pb': 0.25,
            'total_mv': 0.20,
            'price': 0.15,
            'volume': 0.10,
            'turnover_rate': 0.05
        }
    
    def check_daily_basic_consistency(
        self, 
        primary_data: pd.DataFrame, 
        secondary_data: pd.DataFrame,
        primary_source: str,
        secondary_source: str
    ) -> DataConsistencyResult:
        """
        æ£€æŸ¥daily_basicæ•°æ®çš„ä¸€è‡´æ€§
        
        Args:
            primary_data: ä¸»æ•°æ®æºæ•°æ®
            secondary_data: æ¬¡æ•°æ®æºæ•°æ®
            primary_source: ä¸»æ•°æ®æºåç§°
            secondary_source: æ¬¡æ•°æ®æºåç§°
        """
        try:
            logger.info(f"ğŸ” æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§: {primary_source} vs {secondary_source}")
            
            # 1. åŸºç¡€æ£€æŸ¥
            if primary_data.empty or secondary_data.empty:
                return DataConsistencyResult(
                    is_consistent=False,
                    primary_source=primary_source,
                    secondary_source=secondary_source,
                    differences={'error': 'One or both datasets are empty'},
                    confidence_score=0.0,
                    recommended_action='use_primary_only',
                    details={'reason': 'Empty dataset detected'}
                )
            
            # 2. è‚¡ç¥¨ä»£ç åŒ¹é…
            common_stocks = self._find_common_stocks(primary_data, secondary_data)
            if len(common_stocks) == 0:
                return DataConsistencyResult(
                    is_consistent=False,
                    primary_source=primary_source,
                    secondary_source=secondary_source,
                    differences={'error': 'No common stocks found'},
                    confidence_score=0.0,
                    recommended_action='use_primary_only',
                    details={'reason': 'No overlapping stocks'}
                )
            
            logger.info(f"ğŸ“Š æ‰¾åˆ°{len(common_stocks)}åªå…±åŒè‚¡ç¥¨è¿›è¡Œæ¯”è¾ƒ")
            
            # 3. é€æŒ‡æ ‡æ¯”è¾ƒ
            metric_comparisons = []
            for metric in ['pe', 'pb', 'total_mv']:
                comparison = self._compare_metric(
                    primary_data, secondary_data, common_stocks, metric
                )
                if comparison:
                    metric_comparisons.append(comparison)
            
            # 4. è®¡ç®—æ•´ä½“ä¸€è‡´æ€§
            consistency_result = self._calculate_overall_consistency(
                metric_comparisons, primary_source, secondary_source
            )
            
            return consistency_result
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return DataConsistencyResult(
                is_consistent=False,
                primary_source=primary_source,
                secondary_source=secondary_source,
                differences={'error': str(e)},
                confidence_score=0.0,
                recommended_action='use_primary_only',
                details={'exception': str(e)}
            )
    
    def _find_common_stocks(self, df1: pd.DataFrame, df2: pd.DataFrame) -> List[str]:
        """æ‰¾åˆ°ä¸¤ä¸ªæ•°æ®é›†ä¸­çš„å…±åŒè‚¡ç¥¨"""
        # å°è¯•ä¸åŒçš„è‚¡ç¥¨ä»£ç åˆ—å
        code_cols = ['ts_code', 'symbol', 'code', 'stock_code']
        
        df1_codes = set()
        df2_codes = set()
        
        for col in code_cols:
            if col in df1.columns:
                df1_codes.update(df1[col].dropna().astype(str).tolist())
            if col in df2.columns:
                df2_codes.update(df2[col].dropna().astype(str).tolist())
        
        return list(df1_codes.intersection(df2_codes))
    
    def _compare_metric(
        self, 
        df1: pd.DataFrame, 
        df2: pd.DataFrame, 
        common_stocks: List[str], 
        metric: str
    ) -> Optional[FinancialMetricComparison]:
        """æ¯”è¾ƒç‰¹å®šæŒ‡æ ‡"""
        try:
            if metric not in df1.columns or metric not in df2.columns:
                return None
            
            # è·å–å…±åŒè‚¡ç¥¨çš„æŒ‡æ ‡å€¼
            df1_values = []
            df2_values = []
            
            for stock in common_stocks[:100]:  # é™åˆ¶æ¯”è¾ƒæ•°é‡
                val1 = self._get_stock_metric_value(df1, stock, metric)
                val2 = self._get_stock_metric_value(df2, stock, metric)
                
                if val1 is not None and val2 is not None:
                    df1_values.append(val1)
                    df2_values.append(val2)
            
            if len(df1_values) == 0:
                return None
            
            # è®¡ç®—å¹³å‡å€¼å’Œå·®å¼‚
            avg1 = np.mean(df1_values)
            avg2 = np.mean(df2_values)
            
            if avg1 != 0:
                diff_pct = abs(avg2 - avg1) / abs(avg1)
            else:
                diff_pct = float('inf') if avg2 != 0 else 0
            
            tolerance = self.tolerance_thresholds.get(metric, 0.1)
            is_significant = diff_pct > tolerance
            
            return FinancialMetricComparison(
                metric_name=metric,
                primary_value=avg1,
                secondary_value=avg2,
                difference_pct=diff_pct,
                is_significant=is_significant,
                tolerance=tolerance
            )
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ¯”è¾ƒæŒ‡æ ‡{metric}å¤±è´¥: {e}")
            return None
    
    def _get_stock_metric_value(self, df: pd.DataFrame, stock_code: str, metric: str) -> Optional[float]:
        """è·å–ç‰¹å®šè‚¡ç¥¨çš„æŒ‡æ ‡å€¼"""
        try:
            # å°è¯•ä¸åŒçš„åŒ¹é…æ–¹å¼
            for code_col in ['ts_code', 'symbol', 'code']:
                if code_col in df.columns:
                    mask = df[code_col].astype(str) == stock_code
                    if mask.any():
                        value = df.loc[mask, metric].iloc[0]
                        if pd.notna(value) and value != 0:
                            return float(value)
            return None
        except:
            return None
    
    def _calculate_overall_consistency(
        self, 
        comparisons: List[FinancialMetricComparison],
        primary_source: str,
        secondary_source: str
    ) -> DataConsistencyResult:
        """è®¡ç®—æ•´ä½“ä¸€è‡´æ€§ç»“æœ"""
        if not comparisons:
            return DataConsistencyResult(
                is_consistent=False,
                primary_source=primary_source,
                secondary_source=secondary_source,
                differences={'error': 'No valid metric comparisons'},
                confidence_score=0.0,
                recommended_action='use_primary_only',
                details={'reason': 'No comparable metrics'}
            )
        
        # è®¡ç®—åŠ æƒç½®ä¿¡åº¦åˆ†æ•°
        total_weight = 0
        weighted_score = 0
        differences = {}
        
        for comp in comparisons:
            weight = self.metric_weights.get(comp.metric_name, 0.1)
            total_weight += weight
            
            # ä¸€è‡´æ€§åˆ†æ•°ï¼šå·®å¼‚è¶Šå°åˆ†æ•°è¶Šé«˜
            if comp.difference_pct is not None and comp.difference_pct != float('inf'):
                consistency_score = max(0, 1 - (comp.difference_pct / comp.tolerance))
            else:
                consistency_score = 0
            
            weighted_score += weight * consistency_score
            
            # è®°å½•å·®å¼‚
            differences[comp.metric_name] = {
                'primary_value': comp.primary_value,
                'secondary_value': comp.secondary_value,
                'difference_pct': comp.difference_pct,
                'is_significant': comp.is_significant,
                'tolerance': comp.tolerance
            }
        
        confidence_score = weighted_score / total_weight if total_weight > 0 else 0
        
        # åˆ¤æ–­æ•´ä½“ä¸€è‡´æ€§
        significant_differences = sum(1 for comp in comparisons if comp.is_significant)
        is_consistent = significant_differences <= len(comparisons) * 0.3  # å…è®¸30%çš„æŒ‡æ ‡æœ‰æ˜¾è‘—å·®å¼‚
        
        # æ¨èè¡ŒåŠ¨
        if confidence_score > 0.8:
            recommended_action = 'use_either'  # æ•°æ®é«˜åº¦ä¸€è‡´ï¼Œå¯ä»¥ä½¿ç”¨ä»»ä¸€æ•°æ®æº
        elif confidence_score > 0.6:
            recommended_action = 'use_primary_with_warning'  # ä½¿ç”¨ä¸»æ•°æ®æºä½†å‘å‡ºè­¦å‘Š
        elif confidence_score > 0.3:
            recommended_action = 'use_primary_only'  # ä»…ä½¿ç”¨ä¸»æ•°æ®æº
        else:
            recommended_action = 'investigate_sources'  # éœ€è¦è°ƒæŸ¥æ•°æ®æºé—®é¢˜
        
        return DataConsistencyResult(
            is_consistent=is_consistent,
            primary_source=primary_source,
            secondary_source=secondary_source,
            differences=differences,
            confidence_score=confidence_score,
            recommended_action=recommended_action,
            details={
                'total_comparisons': len(comparisons),
                'significant_differences': significant_differences,
                'consistency_threshold': 0.3
            }
        )

    def resolve_data_conflicts(
        self, 
        primary_data: pd.DataFrame,
        secondary_data: pd.DataFrame,
        consistency_result: DataConsistencyResult
    ) -> Tuple[pd.DataFrame, str]:
        """
        æ ¹æ®ä¸€è‡´æ€§æ£€æŸ¥ç»“æœè§£å†³æ•°æ®å†²çª
        
        Returns:
            Tuple[pd.DataFrame, str]: (æœ€ç»ˆæ•°æ®, è§£å†³ç­–ç•¥è¯´æ˜)
        """
        action = consistency_result.recommended_action
        
        if action == 'use_either':
            logger.info("âœ… æ•°æ®é«˜åº¦ä¸€è‡´ï¼Œä½¿ç”¨ä¸»æ•°æ®æº")
            return primary_data, "æ•°æ®æºé«˜åº¦ä¸€è‡´ï¼Œä½¿ç”¨ä¸»æ•°æ®æº"
        
        elif action == 'use_primary_with_warning':
            logger.warning("âš ï¸ æ•°æ®å­˜åœ¨å·®å¼‚ä½†åœ¨å¯æ¥å—èŒƒå›´å†…ï¼Œä½¿ç”¨ä¸»æ•°æ®æº")
            return primary_data, f"æ•°æ®å­˜åœ¨è½»å¾®å·®å¼‚ï¼ˆç½®ä¿¡åº¦: {consistency_result.confidence_score:.2f}ï¼‰ï¼Œä½¿ç”¨ä¸»æ•°æ®æº"
        
        elif action == 'use_primary_only':
            logger.warning("ğŸš¨ æ•°æ®å·®å¼‚è¾ƒå¤§ï¼Œä»…ä½¿ç”¨ä¸»æ•°æ®æº")
            return primary_data, f"æ•°æ®å·®å¼‚æ˜¾è‘—ï¼ˆç½®ä¿¡åº¦: {consistency_result.confidence_score:.2f}ï¼‰ï¼Œä»…ä½¿ç”¨ä¸»æ•°æ®æº"
        
        else:  # investigate_sources
            logger.error("âŒ æ•°æ®æºå­˜åœ¨ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦äººå·¥è°ƒæŸ¥")
            return primary_data, f"æ•°æ®æºå­˜åœ¨ä¸¥é‡ä¸ä¸€è‡´ï¼ˆç½®ä¿¡åº¦: {consistency_result.confidence_score:.2f}ï¼‰ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®æº"
