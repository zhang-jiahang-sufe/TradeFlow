import logging
import logging.config
import sys
from pathlib import Path
import os
import platform

from app.core.logging_context import LoggingContextFilter, trace_id_var

# ğŸ”¥ åœ¨ Windows ä¸Šä½¿ç”¨ concurrent-log-handler é¿å…æ–‡ä»¶å ç”¨é—®é¢˜
_IS_WINDOWS = platform.system() == "Windows"
if _IS_WINDOWS:
    try:
        from concurrent_log_handler import ConcurrentRotatingFileHandler
        _USE_CONCURRENT_HANDLER = True
    except ImportError:
        _USE_CONCURRENT_HANDLER = False
        logging.warning("concurrent-log-handler æœªå®‰è£…ï¼Œåœ¨ Windows ä¸Šå¯èƒ½é‡åˆ°æ—¥å¿—è½®è½¬é—®é¢˜")
else:
    _USE_CONCURRENT_HANDLER = False

try:
    import tomllib as toml_loader  # Python 3.11+
except Exception:
    try:
        import tomli as toml_loader  # Python 3.10 fallback
    except Exception:
        toml_loader = None


def resolve_logging_cfg_path() -> Path:
    """æ ¹æ®ç¯å¢ƒé€‰æ‹©æ—¥å¿—é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰
    ä¼˜å…ˆ docker é…ç½®ï¼Œå…¶æ¬¡é»˜è®¤é…ç½®ã€‚
    """
    profile = os.environ.get("LOGGING_PROFILE", "").lower()
    is_docker_env = os.environ.get("DOCKER", "").lower() in {"1", "true", "yes"} or Path("/.dockerenv").exists()
    cfg_candidate = "config/logging_docker.toml" if profile == "docker" or is_docker_env else "config/logging.toml"
    return Path(cfg_candidate)


class SimpleJsonFormatter(logging.Formatter):
    """Minimal JSON formatter without external deps."""
    def format(self, record: logging.LogRecord) -> str:
        import json
        obj = {
            "time": self.formatTime(record, "%Y-%m-%d %H:%M:%S"),
            "name": record.name,
            "level": record.levelname,
            "trace_id": getattr(record, "trace_id", "-"),
            "message": record.getMessage(),
        }
        return json.dumps(obj, ensure_ascii=False)


def _parse_size(size_str: str) -> int:
    """è§£æå¤§å°å­—ç¬¦ä¸²ï¼ˆå¦‚ '10MB'ï¼‰ä¸ºå­—èŠ‚æ•°"""
    if isinstance(size_str, int):
        return size_str
    if isinstance(size_str, str) and size_str.upper().endswith("MB"):
        try:
            return int(float(size_str[:-2]) * 1024 * 1024)
        except Exception:
            return 10 * 1024 * 1024
    return 10 * 1024 * 1024

def setup_logging(log_level: str = "INFO"):
    """
    è®¾ç½®åº”ç”¨æ—¥å¿—é…ç½®ï¼š
    1) ä¼˜å…ˆå°è¯•ä» config/logging.toml è¯»å–å¹¶è½¬åŒ–ä¸º dictConfig
    2) å¤±è´¥æˆ–ä¸å­˜åœ¨æ—¶ï¼Œå›é€€åˆ°å†…ç½®é»˜è®¤é…ç½®
    """
    # 1) è‹¥å­˜åœ¨ TOML é…ç½®ä¸”å¯è§£æï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨
    try:
        cfg_path = resolve_logging_cfg_path()
        print(f"ğŸ” [setup_logging] æ—¥å¿—é…ç½®æ–‡ä»¶è·¯å¾„: {cfg_path}")
        print(f"ğŸ” [setup_logging] é…ç½®æ–‡ä»¶å­˜åœ¨: {cfg_path.exists()}")
        print(f"ğŸ” [setup_logging] TOMLåŠ è½½å™¨å¯ç”¨: {toml_loader is not None}")

        if cfg_path.exists() and toml_loader is not None:
            with cfg_path.open("rb") as f:
                toml_data = toml_loader.load(f)

            print(f"ğŸ” [setup_logging] æˆåŠŸåŠ è½½TOMLé…ç½®")

            # è¯»å–åŸºç¡€å­—æ®µ
            logging_root = toml_data.get("logging", {})
            level = logging_root.get("level", log_level)
            fmt_cfg = logging_root.get("format", {})
            fmt_console = fmt_cfg.get(
                "console", "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            )
            fmt_file = fmt_cfg.get(
                "file", "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            )
            # ç¡®ä¿æ–‡æœ¬æ ¼å¼åŒ…å« trace_idï¼ˆè‹¥æœªæ˜¾å¼åŒ…å«ï¼‰
            if "%(trace_id)" not in str(fmt_console):
                fmt_console = str(fmt_console) + " trace=%(trace_id)s"
            if "%(trace_id)" not in str(fmt_file):
                fmt_file = str(fmt_file) + " trace=%(trace_id)s"

            handlers_cfg = logging_root.get("handlers", {})
            file_handler_cfg = handlers_cfg.get("file", {})
            file_dir = file_handler_cfg.get("directory", "./logs")
            file_level = file_handler_cfg.get("level", "DEBUG")
            max_bytes = file_handler_cfg.get("max_size", "10MB")
            # æ”¯æŒ "10MB" å½¢å¼
            if isinstance(max_bytes, str) and max_bytes.upper().endswith("MB"):
                try:
                    max_bytes = int(float(max_bytes[:-2]) * 1024 * 1024)
                except Exception:
                    max_bytes = 10 * 1024 * 1024
            elif not isinstance(max_bytes, int):
                max_bytes = 10 * 1024 * 1024
            backup_count = int(file_handler_cfg.get("backup_count", 5))

            Path(file_dir).mkdir(parents=True, exist_ok=True)

            # ä»TOMLé…ç½®è¯»å–å„ä¸ªæ—¥å¿—æ–‡ä»¶è·¯å¾„
            main_handler_cfg = handlers_cfg.get("main", {})
            webapi_handler_cfg = handlers_cfg.get("webapi", {})
            worker_handler_cfg = handlers_cfg.get("worker", {})

            print(f"ğŸ” [setup_logging] handlersé…ç½®: {list(handlers_cfg.keys())}")
            print(f"ğŸ” [setup_logging] main_handler_cfg: {main_handler_cfg}")
            print(f"ğŸ” [setup_logging] webapi_handler_cfg: {webapi_handler_cfg}")
            print(f"ğŸ” [setup_logging] worker_handler_cfg: {worker_handler_cfg}")

            # ä¸»æ—¥å¿—æ–‡ä»¶ï¼ˆtradingagents.logï¼‰
            main_log = main_handler_cfg.get("filename", str(Path(file_dir) / "tradingagents.log"))
            main_enabled = main_handler_cfg.get("enabled", True)
            main_level = main_handler_cfg.get("level", "INFO")
            main_max_bytes = _parse_size(main_handler_cfg.get("max_size", "100MB"))
            main_backup_count = int(main_handler_cfg.get("backup_count", 5))

            print(f"ğŸ” [setup_logging] ä¸»æ—¥å¿—æ–‡ä»¶é…ç½®:")
            print(f"  - æ–‡ä»¶è·¯å¾„: {main_log}")
            print(f"  - æ˜¯å¦å¯ç”¨: {main_enabled}")
            print(f"  - æ—¥å¿—çº§åˆ«: {main_level}")
            print(f"  - æœ€å¤§å¤§å°: {main_max_bytes} bytes")
            print(f"  - å¤‡ä»½æ•°é‡: {main_backup_count}")

            # WebAPIæ—¥å¿—æ–‡ä»¶
            webapi_log = webapi_handler_cfg.get("filename", str(Path(file_dir) / "webapi.log"))
            webapi_enabled = webapi_handler_cfg.get("enabled", True)
            webapi_level = webapi_handler_cfg.get("level", "DEBUG")
            webapi_max_bytes = _parse_size(webapi_handler_cfg.get("max_size", "100MB"))
            webapi_backup_count = int(webapi_handler_cfg.get("backup_count", 5))

            print(f"ğŸ” [setup_logging] WebAPIæ—¥å¿—æ–‡ä»¶: {webapi_log}, å¯ç”¨: {webapi_enabled}")

            # Workeræ—¥å¿—æ–‡ä»¶
            worker_log = worker_handler_cfg.get("filename", str(Path(file_dir) / "worker.log"))
            worker_enabled = worker_handler_cfg.get("enabled", True)
            worker_level = worker_handler_cfg.get("level", "DEBUG")
            worker_max_bytes = _parse_size(worker_handler_cfg.get("max_size", "100MB"))
            worker_backup_count = int(worker_handler_cfg.get("backup_count", 5))

            print(f"ğŸ” [setup_logging] Workeræ—¥å¿—æ–‡ä»¶: {worker_log}, å¯ç”¨: {worker_enabled}")

            # é”™è¯¯æ—¥å¿—æ–‡ä»¶
            error_handler_cfg = handlers_cfg.get("error", {})
            error_log = error_handler_cfg.get("filename", str(Path(file_dir) / "error.log"))
            error_enabled = error_handler_cfg.get("enabled", True)
            error_level = error_handler_cfg.get("level", "WARNING")
            error_max_bytes = _parse_size(error_handler_cfg.get("max_size", "100MB"))
            error_backup_count = int(error_handler_cfg.get("backup_count", 5))

            # JSON å¼€å…³ï¼šä¿æŒå‘åå…¼å®¹ï¼ˆjson/mode ä»…æ§åˆ¶å°ï¼‰ï¼›æ–°å¢ file_json/file_mode æ§åˆ¶æ–‡ä»¶ handler
            use_json_console = bool(fmt_cfg.get("json", False)) or str(fmt_cfg.get("mode", "")).lower() == "json"
            use_json_file = (
                bool(fmt_cfg.get("file_json", False))
                or bool(fmt_cfg.get("json_file", False))
                or str(fmt_cfg.get("file_mode", "")).lower() == "json"
            )

            # æ„å»ºå¤„ç†å™¨é…ç½®
            handlers_config = {
                "console": {
                    "class": "logging.StreamHandler",
                    "formatter": "json_console_fmt" if use_json_console else "console_fmt",
                    "level": level,
                    "filters": ["request_context"],
                    "stream": sys.stdout,
                },
            }

            print(f"ğŸ” [setup_logging] å¼€å§‹æ„å»ºhandlersé…ç½®")

            # ğŸ”¥ é€‰æ‹©æ—¥å¿—å¤„ç†å™¨ç±»ï¼ˆWindows ä½¿ç”¨ ConcurrentRotatingFileHandlerï¼‰
            handler_class = "concurrent_log_handler.ConcurrentRotatingFileHandler" if _USE_CONCURRENT_HANDLER else "logging.handlers.RotatingFileHandler"

            # ä¸»æ—¥å¿—æ–‡ä»¶ï¼ˆtradingagents.logï¼‰
            if main_enabled:
                print(f"âœ… [setup_logging] æ·»åŠ  main_file handler: {main_log} (ä½¿ç”¨ {handler_class})")
                handlers_config["main_file"] = {
                    "class": handler_class,
                    "formatter": "json_file_fmt" if use_json_file else "file_fmt",
                    "level": main_level,
                    "filename": main_log,
                    "maxBytes": main_max_bytes,
                    "backupCount": main_backup_count,
                    "encoding": "utf-8",
                    "filters": ["request_context"],
                }
            else:
                print(f"âš ï¸ [setup_logging] main_file handler æœªå¯ç”¨")

            # WebAPIæ—¥å¿—æ–‡ä»¶
            if webapi_enabled:
                handlers_config["file"] = {
                    "class": handler_class,
                    "formatter": "json_file_fmt" if use_json_file else "file_fmt",
                    "level": webapi_level,
                    "filename": webapi_log,
                    "maxBytes": webapi_max_bytes,
                    "backupCount": webapi_backup_count,
                    "encoding": "utf-8",
                    "filters": ["request_context"],
                }

            # Workeræ—¥å¿—æ–‡ä»¶
            if worker_enabled:
                handlers_config["worker_file"] = {
                    "class": handler_class,
                    "formatter": "json_file_fmt" if use_json_file else "file_fmt",
                    "level": worker_level,
                    "filename": worker_log,
                    "maxBytes": worker_max_bytes,
                    "backupCount": worker_backup_count,
                    "encoding": "utf-8",
                    "filters": ["request_context"],
                }

            # æ·»åŠ é”™è¯¯æ—¥å¿—å¤„ç†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if error_enabled:
                handlers_config["error_file"] = {
                    "class": "logging.handlers.RotatingFileHandler",
                    "formatter": "json_file_fmt" if use_json_file else "file_fmt",
                    "level": error_level,
                    "filename": error_log,
                    "maxBytes": error_max_bytes,
                    "backupCount": error_backup_count,
                    "encoding": "utf-8",
                    "filters": ["request_context"],
                }

            # æ„å»ºlogger handlersåˆ—è¡¨
            main_handlers = ["console"]
            if main_enabled:
                main_handlers.append("main_file")
            if error_enabled:
                main_handlers.append("error_file")

            print(f"ğŸ” [setup_logging] main_handlers: {main_handlers}")

            webapi_handlers = ["console"]
            if webapi_enabled:
                webapi_handlers.append("file")
            if main_enabled:
                webapi_handlers.append("main_file")
            if error_enabled:
                webapi_handlers.append("error_file")

            print(f"ğŸ” [setup_logging] webapi_handlers: {webapi_handlers}")

            worker_handlers = ["console"]
            if worker_enabled:
                worker_handlers.append("worker_file")
            if main_enabled:
                worker_handlers.append("main_file")
            if error_enabled:
                worker_handlers.append("error_file")

            print(f"ğŸ” [setup_logging] worker_handlers: {worker_handlers}")

            logging_config = {
                "version": 1,
                "disable_existing_loggers": False,
                "filters": {
                    "request_context": {"()": "app.core.logging_context.LoggingContextFilter"}
                },
                "formatters": {
                    "console_fmt": {
                        "format": fmt_console,
                        "datefmt": "%Y-%m-%d %H:%M:%S",
                    },
                    "file_fmt": {
                        "format": fmt_file,
                        "datefmt": "%Y-%m-%d %H:%M:%S",
                    },
                    "json_console_fmt": {
                        "()": "app.core.logging_config.SimpleJsonFormatter"
                    },
                    "json_file_fmt": {
                        "()": "app.core.logging_config.SimpleJsonFormatter"
                    },
                },
                "handlers": handlers_config,
                "loggers": {
                    "tradingagents": {
                        "level": "INFO",
                        "handlers": main_handlers,
                        "propagate": False
                    },
                    "webapi": {
                        "level": "INFO",
                        "handlers": webapi_handlers,
                        "propagate": False
                    },
                    "worker": {
                        "level": "DEBUG",
                        "handlers": worker_handlers,
                        "propagate": False
                    },
                    "uvicorn": {
                        "level": "INFO",
                        "handlers": webapi_handlers,
                        "propagate": False
                    },
                    "fastapi": {
                        "level": "INFO",
                        "handlers": webapi_handlers,
                        "propagate": False
                    },
                    "app": {
                        "level": "INFO",
                        "handlers": main_handlers,
                        "propagate": False
                    },
                },
                "root": {"level": level, "handlers": main_handlers},
            }

            print(f"ğŸ” [setup_logging] æœ€ç»ˆhandlersé…ç½®: {list(handlers_config.keys())}")
            print(f"ğŸ” [setup_logging] å¼€å§‹åº”ç”¨ dictConfig")

            logging.config.dictConfig(logging_config)

            print(f"âœ… [setup_logging] dictConfig åº”ç”¨æˆåŠŸ")

            logging.getLogger("webapi").info(f"Logging configured from {cfg_path}")

            # æµ‹è¯•ä¸»æ—¥å¿—æ–‡ä»¶æ˜¯å¦å¯å†™
            if main_enabled:
                test_logger = logging.getLogger("tradingagents")
                test_logger.info(f"ğŸ” æµ‹è¯•ä¸»æ—¥å¿—æ–‡ä»¶å†™å…¥: {main_log}")
                print(f"ğŸ” [setup_logging] å·²å‘ tradingagents logger å†™å…¥æµ‹è¯•æ—¥å¿—")

            return
    except Exception as e:
        # TOML å­˜åœ¨ä½†åŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°é»˜è®¤é…ç½®
        logging.getLogger("webapi").warning(f"Failed to load logging.toml, fallback to defaults: {e}")

    # 2) é»˜è®¤å†…ç½®é…ç½®ï¼ˆä¸åŸå…ˆä¸€è‡´ï¼‰
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)

    # ğŸ”¥ é€‰æ‹©æ—¥å¿—å¤„ç†å™¨ç±»ï¼ˆWindows ä½¿ç”¨ ConcurrentRotatingFileHandlerï¼‰
    handler_class = "concurrent_log_handler.ConcurrentRotatingFileHandler" if _USE_CONCURRENT_HANDLER else "logging.handlers.RotatingFileHandler"

    logging_config = {
        "version": 1,
        "disable_existing_loggers": False,
        "filters": {"request_context": {"()": "app.core.logging_context.LoggingContextFilter"}},
        "formatters": {
            "default": {
                "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s trace=%(trace_id)s",
                "datefmt": "%Y-%m-%d %H:%M:%S",
            },
            "detailed": {
                "format": "%(asctime)s - %(name)s - %(levelname)s - %(pathname)s:%(lineno)d - %(message)s trace=%(trace_id)s",
                "datefmt": "%Y-%m-%d %H:%M:%S",
            },
        },
        "handlers": {
            "console": {
                "class": "logging.StreamHandler",
                "formatter": "default",
                "level": log_level,
                "filters": ["request_context"],
                "stream": sys.stdout,
            },
            "file": {
                "class": handler_class,
                "formatter": "detailed",
                "level": "DEBUG",
                "filters": ["request_context"],
                "filename": "logs/webapi.log",
                "maxBytes": 10485760,
                "backupCount": 5,
                "encoding": "utf-8",
            },
            "worker_file": {
                "class": handler_class,
                "formatter": "detailed",
                "level": "DEBUG",
                "filters": ["request_context"],
                "filename": "logs/worker.log",
                "maxBytes": 10485760,
                "backupCount": 5,
                "encoding": "utf-8",
            },
            "error_file": {
                "class": handler_class,
                "formatter": "detailed",
                "level": "WARNING",
                "filters": ["request_context"],
                "filename": "logs/error.log",
                "maxBytes": 10485760,
                "backupCount": 5,
                "encoding": "utf-8",
            },
        },
        "loggers": {
            "webapi": {"level": "INFO", "handlers": ["console", "file", "error_file"], "propagate": True},
            "worker": {"level": "DEBUG", "handlers": ["console", "worker_file", "error_file"], "propagate": False},
            "uvicorn": {"level": "INFO", "handlers": ["console", "file", "error_file"], "propagate": False},
            "fastapi": {"level": "INFO", "handlers": ["console", "file", "error_file"], "propagate": False},
        },
        "root": {"level": log_level, "handlers": ["console"]},
    }

    logging.config.dictConfig(logging_config)
    logging.getLogger("webapi").info("Logging configured successfully (built-in)")