#!/usr/bin/env python3
"""
AKShare å¼ºåˆ¶å…¨é‡åŒæ­¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯

åŠŸèƒ½ï¼š
1. å¼ºåˆ¶æ›´æ–°æ‰€æœ‰è‚¡ç¥¨çš„åŸºç¡€ä¿¡æ¯ï¼ˆå¿½ç•¥24å°æ—¶ç¼“å­˜ï¼‰
2. æ˜¾ç¤ºè¯¦ç»†çš„åŒæ­¥è¿›åº¦å’Œé”™è¯¯ä¿¡æ¯
3. ç»Ÿè®¡æˆåŠŸ/å¤±è´¥çš„è‚¡ç¥¨æ•°é‡

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/akshare_force_sync_all.py
    python scripts/akshare_force_sync_all.py --batch-size 10  # è°ƒæ•´æ‰¹æ¬¡å¤§å°
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.worker.akshare_sync_service import AKShareSyncService
from app.core.database import init_database
import logging
import argparse

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(name)-30s | %(levelname)-8s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


async def main(batch_size: int = 50):
    """ä¸»å‡½æ•°"""
    logger.info("=" * 80)
    logger.info("ğŸš€ AKShare å¼ºåˆ¶å…¨é‡åŒæ­¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯")
    logger.info("=" * 80)
    
    # åˆå§‹åŒ–æ•°æ®åº“
    await init_database()
    
    # åˆ›å»ºåŒæ­¥æœåŠ¡
    service = AKShareSyncService(batch_size=batch_size)
    
    # å¼ºåˆ¶å…¨é‡åŒæ­¥
    logger.info("âš ï¸  ä½¿ç”¨ force_update=Trueï¼Œå°†æ›´æ–°æ‰€æœ‰è‚¡ç¥¨ï¼ˆå¿½ç•¥24å°æ—¶ç¼“å­˜ï¼‰")
    stats = await service.sync_stock_basic_info(force_update=True)
    
    # è¾“å‡ºç»Ÿè®¡
    logger.info("")
    logger.info("=" * 80)
    logger.info("ğŸ“Š åŒæ­¥å®Œæˆç»Ÿè®¡")
    logger.info("=" * 80)
    logger.info(f"   æ€»è®¡: {stats['total_processed']} åªè‚¡ç¥¨")
    logger.info(f"   æˆåŠŸ: {stats['success_count']} åª")
    logger.info(f"   å¤±è´¥: {stats['error_count']} åª")
    logger.info(f"   è·³è¿‡: {stats['skipped_count']} åª")
    logger.info(f"   è€—æ—¶: {stats['duration']:.2f} ç§’")
    logger.info(f"   æˆåŠŸç‡: {stats['success_count']*100//stats['total_processed'] if stats['total_processed'] > 0 else 0}%")
    logger.info("=" * 80)
    
    # è¾“å‡ºé”™è¯¯è¯¦æƒ…
    if stats['errors']:
        logger.info("")
        logger.info(f"âŒ å¤±è´¥çš„è‚¡ç¥¨ ({len(stats['errors'])} åª):")
        for i, error in enumerate(stats['errors'][:20], 1):  # åªæ˜¾ç¤ºå‰20ä¸ªé”™è¯¯
            logger.info(f"   {i}. {error.get('code', 'unknown')}: {error.get('error', 'unknown error')}")
        
        if len(stats['errors']) > 20:
            logger.info(f"   ... è¿˜æœ‰ {len(stats['errors']) - 20} ä¸ªé”™è¯¯æœªæ˜¾ç¤º")
    
    logger.info("")
    logger.info("âœ… åŒæ­¥å®Œæˆï¼")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="AKShare å¼ºåˆ¶å…¨é‡åŒæ­¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        "--batch-size",
        type=int,
        default=50,
        help="æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤ï¼š50ï¼‰"
    )
    
    args = parser.parse_args()
    
    asyncio.run(main(batch_size=args.batch_size))

