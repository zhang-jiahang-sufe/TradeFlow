"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯æ¨¡å‹é…ç½®å‚æ•°æ˜¯å¦æ­£ç¡®ä¼ é€’åˆ°åˆ†æå¼•æ“

è¿™ä¸ªè„šæœ¬ä¼šï¼š
1. æ¨¡æ‹Ÿä»æ•°æ®åº“è¯»å–æ¨¡å‹é…ç½®
2. åˆ›å»ºåˆ†æé…ç½®
3. éªŒè¯é…ç½®ä¸­æ˜¯å¦åŒ…å«æ­£ç¡®çš„å‚æ•°
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.services.simple_analysis_service import create_analysis_config


def test_model_config_params():
    """æµ‹è¯•æ¨¡å‹é…ç½®å‚æ•°æ˜¯å¦æ­£ç¡®ä¼ é€’"""
    
    print("=" * 80)
    print("æµ‹è¯•ï¼šæ¨¡å‹é…ç½®å‚æ•°ä¼ é€’")
    print("=" * 80)
    
    # æ¨¡æ‹Ÿä»æ•°æ®åº“è¯»å–çš„æ¨¡å‹é…ç½®
    quick_model_config = {
        "max_tokens": 6000,
        "temperature": 0.8,
        "timeout": 200,
        "retry_times": 5,
        "api_base": "https://dashscope.aliyuncs.com/api/v1"
    }
    
    deep_model_config = {
        "max_tokens": 8000,
        "temperature": 0.5,
        "timeout": 300,
        "retry_times": 3,
        "api_base": "https://dashscope.aliyuncs.com/api/v1"
    }
    
    print("\nğŸ“‹ è¾“å…¥å‚æ•°ï¼š")
    print(f"  å¿«é€Ÿæ¨¡å‹é…ç½®: {quick_model_config}")
    print(f"  æ·±åº¦æ¨¡å‹é…ç½®: {deep_model_config}")
    
    # åˆ›å»ºåˆ†æé…ç½®
    config = create_analysis_config(
        research_depth="æ ‡å‡†",
        selected_analysts=["market", "fundamentals"],
        quick_model="qwen-turbo",
        deep_model="qwen-max",
        llm_provider="dashscope",
        market_type="Aè‚¡",
        quick_model_config=quick_model_config,
        deep_model_config=deep_model_config
    )
    
    print("\nâœ… é…ç½®åˆ›å»ºæˆåŠŸï¼")
    print("\nğŸ“Š éªŒè¯ç»“æœï¼š")
    
    # éªŒè¯é…ç½®ä¸­æ˜¯å¦åŒ…å«æ¨¡å‹å‚æ•°
    if "quick_model_config" in config:
        print(f"  âœ… quick_model_config å­˜åœ¨")
        print(f"     - max_tokens: {config['quick_model_config']['max_tokens']}")
        print(f"     - temperature: {config['quick_model_config']['temperature']}")
        print(f"     - timeout: {config['quick_model_config']['timeout']}")
        print(f"     - retry_times: {config['quick_model_config']['retry_times']}")
    else:
        print(f"  âŒ quick_model_config ä¸å­˜åœ¨")
    
    if "deep_model_config" in config:
        print(f"  âœ… deep_model_config å­˜åœ¨")
        print(f"     - max_tokens: {config['deep_model_config']['max_tokens']}")
        print(f"     - temperature: {config['deep_model_config']['temperature']}")
        print(f"     - timeout: {config['deep_model_config']['timeout']}")
        print(f"     - retry_times: {config['deep_model_config']['retry_times']}")
    else:
        print(f"  âŒ deep_model_config ä¸å­˜åœ¨")
    
    # éªŒè¯å…¶ä»–é…ç½®
    print(f"\nğŸ“‹ å…¶ä»–é…ç½®ï¼š")
    print(f"  - llm_provider: {config.get('llm_provider')}")
    print(f"  - quick_think_llm: {config.get('quick_think_llm')}")
    print(f"  - deep_think_llm: {config.get('deep_think_llm')}")
    print(f"  - research_depth: {config.get('research_depth')}")
    print(f"  - max_debate_rounds: {config.get('max_debate_rounds')}")
    print(f"  - max_risk_discuss_rounds: {config.get('max_risk_discuss_rounds')}")
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆï¼")
    print("=" * 80)


if __name__ == "__main__":
    test_model_config_params()

