#!/usr/bin/env python3
"""
æ·±åº¦è°ƒè¯•æ•°æ®ä¿å­˜è¿‡ç¨‹
é€æ­¥æ£€æŸ¥æ¯ä¸ªç¯èŠ‚
"""
import asyncio
import logging
import pandas as pd
from datetime import datetime, timedelta
from tradingagents.dataflows.providers.tushare_provider import TushareProvider
from app.services.historical_data_service import get_historical_data_service
from app.core.database import init_database
from tradingagents.config.database_manager import get_mongodb_client
from pymongo import ReplaceOne

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)


async def debug_data_save_process():
    """æ·±åº¦è°ƒè¯•æ•°æ®ä¿å­˜è¿‡ç¨‹"""
    
    print("ğŸ” æ·±åº¦è°ƒè¯•æ•°æ®ä¿å­˜è¿‡ç¨‹")
    print("=" * 60)
    
    # æµ‹è¯•å‚æ•°
    test_symbol = "000002"  # æ¢ä¸ªè‚¡ç¥¨é¿å…å¹²æ‰°
    start_date = "2024-01-01"
    end_date = "2024-01-05"  # åªæµ‹è¯•å‡ å¤©
    
    print(f"ğŸ“Š æµ‹è¯•å‚æ•°:")
    print(f"   è‚¡ç¥¨ä»£ç : {test_symbol}")
    print(f"   æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
    print()
    
    try:
        # 1. åˆå§‹åŒ–æ•°æ®åº“
        print("1ï¸âƒ£ åˆå§‹åŒ–æ•°æ®åº“è¿æ¥")
        await init_database()
        print("   âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        # 2. è¿æ¥Tushareæä¾›è€…
        print("\n2ï¸âƒ£ è¿æ¥Tushareæä¾›è€…")
        provider = TushareProvider()
        connect_success = await provider.connect()
        if not connect_success:
            print("   âŒ Tushareè¿æ¥å¤±è´¥")
            return
        print("   âœ… Tushareè¿æ¥æˆåŠŸ")
        
        # 3. è·å–å†å²æ•°æ®
        print(f"\n3ï¸âƒ£ è·å– {test_symbol} å†å²æ•°æ®")
        df = await provider.get_historical_data(test_symbol, start_date, end_date)
        if df is None or df.empty:
            print("   âŒ æœªè·å–åˆ°å†å²æ•°æ®")
            return
        
        print(f"   âœ… è·å–åˆ° {len(df)} æ¡è®°å½•")
        print(f"   ğŸ“‹ åˆ—å: {list(df.columns)}")
        print(f"   ğŸ“… ç´¢å¼•ç±»å‹: {type(df.index)}")
        print(f"   ğŸ“… æ—¥æœŸèŒƒå›´: {df.index.min()} åˆ° {df.index.max()}")
        
        # æ˜¾ç¤ºåŸå§‹æ•°æ®
        print("   ğŸ“Š åŸå§‹æ•°æ®å‰3æ¡:")
        for i, (date, row) in enumerate(df.head(3).iterrows()):
            print(f"     {date}: {dict(row)}")
        
        # 4. æ£€æŸ¥æ•°æ®åº“çŠ¶æ€ï¼ˆä¿å­˜å‰ï¼‰
        print(f"\n4ï¸âƒ£ æ£€æŸ¥æ•°æ®åº“çŠ¶æ€ï¼ˆä¿å­˜å‰ï¼‰")
        client = get_mongodb_client()
        db = client.get_database('tradingagents')
        collection = db.stock_daily_quotes
        
        before_count = collection.count_documents({"symbol": test_symbol})
        print(f"   ğŸ“Š {test_symbol} ä¿å­˜å‰è®°å½•æ•°: {before_count}")
        
        # 5. æ‰‹åŠ¨æ¨¡æ‹Ÿæ•°æ®æ ‡å‡†åŒ–è¿‡ç¨‹
        print(f"\n5ï¸âƒ£ æ‰‹åŠ¨æ¨¡æ‹Ÿæ•°æ®æ ‡å‡†åŒ–")
        
        operations = []
        processed_records = []
        
        for i, (date, row) in enumerate(df.iterrows()):
            # æ¨¡æ‹Ÿ _standardize_record æ–¹æ³•
            now = datetime.utcnow()
            
            # å¤„ç†æ—¥æœŸ
            if hasattr(date, 'strftime'):
                trade_date = date.strftime('%Y-%m-%d')
            else:
                trade_date = str(date)[:10]
            
            doc = {
                "symbol": test_symbol,
                "full_symbol": f"{test_symbol}.SZ",
                "market": "CN",
                "trade_date": trade_date,
                "period": "daily",
                "data_source": "tushare",
                "created_at": now,
                "updated_at": now,
                "version": 1,
                "open": float(row.get('open', 0)),
                "high": float(row.get('high', 0)),
                "low": float(row.get('low', 0)),
                "close": float(row.get('close', 0)),
                "pre_close": float(row.get('pre_close', 0)),
                "volume": float(row.get('volume', 0)),
                "amount": float(row.get('amount', 0)),
                "change": float(row.get('change', 0)),
                "pct_chg": float(row.get('pct_chg', 0))
            }
            
            processed_records.append(doc)
            
            # åˆ›å»ºupsertæ“ä½œ
            filter_doc = {
                "symbol": doc["symbol"],
                "trade_date": doc["trade_date"],
                "data_source": doc["data_source"],
                "period": doc["period"]
            }
            
            operations.append(ReplaceOne(
                filter=filter_doc,
                replacement=doc,
                upsert=True
            ))
            
            if i < 3:  # åªæ˜¾ç¤ºå‰3æ¡
                print(f"   ğŸ“‹ è®°å½• {i+1}:")
                print(f"     è¿‡æ»¤æ¡ä»¶: {filter_doc}")
                print(f"     æ•°æ®: symbol={doc['symbol']}, date={doc['trade_date']}, close={doc['close']}")
        
        print(f"   âœ… å‡†å¤‡äº† {len(operations)} ä¸ªæ“ä½œ")
        
        # 6. æ‰§è¡Œæ‰¹é‡å†™å…¥
        print(f"\n6ï¸âƒ£ æ‰§è¡Œæ‰¹é‡å†™å…¥")
        try:
            result = collection.bulk_write(operations)
            print(f"   âœ… æ‰¹é‡å†™å…¥å®Œæˆ:")
            print(f"     æ’å…¥æ•°é‡: {result.upserted_count}")
            print(f"     æ›´æ–°æ•°é‡: {result.modified_count}")
            print(f"     åŒ¹é…æ•°é‡: {result.matched_count}")
            print(f"     æ€»æ“ä½œæ•°: {len(operations)}")
            
            # æ£€æŸ¥å†™å…¥ç»“æœ
            if hasattr(result, 'upserted_ids'):
                print(f"     æ–°æ’å…¥çš„IDæ•°é‡: {len(result.upserted_ids)}")
            
        except Exception as e:
            print(f"   âŒ æ‰¹é‡å†™å…¥å¤±è´¥: {e}")
            return
        
        # 7. æ£€æŸ¥æ•°æ®åº“çŠ¶æ€ï¼ˆä¿å­˜åï¼‰
        print(f"\n7ï¸âƒ£ æ£€æŸ¥æ•°æ®åº“çŠ¶æ€ï¼ˆä¿å­˜åï¼‰")
        after_count = collection.count_documents({"symbol": test_symbol})
        print(f"   ğŸ“Š {test_symbol} ä¿å­˜åè®°å½•æ•°: {after_count}")
        print(f"   ğŸ“ˆ æ–°å¢è®°å½•æ•°: {after_count - before_count}")
        
        # æŸ¥è¯¢åˆšä¿å­˜çš„æ•°æ®
        saved_records = list(collection.find(
            {"symbol": test_symbol, "data_source": "tushare"},
            sort=[("trade_date", 1)]
        ))
        
        print(f"   ğŸ“‹ æ•°æ®åº“ä¸­çš„è®°å½• ({len(saved_records)}æ¡):")
        for record in saved_records:
            trade_date = record.get('trade_date', 'N/A')
            close = record.get('close', 'N/A')
            data_source = record.get('data_source', 'N/A')
            print(f"     {trade_date}: æ”¶ç›˜={close}, æ•°æ®æº={data_source}")
        
        # 8. å¯¹æ¯”åŸå§‹æ•°æ®å’Œä¿å­˜çš„æ•°æ®
        print(f"\n8ï¸âƒ£ æ•°æ®å¯¹æ¯”éªŒè¯")
        if len(saved_records) == len(df):
            print("   âœ… è®°å½•æ•°é‡åŒ¹é…")
        else:
            print(f"   âŒ è®°å½•æ•°é‡ä¸åŒ¹é…: åŸå§‹{len(df)}æ¡ vs ä¿å­˜{len(saved_records)}æ¡")
        
        # æ£€æŸ¥å…·ä½“æ•°æ®
        for i, (date, row) in enumerate(df.iterrows()):
            original_date = date.strftime('%Y-%m-%d')
            original_close = float(row.get('close', 0))
            
            # æŸ¥æ‰¾å¯¹åº”çš„ä¿å­˜è®°å½•
            saved_record = next((r for r in saved_records if r.get('trade_date') == original_date), None)
            
            if saved_record:
                saved_close = saved_record.get('close', 0)
                if abs(original_close - saved_close) < 0.01:
                    print(f"   âœ… {original_date}: æ•°æ®ä¸€è‡´ (æ”¶ç›˜={original_close})")
                else:
                    print(f"   âŒ {original_date}: æ•°æ®ä¸ä¸€è‡´ åŸå§‹={original_close} vs ä¿å­˜={saved_close}")
            else:
                print(f"   âŒ {original_date}: æœªæ‰¾åˆ°ä¿å­˜çš„è®°å½•")
        
        client.close()
        
    except Exception as e:
        print(f"âŒ è°ƒè¯•è¿‡ç¨‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 60)
    print("ğŸ¯ æ·±åº¦è°ƒè¯•å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(debug_data_save_process())
