#!/usr/bin/env python3
"""
AKShare ä¼˜åŒ–åŒæ­¥è„šæœ¬

ä¼˜åŒ–ç‚¹ï¼š
1. é¢„å…ˆç¼“å­˜è‚¡ç¥¨åˆ—è¡¨ï¼Œé¿å…é‡å¤è·å–
2. æ‰¹é‡å¤„ç†ï¼Œæ˜¾ç¤ºè¯¦ç»†è¿›åº¦
3. å¤±è´¥é‡è¯•æœºåˆ¶
4. è¯¦ç»†çš„é”™è¯¯æ—¥å¿—

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/akshare_sync_optimized.py
    python scripts/akshare_sync_optimized.py --batch-size 100  # è°ƒæ•´æ‰¹æ¬¡å¤§å°
    python scripts/akshare_sync_optimized.py --delay 0.2  # è°ƒæ•´å»¶è¿Ÿæ—¶é—´
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from motor.motor_asyncio import AsyncIOMotorClient
from app.core.config import settings
from tradingagents.dataflows.providers.china.akshare import AKShareProvider
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


async def sync_stock_basic_info(
    batch_size: int = 100,
    delay: float = 0.3,
    retry_failed: bool = True
):
    """
    åŒæ­¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
    
    Args:
        batch_size: æ‰¹æ¬¡å¤§å°
        delay: æ¯åªè‚¡ç¥¨ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
        retry_failed: æ˜¯å¦é‡è¯•å¤±è´¥çš„è‚¡ç¥¨
    """
    logger.info("=" * 80)
    logger.info("ğŸš€ AKShare ä¼˜åŒ–åŒæ­¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯")
    logger.info("=" * 80)
    
    # 1. è¿æ¥æ•°æ®åº“
    client = AsyncIOMotorClient(settings.MONGO_URI)
    db = client[settings.MONGO_DB]
    collection = db["stock_basic_info"]
    
    # 2. åˆå§‹åŒ– Provider
    provider = AKShareProvider()
    await provider.connect()
    
    try:
        # 3. è·å–è‚¡ç¥¨åˆ—è¡¨
        logger.info("ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...")
        stock_list = await provider.get_stock_list()
        
        if not stock_list:
            logger.error("âŒ æœªè·å–åˆ°è‚¡ç¥¨åˆ—è¡¨")
            return
        
        total_count = len(stock_list)
        logger.info(f"âœ… è·å–åˆ° {total_count} åªè‚¡ç¥¨")
        
        # 4. é¢„åŠ è½½è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜ï¼ˆç”¨äºé™çº§æŸ¥è¯¢ï¼‰
        logger.info("ğŸ”„ é¢„åŠ è½½è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜...")
        await provider._get_stock_list_cached()
        
        # 5. æ‰¹é‡å¤„ç†
        logger.info(f"\nğŸ”„ å¼€å§‹åŒæ­¥...")
        logger.info(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
        logger.info(f"   å»¶è¿Ÿæ—¶é—´: {delay}ç§’/è‚¡ç¥¨")
        logger.info("")
        
        success_count = 0
        failed_count = 0
        failed_stocks = []
        
        start_time = datetime.now()
        
        for i, stock in enumerate(stock_list, 1):
            code = stock.get("code")
            name = stock.get("name", "")
            
            if not code:
                logger.warning(f"âš ï¸  [{i}/{total_count}] è·³è¿‡: ç¼ºå°‘è‚¡ç¥¨ä»£ç ")
                failed_count += 1
                continue
            
            try:
                # è·å–è¯¦ç»†ä¿¡æ¯
                basic_info = await provider.get_stock_basic_info(code)
                
                if basic_info:
                    # æ·»åŠ  symbol å­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
                    basic_info["symbol"] = code
                    basic_info["updated_at"] = datetime.utcnow()
                    
                    # æ›´æ–°æ•°æ®åº“
                    await collection.update_one(
                        {"code": code},
                        {"$set": basic_info},
                        upsert=True
                    )
                    
                    # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯10åªè‚¡ç¥¨æ˜¾ç¤ºä¸€æ¬¡ï¼‰
                    if i % 10 == 0 or i == total_count:
                        logger.info(f"ğŸ“ˆ [{i}/{total_count}] {code} ({basic_info.get('name', 'N/A')}) "
                                   f"- è¡Œä¸š: {basic_info.get('industry', 'N/A')}")
                    
                    success_count += 1
                else:
                    logger.warning(f"âš ï¸  [{i}/{total_count}] {code} è·å–å¤±è´¥")
                    failed_count += 1
                    failed_stocks.append({"code": code, "name": name})
                
                # å»¶è¿Ÿï¼Œé¿å…APIé™æµ
                if i < total_count:
                    await asyncio.sleep(delay)
                
                # æ¯æ‰¹æ¬¡è¾“å‡ºç»Ÿè®¡
                if i % batch_size == 0:
                    elapsed = (datetime.now() - start_time).total_seconds()
                    speed = i / elapsed if elapsed > 0 else 0
                    eta = (total_count - i) / speed if speed > 0 else 0
                    
                    logger.info(f"\nğŸ“Š è¿›åº¦ç»Ÿè®¡:")
                    logger.info(f"   å·²å¤„ç†: {i}/{total_count} ({i*100//total_count}%)")
                    logger.info(f"   æˆåŠŸ: {success_count}, å¤±è´¥: {failed_count}")
                    logger.info(f"   é€Ÿåº¦: {speed:.1f} åª/ç§’")
                    logger.info(f"   é¢„è®¡å‰©ä½™æ—¶é—´: {eta/60:.1f} åˆ†é’Ÿ\n")
                
            except Exception as e:
                logger.error(f"âŒ [{i}/{total_count}] {code} å¤„ç†å¼‚å¸¸: {e}")
                failed_count += 1
                failed_stocks.append({"code": code, "name": name, "error": str(e)})
        
        # 6. è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        elapsed = (datetime.now() - start_time).total_seconds()
        
        logger.info("")
        logger.info("=" * 80)
        logger.info("ğŸ“Š åŒæ­¥å®Œæˆç»Ÿè®¡")
        logger.info("=" * 80)
        logger.info(f"   æ€»è®¡: {total_count} åªè‚¡ç¥¨")
        logger.info(f"   æˆåŠŸ: {success_count} åª")
        logger.info(f"   å¤±è´¥: {failed_count} åª")
        logger.info(f"   æˆåŠŸç‡: {success_count*100//total_count if total_count > 0 else 0}%")
        logger.info(f"   æ€»è€—æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ")
        logger.info(f"   å¹³å‡é€Ÿåº¦: {success_count/elapsed if elapsed > 0 else 0:.1f} åª/ç§’")
        logger.info("=" * 80)
        
        # 7. é‡è¯•å¤±è´¥çš„è‚¡ç¥¨
        if retry_failed and failed_stocks:
            logger.info(f"\nğŸ”„ é‡è¯•å¤±è´¥çš„ {len(failed_stocks)} åªè‚¡ç¥¨...")
            
            retry_success = 0
            for i, stock in enumerate(failed_stocks, 1):
                code = stock["code"]
                try:
                    logger.info(f"   [{i}/{len(failed_stocks)}] é‡è¯• {code}...")
                    basic_info = await provider.get_stock_basic_info(code)
                    
                    if basic_info:
                        basic_info["symbol"] = code
                        basic_info["updated_at"] = datetime.utcnow()
                        
                        await collection.update_one(
                            {"code": code},
                            {"$set": basic_info},
                            upsert=True
                        )
                        
                        logger.info(f"      âœ… æˆåŠŸ: {basic_info.get('name', 'N/A')}")
                        retry_success += 1
                    else:
                        logger.warning(f"      âŒ ä»ç„¶å¤±è´¥")
                    
                    await asyncio.sleep(delay * 2)  # é‡è¯•æ—¶å»¶è¿ŸåŠ å€
                    
                except Exception as e:
                    logger.error(f"      âŒ å¼‚å¸¸: {e}")
            
            logger.info(f"\nğŸ“Š é‡è¯•ç»“æœ: æˆåŠŸ {retry_success}/{len(failed_stocks)}")
        
        # 8. ä¿å­˜å¤±è´¥åˆ—è¡¨
        if failed_stocks:
            failed_file = project_root / "failed_stocks_akshare.txt"
            with open(failed_file, 'w', encoding='utf-8') as f:
                for stock in failed_stocks:
                    f.write(f"{stock['code']}\t{stock.get('name', 'N/A')}\t{stock.get('error', '')}\n")
            logger.info(f"\nğŸ’¾ å¤±è´¥åˆ—è¡¨å·²ä¿å­˜åˆ°: {failed_file}")
        
        logger.info("")
        logger.info("âœ… åŒæ­¥å®Œæˆï¼")
        
    finally:
        client.close()


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="AKShare ä¼˜åŒ–åŒæ­¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        "--batch-size",
        type=int,
        default=100,
        help="æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤ï¼š100ï¼‰"
    )
    parser.add_argument(
        "--delay",
        type=float,
        default=0.3,
        help="æ¯åªè‚¡ç¥¨ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰ï¼ˆé»˜è®¤ï¼š0.3ï¼‰"
    )
    parser.add_argument(
        "--no-retry",
        action="store_true",
        help="ä¸é‡è¯•å¤±è´¥çš„è‚¡ç¥¨"
    )
    
    args = parser.parse_args()
    
    asyncio.run(sync_stock_basic_info(
        batch_size=args.batch_size,
        delay=args.delay,
        retry_failed=not args.no_retry
    ))


if __name__ == "__main__":
    main()

