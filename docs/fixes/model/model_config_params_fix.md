# æ¨¡å‹é…ç½®å‚æ•°ä¿®å¤æ–‡æ¡£

## ğŸ“‹ é—®é¢˜æè¿°

åœ¨ä¹‹å‰çš„å®ç°ä¸­ï¼Œåç«¯è™½ç„¶ä»æ•°æ®åº“è¯»å–äº†ç”¨æˆ·é…ç½®çš„æ¨¡å‹åç§°ï¼Œä½†åœ¨åˆ›å»º LLM å®ä¾‹æ—¶ï¼Œ**æ‰€æœ‰çš„æ¨¡å‹å‚æ•°éƒ½æ˜¯ç¡¬ç¼–ç çš„**ï¼š

- `max_tokens`: ç¡¬ç¼–ç ä¸º `2000`
- `temperature`: ç¡¬ç¼–ç ä¸º `0.1`
- `timeout`: éƒ¨åˆ†ç¡¬ç¼–ç æˆ–åŠ¨æ€è®¡ç®—ï¼ˆé˜¿é‡Œç™¾ç‚¼ï¼‰
- `retry_times`: æœªä½¿ç”¨

è¿™å¯¼è‡´ç”¨æˆ·åœ¨å‰ç«¯é…ç½®çš„æ¨¡å‹å‚æ•°ï¼ˆå¦‚è¶…æ—¶æ—¶é—´ã€æ¸©åº¦å‚æ•°ç­‰ï¼‰**å®Œå…¨æ²¡æœ‰ç”Ÿæ•ˆ**ã€‚

## âœ… ä¿®å¤æ–¹æ¡ˆ

### 1. ä¿®æ”¹é»˜è®¤è¶…æ—¶æ—¶é—´

å°†é»˜è®¤è¶…æ—¶æ—¶é—´ä» `60ç§’` æ”¹ä¸º `180ç§’`ï¼š

**ä¿®æ”¹çš„æ–‡ä»¶ï¼š**
- `frontend/src/views/Settings/components/LLMConfigDialog.vue` (ç¬¬380è¡Œ)
- `app/models/config.py` (ç¬¬175è¡Œã€ç¬¬344è¡Œ)

### 2. ä¿®æ”¹é…ç½®ä¼ é€’æµç¨‹

#### 2.1 ä¿®æ”¹ `create_analysis_config` å‡½æ•°

**æ–‡ä»¶ï¼š** `app/services/simple_analysis_service.py`

**ä¿®æ”¹å†…å®¹ï¼š**
- æ·»åŠ ä¸¤ä¸ªæ–°å‚æ•°ï¼š`quick_model_config` å’Œ `deep_model_config`
- å°†æ¨¡å‹é…ç½®å‚æ•°æ·»åŠ åˆ°è¿”å›çš„ config å­—å…¸ä¸­
- æ·»åŠ æ—¥å¿—è¾“å‡ºï¼Œæ–¹ä¾¿è°ƒè¯•

```python
def create_analysis_config(
    research_depth,
    selected_analysts: list,
    quick_model: str,
    deep_model: str,
    llm_provider: str,
    market_type: str = "Aè‚¡",
    quick_model_config: dict = None,  # æ–°å¢
    deep_model_config: dict = None    # æ–°å¢
) -> dict:
    # ... å…¶ä»–ä»£ç  ...
    
    # æ·»åŠ æ¨¡å‹é…ç½®å‚æ•°
    if quick_model_config:
        config["quick_model_config"] = quick_model_config
    
    if deep_model_config:
        config["deep_model_config"] = deep_model_config
    
    return config
```

#### 2.2 ä¿®æ”¹è°ƒç”¨ `create_analysis_config` çš„åœ°æ–¹

**æ–‡ä»¶ï¼š** `app/services/analysis_service.py`

**ä¿®æ”¹å†…å®¹ï¼š**
- åœ¨è°ƒç”¨ `create_analysis_config` ä¹‹å‰ï¼Œä»æ•°æ®åº“è¯»å–æ¨¡å‹çš„å®Œæ•´é…ç½®
- å°†é…ç½®å‚æ•°ä¼ é€’ç»™ `create_analysis_config`

**ä¿®æ”¹çš„å‡½æ•°ï¼š**
1. `_execute_analysis_sync_with_progress` (ç¬¬113-165è¡Œ)
2. `_execute_analysis_sync` (ç¬¬215-259è¡Œ)
3. `execute_analysis_task` (ç¬¬577-620è¡Œ)

```python
# ä»æ•°æ®åº“è¯»å–æ¨¡å‹çš„å®Œæ•´é…ç½®å‚æ•°
quick_model_config = None
deep_model_config = None
llm_configs = unified_config.get_llm_configs()

for llm_config in llm_configs:
    if llm_config.model_name == quick_model:
        quick_model_config = {
            "max_tokens": llm_config.max_tokens,
            "temperature": llm_config.temperature,
            "timeout": llm_config.timeout,
            "retry_times": llm_config.retry_times,
            "api_base": llm_config.api_base
        }
    
    if llm_config.model_name == deep_model:
        deep_model_config = {
            "max_tokens": llm_config.max_tokens,
            "temperature": llm_config.temperature,
            "timeout": llm_config.timeout,
            "retry_times": llm_config.retry_times,
            "api_base": llm_config.api_base
        }

# ä¼ é€’ç»™ create_analysis_config
config = create_analysis_config(
    research_depth=task.parameters.research_depth,
    selected_analysts=task.parameters.selected_analysts or ["market", "fundamentals"],
    quick_model=quick_model,
    deep_model=deep_model,
    llm_provider=llm_provider,
    market_type=getattr(task.parameters, 'market_type', "Aè‚¡"),
    quick_model_config=quick_model_config,  # ä¼ é€’æ¨¡å‹é…ç½®
    deep_model_config=deep_model_config     # ä¼ é€’æ¨¡å‹é…ç½®
)
```

#### 2.3 ä¿®æ”¹ TradingAgentsGraph

**æ–‡ä»¶ï¼š** `tradingagents/graph/trading_graph.py`

**ä¿®æ”¹å†…å®¹ï¼š**
- åœ¨ `__init__` æ–¹æ³•ä¸­ï¼Œä» config è¯»å–æ¨¡å‹é…ç½®å‚æ•°
- ä½¿ç”¨é…ç½®ä¸­çš„å‚æ•°åˆ›å»º LLM å®ä¾‹ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç 

**ä¿®æ”¹çš„ä¾›åº”å•†ï¼š**
1. OpenAI (ç¬¬69-153è¡Œ)
2. SiliconFlow (ç¬¬69-153è¡Œ)
3. OpenRouter (ç¬¬69-153è¡Œ)
4. Ollama (ç¬¬154-228è¡Œ)
5. Anthropic (ç¬¬154-228è¡Œ)
6. Google (ç¬¬154-228è¡Œ)
7. é˜¿é‡Œç™¾ç‚¼/DashScope (ç¬¬229-260è¡Œ)
8. DeepSeek (ç¬¬261-304è¡Œ)
9. Custom OpenAI (ç¬¬305-345è¡Œ)
10. åƒå¸†/Qianfan (ç¬¬346-384è¡Œ)

**ç¤ºä¾‹ä»£ç ï¼ˆé˜¿é‡Œç™¾ç‚¼ï¼‰ï¼š**

```python
# ä»é…ç½®ä¸­è¯»å–æ¨¡å‹å‚æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é…ç½®ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼‰
quick_config = self.config.get("quick_model_config", {})
deep_config = self.config.get("deep_model_config", {})

# è¯»å–å¿«é€Ÿæ¨¡å‹å‚æ•°
quick_max_tokens = quick_config.get("max_tokens", 4000)
quick_temperature = quick_config.get("temperature", 0.7)
quick_timeout = quick_config.get("timeout", 180)

# è¯»å–æ·±åº¦æ¨¡å‹å‚æ•°
deep_max_tokens = deep_config.get("max_tokens", 4000)
deep_temperature = deep_config.get("temperature", 0.7)
deep_timeout = deep_config.get("timeout", 180)

logger.info(f"ğŸ”§ [é˜¿é‡Œç™¾ç‚¼-å¿«é€Ÿæ¨¡å‹] max_tokens={quick_max_tokens}, temperature={quick_temperature}, timeout={quick_timeout}s")
logger.info(f"ğŸ”§ [é˜¿é‡Œç™¾ç‚¼-æ·±åº¦æ¨¡å‹] max_tokens={deep_max_tokens}, temperature={deep_temperature}, timeout={deep_timeout}s")

self.deep_thinking_llm = ChatDashScopeOpenAI(
    model=self.config["deep_think_llm"],
    temperature=deep_temperature,      # ä½¿ç”¨ç”¨æˆ·é…ç½®
    max_tokens=deep_max_tokens,        # ä½¿ç”¨ç”¨æˆ·é…ç½®
    request_timeout=deep_timeout       # ä½¿ç”¨ç”¨æˆ·é…ç½®
)
self.quick_thinking_llm = ChatDashScopeOpenAI(
    model=self.config["quick_think_llm"],
    temperature=quick_temperature,     # ä½¿ç”¨ç”¨æˆ·é…ç½®
    max_tokens=quick_max_tokens,       # ä½¿ç”¨ç”¨æˆ·é…ç½®
    request_timeout=quick_timeout      # ä½¿ç”¨ç”¨æˆ·é…ç½®
)
```

## ğŸ“Š ä¿®æ”¹æ€»ç»“

### ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨

1. âœ… `frontend/src/views/Settings/components/LLMConfigDialog.vue` - é»˜è®¤è¶…æ—¶æ—¶é—´æ”¹ä¸º180ç§’
2. âœ… `app/models/config.py` - é»˜è®¤è¶…æ—¶æ—¶é—´æ”¹ä¸º180ç§’ï¼ˆ2å¤„ï¼‰
3. âœ… `app/services/simple_analysis_service.py` - æ·»åŠ æ¨¡å‹é…ç½®å‚æ•°ä¼ é€’
4. âœ… `app/services/analysis_service.py` - ä»æ•°æ®åº“è¯»å–å¹¶ä¼ é€’æ¨¡å‹é…ç½®ï¼ˆ3å¤„ï¼‰
5. âœ… `tradingagents/graph/trading_graph.py` - ä½¿ç”¨é…ç½®å‚æ•°è€Œä¸æ˜¯ç¡¬ç¼–ç ï¼ˆ10ä¸ªä¾›åº”å•†ï¼‰

### å½±å“çš„ä¾›åº”å•†

æ‰€æœ‰ LLM ä¾›åº”å•†éƒ½å·²ä¿®æ”¹ï¼Œç°åœ¨éƒ½ä¼šä½¿ç”¨ç”¨æˆ·é…ç½®çš„å‚æ•°ï¼š

1. âœ… OpenAI
2. âœ… SiliconFlow
3. âœ… OpenRouter
4. âœ… Ollama
5. âœ… Anthropic
6. âœ… Google AI
7. âœ… é˜¿é‡Œç™¾ç‚¼ (DashScope)
8. âœ… DeepSeek
9. âœ… Custom OpenAI
10. âœ… åƒå¸† (Qianfan)

## ğŸ§ª æµ‹è¯•éªŒè¯

è¿è¡Œæµ‹è¯•è„šæœ¬ï¼š

```bash
.\.venv\Scripts\python scripts/test_model_config_params.py
```

**æµ‹è¯•ç»“æœï¼š** âœ… é€šè¿‡

æµ‹è¯•éªŒè¯äº†ï¼š
- âœ… æ¨¡å‹é…ç½®å‚æ•°æ­£ç¡®ä¼ é€’åˆ° `create_analysis_config`
- âœ… é…ç½®ä¸­åŒ…å« `quick_model_config` å’Œ `deep_model_config`
- âœ… å‚æ•°å€¼ä¸è¾“å…¥ä¸€è‡´

## ğŸ“ ä½¿ç”¨è¯´æ˜

### ç”¨æˆ·é…ç½®æµç¨‹

1. ç”¨æˆ·åœ¨å‰ç«¯"ç³»ç»Ÿè®¾ç½®"é¡µé¢é…ç½®æ¨¡å‹å‚æ•°ï¼š
   - æœ€å¤§Tokenæ•° (max_tokens)
   - æ¸©åº¦å‚æ•° (temperature)
   - è¶…æ—¶æ—¶é—´ (timeout) - é»˜è®¤180ç§’
   - é‡è¯•æ¬¡æ•° (retry_times)

2. é…ç½®ä¿å­˜åˆ°æ•°æ®åº“

3. ç”¨æˆ·å‘èµ·åˆ†ææ—¶ï¼š
   - åç«¯ä»æ•°æ®åº“è¯»å–æ¨¡å‹é…ç½®
   - å°†é…ç½®å‚æ•°ä¼ é€’ç»™åˆ†æå¼•æ“
   - åˆ†æå¼•æ“ä½¿ç”¨ç”¨æˆ·é…ç½®çš„å‚æ•°åˆ›å»º LLM å®ä¾‹

### æ—¥å¿—éªŒè¯

åœ¨åˆ†ææ—¥å¿—ä¸­ï¼Œå¯ä»¥çœ‹åˆ°ç±»ä¼¼çš„è¾“å‡ºï¼š

```
ğŸ”§ [é˜¿é‡Œç™¾ç‚¼-å¿«é€Ÿæ¨¡å‹] max_tokens=6000, temperature=0.8, timeout=200s
ğŸ”§ [é˜¿é‡Œç™¾ç‚¼-æ·±åº¦æ¨¡å‹] max_tokens=8000, temperature=0.5, timeout=300s
âœ… [é˜¿é‡Œç™¾ç‚¼] å·²åº”ç”¨ç”¨æˆ·é…ç½®çš„æ¨¡å‹å‚æ•°
```

## ğŸ¯ ä¿®å¤æ•ˆæœ

### ä¿®å¤å‰

- âŒ æ‰€æœ‰æ¨¡å‹ä½¿ç”¨ç¡¬ç¼–ç å‚æ•°ï¼š`temperature=0.1`, `max_tokens=2000`
- âŒ ç”¨æˆ·é…ç½®çš„å‚æ•°ä¸ç”Ÿæ•ˆ
- âŒ è¶…æ—¶æ—¶é—´é»˜è®¤60ç§’ï¼Œå¯èƒ½å¯¼è‡´é•¿æ—¶é—´åˆ†æè¶…æ—¶

### ä¿®å¤å

- âœ… æ‰€æœ‰æ¨¡å‹ä½¿ç”¨ç”¨æˆ·é…ç½®çš„å‚æ•°
- âœ… ç”¨æˆ·å¯ä»¥è‡ªå®šä¹‰æ¯ä¸ªæ¨¡å‹çš„å‚æ•°
- âœ… è¶…æ—¶æ—¶é—´é»˜è®¤180ç§’ï¼Œæ›´åˆç†
- âœ… æ”¯æŒæ‰€æœ‰10ä¸ª LLM ä¾›åº”å•†

## ğŸ” æ³¨æ„äº‹é¡¹

1. **é»˜è®¤å€¼**ï¼šå¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®ï¼Œä¼šä½¿ç”¨é»˜è®¤å€¼ï¼š
   - `max_tokens`: 4000
   - `temperature`: 0.7
   - `timeout`: 180ç§’
   - `retry_times`: 3

2. **æ—¥å¿—è¾“å‡º**ï¼šæ‰€æœ‰ä¾›åº”å•†éƒ½ä¼šè¾“å‡ºé…ç½®å‚æ•°åˆ°æ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯•

3. **å‘åå…¼å®¹**ï¼šå¦‚æœæ²¡æœ‰ä¼ é€’æ¨¡å‹é…ç½®å‚æ•°ï¼Œä¼šä½¿ç”¨é»˜è®¤å€¼ï¼Œä¸ä¼šæŠ¥é”™

## ğŸ“… ä¿®æ”¹æ—¥æœŸ

2025-10-12

