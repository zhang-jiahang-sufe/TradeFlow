#!/usr/bin/env python3
"""
æ¶ˆæ¯æ•°æ®çˆ¬è™«è°ƒåº¦å™¨
ç»Ÿä¸€è°ƒåº¦ç¤¾åª’æ¶ˆæ¯å’Œå†…éƒ¨æ¶ˆæ¯çš„çˆ¬å–ä»»åŠ¡
"""
import asyncio
import logging
import sys
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from app.core.database import init_db
from app.services.social_media_service import get_social_media_service
from app.services.internal_message_service import get_internal_message_service

# å¯¼å…¥çˆ¬è™«æ¨¡å—
try:
    from social_media_crawler import crawl_and_save_social_media
    from internal_message_crawler import crawl_and_save_internal_messages
except ImportError:
    # å¦‚æœä»å…¶ä»–ç›®å½•è¿è¡Œï¼Œå°è¯•ç»å¯¹å¯¼å…¥
    from examples.crawlers.social_media_crawler import crawl_and_save_social_media
    from examples.crawlers.internal_message_crawler import crawl_and_save_internal_messages

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class MessageCrawlerScheduler:
    """æ¶ˆæ¯æ•°æ®çˆ¬è™«è°ƒåº¦å™¨"""
    
    def __init__(self, config_file: str = None):
        self.config_file = config_file or "crawler_config.json"
        self.logger = logging.getLogger(self.__class__.__name__)
        self.config = self._load_config()
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½çˆ¬è™«é…ç½®"""
        default_config = {
            "symbols": ["000001", "000002", "600000", "600036", "000858"],
            "social_media": {
                "enabled": True,
                "platforms": ["weibo", "douyin"],
                "limits": {
                    "weibo": 50,
                    "douyin": 30
                },
                "schedule": {
                    "interval_hours": 4,
                    "max_daily_runs": 6
                }
            },
            "internal_messages": {
                "enabled": True,
                "types": ["research_report", "analyst_note"],
                "limits": {
                    "research_report": 10,
                    "analyst_note": 20
                },
                "schedule": {
                    "interval_hours": 8,
                    "max_daily_runs": 3
                }
            },
            "database": {
                "batch_size": 100,
                "retry_attempts": 3,
                "retry_delay": 5
            },
            "logging": {
                "level": "INFO",
                "save_logs": True,
                "log_file": "crawler_logs.txt"
            }
        }
        
        config_path = Path(self.config_file)
        if config_path.exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    # åˆå¹¶é…ç½®
                    default_config.update(user_config)
                    self.logger.info(f"âœ… åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
            except Exception as e:
                self.logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
        else:
            # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
            try:
                with open(config_path, 'w', encoding='utf-8') as f:
                    json.dump(default_config, f, indent=2, ensure_ascii=False)
                self.logger.info(f"âœ… åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {config_path}")
            except Exception as e:
                self.logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶åˆ›å»ºå¤±è´¥: {e}")
        
        return default_config
    
    async def run_social_media_crawl(self) -> Dict[str, Any]:
        """è¿è¡Œç¤¾åª’æ¶ˆæ¯çˆ¬å–"""
        if not self.config["social_media"]["enabled"]:
            self.logger.info("â¸ï¸ ç¤¾åª’æ¶ˆæ¯çˆ¬å–å·²ç¦ç”¨")
            return {"status": "disabled", "saved": 0}
        
        self.logger.info("ğŸ•·ï¸ å¼€å§‹ç¤¾åª’æ¶ˆæ¯çˆ¬å–ä»»åŠ¡")
        
        try:
            symbols = self.config["symbols"]
            platforms = self.config["social_media"]["platforms"]
            
            # æ‰§è¡Œçˆ¬å–
            saved_count = await crawl_and_save_social_media(symbols, platforms)
            
            result = {
                "status": "success",
                "saved": saved_count,
                "symbols": len(symbols),
                "platforms": len(platforms),
                "timestamp": datetime.now().isoformat()
            }
            
            self.logger.info(f"âœ… ç¤¾åª’æ¶ˆæ¯çˆ¬å–å®Œæˆ: {saved_count} æ¡")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ç¤¾åª’æ¶ˆæ¯çˆ¬å–å¤±è´¥: {e}")
            return {
                "status": "error",
                "error": str(e),
                "saved": 0,
                "timestamp": datetime.now().isoformat()
            }
    
    async def run_internal_message_crawl(self) -> Dict[str, Any]:
        """è¿è¡Œå†…éƒ¨æ¶ˆæ¯çˆ¬å–"""
        if not self.config["internal_messages"]["enabled"]:
            self.logger.info("â¸ï¸ å†…éƒ¨æ¶ˆæ¯çˆ¬å–å·²ç¦ç”¨")
            return {"status": "disabled", "saved": 0}
        
        self.logger.info("ğŸ“Š å¼€å§‹å†…éƒ¨æ¶ˆæ¯çˆ¬å–ä»»åŠ¡")
        
        try:
            symbols = self.config["symbols"]
            message_types = self.config["internal_messages"]["types"]
            
            # æ‰§è¡Œçˆ¬å–
            saved_count = await crawl_and_save_internal_messages(symbols, message_types)
            
            result = {
                "status": "success",
                "saved": saved_count,
                "symbols": len(symbols),
                "types": len(message_types),
                "timestamp": datetime.now().isoformat()
            }
            
            self.logger.info(f"âœ… å†…éƒ¨æ¶ˆæ¯çˆ¬å–å®Œæˆ: {saved_count} æ¡")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ å†…éƒ¨æ¶ˆæ¯çˆ¬å–å¤±è´¥: {e}")
            return {
                "status": "error",
                "error": str(e),
                "saved": 0,
                "timestamp": datetime.now().isoformat()
            }
    
    async def run_full_crawl(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çˆ¬å–ä»»åŠ¡"""
        self.logger.info("ğŸš€ å¼€å§‹å®Œæ•´æ¶ˆæ¯æ•°æ®çˆ¬å–ä»»åŠ¡")
        
        start_time = datetime.now()
        
        # åˆå§‹åŒ–æ•°æ®åº“
        await init_db()
        
        # å¹¶è¡Œæ‰§è¡Œç¤¾åª’å’Œå†…éƒ¨æ¶ˆæ¯çˆ¬å–
        social_task = asyncio.create_task(self.run_social_media_crawl())
        internal_task = asyncio.create_task(self.run_internal_message_crawl())
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        social_result, internal_result = await asyncio.gather(
            social_task, internal_task, return_exceptions=True
        )
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        if isinstance(social_result, Exception):
            social_result = {
                "status": "error",
                "error": str(social_result),
                "saved": 0
            }
        
        if isinstance(internal_result, Exception):
            internal_result = {
                "status": "error", 
                "error": str(internal_result),
                "saved": 0
            }
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        # æ±‡æ€»ç»“æœ
        total_saved = social_result.get("saved", 0) + internal_result.get("saved", 0)
        
        summary = {
            "status": "completed",
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration_seconds": duration,
            "total_saved": total_saved,
            "social_media": social_result,
            "internal_messages": internal_result,
            "symbols_processed": len(self.config["symbols"])
        }
        
        self.logger.info(f"ğŸ‰ å®Œæ•´çˆ¬å–ä»»åŠ¡å®Œæˆ: {total_saved} æ¡æ¶ˆæ¯, è€—æ—¶ {duration:.1f} ç§’")
        
        # ä¿å­˜è¿è¡Œæ—¥å¿—
        await self._save_run_log(summary)
        
        return summary
    
    async def _save_run_log(self, summary: Dict[str, Any]):
        """ä¿å­˜è¿è¡Œæ—¥å¿—"""
        if not self.config["logging"]["save_logs"]:
            return
        
        try:
            log_file = Path(self.config["logging"]["log_file"])
            
            # è¯»å–ç°æœ‰æ—¥å¿—
            logs = []
            if log_file.exists():
                with open(log_file, 'r', encoding='utf-8') as f:
                    try:
                        logs = json.load(f)
                    except json.JSONDecodeError:
                        logs = []
            
            # æ·»åŠ æ–°æ—¥å¿—
            logs.append(summary)
            
            # ä¿æŒæœ€è¿‘100æ¡è®°å½•
            if len(logs) > 100:
                logs = logs[-100:]
            
            # ä¿å­˜æ—¥å¿—
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(logs, f, indent=2, ensure_ascii=False)
            
            self.logger.debug(f"ğŸ“ è¿è¡Œæ—¥å¿—å·²ä¿å­˜: {log_file}")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ è¿è¡Œæ—¥å¿—ä¿å­˜å¤±è´¥: {e}")
    
    async def get_crawl_statistics(self) -> Dict[str, Any]:
        """è·å–çˆ¬å–ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # è·å–æœåŠ¡
            social_service = await get_social_media_service()
            internal_service = await get_internal_message_service()
            
            # è®¡ç®—æ—¶é—´èŒƒå›´ï¼ˆæœ€è¿‘24å°æ—¶ï¼‰
            end_time = datetime.utcnow()
            start_time = end_time - timedelta(hours=24)
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            social_stats = await social_service.get_social_media_statistics(
                start_time=start_time, end_time=end_time
            )
            
            internal_stats = await internal_service.get_internal_statistics(
                start_time=start_time, end_time=end_time
            )
            
            return {
                "time_range": {
                    "start_time": start_time.isoformat(),
                    "end_time": end_time.isoformat(),
                    "hours": 24
                },
                "social_media": {
                    "total_messages": social_stats.total_count,
                    "positive_messages": social_stats.positive_count,
                    "negative_messages": social_stats.negative_count,
                    "neutral_messages": social_stats.neutral_count,
                    "platforms": social_stats.platforms,
                    "avg_engagement_rate": social_stats.avg_engagement_rate
                },
                "internal_messages": {
                    "total_messages": internal_stats.total_count,
                    "message_types": internal_stats.message_types,
                    "departments": internal_stats.departments,
                    "avg_confidence": internal_stats.avg_confidence
                },
                "total_messages": social_stats.total_count + internal_stats.total_count
            }
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def print_config(self):
        """æ‰“å°å½“å‰é…ç½®"""
        self.logger.info("ğŸ“‹ å½“å‰çˆ¬è™«é…ç½®:")
        self.logger.info(f"   - è‚¡ç¥¨æ•°é‡: {len(self.config['symbols'])}")
        self.logger.info(f"   - ç¤¾åª’å¹³å°: {self.config['social_media']['platforms']}")
        self.logger.info(f"   - å†…éƒ¨æ¶ˆæ¯ç±»å‹: {self.config['internal_messages']['types']}")
        self.logger.info(f"   - ç¤¾åª’çˆ¬å–: {'å¯ç”¨' if self.config['social_media']['enabled'] else 'ç¦ç”¨'}")
        self.logger.info(f"   - å†…éƒ¨æ¶ˆæ¯çˆ¬å–: {'å¯ç”¨' if self.config['internal_messages']['enabled'] else 'ç¦ç”¨'}")


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¤– æ¶ˆæ¯æ•°æ®çˆ¬è™«è°ƒåº¦å™¨å¯åŠ¨")
    
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = MessageCrawlerScheduler()
    
    # æ‰“å°é…ç½®
    scheduler.print_config()
    
    # è¿è¡Œå®Œæ•´çˆ¬å–
    result = await scheduler.run_full_crawl()
    
    # æ‰“å°ç»“æœ
    logger.info("\n" + "="*60)
    logger.info("ğŸ“Š çˆ¬å–ä»»åŠ¡æ‰§è¡Œç»“æœ")
    logger.info("="*60)
    logger.info(f"æ€»è€—æ—¶: {result['duration_seconds']:.1f} ç§’")
    logger.info(f"æ€»ä¿å­˜: {result['total_saved']} æ¡æ¶ˆæ¯")
    logger.info(f"ç¤¾åª’æ¶ˆæ¯: {result['social_media']['saved']} æ¡")
    logger.info(f"å†…éƒ¨æ¶ˆæ¯: {result['internal_messages']['saved']} æ¡")
    logger.info(f"å¤„ç†è‚¡ç¥¨: {result['symbols_processed']} åª")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = await scheduler.get_crawl_statistics()
    if "error" not in stats:
        logger.info("\nğŸ“ˆ æœ€è¿‘24å°æ—¶ç»Ÿè®¡:")
        logger.info(f"ç¤¾åª’æ¶ˆæ¯æ€»æ•°: {stats['social_media']['total_messages']}")
        logger.info(f"å†…éƒ¨æ¶ˆæ¯æ€»æ•°: {stats['internal_messages']['total_messages']}")
        logger.info(f"æ¶ˆæ¯æ€»æ•°: {stats['total_messages']}")
    
    logger.info("="*60)
    
    if result['total_saved'] > 0:
        logger.info("âœ… æ¶ˆæ¯æ•°æ®çˆ¬è™«è°ƒåº¦å™¨è¿è¡ŒæˆåŠŸ!")
    else:
        logger.warning("âš ï¸ æœªä¿å­˜ä»»ä½•æ¶ˆæ¯ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç½‘ç»œè¿æ¥")


if __name__ == "__main__":
    asyncio.run(main())
